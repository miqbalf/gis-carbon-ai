{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b588df83",
   "metadata": {},
   "source": [
    "# Test Refactored tsfresh Ground Truth Preparation\n",
    "\n",
    "This notebook tests the refactored `forestry.prepare_tsfresh_with_ground_truth()` method which:\n",
    "1. Loads ground truth training data (polygons)\n",
    "2. Clips satellite data to sample bounding boxes\n",
    "3. Converts training polygons to raster masks\n",
    "4. Merges masks into 4D dataset (plot_id, time, y, x)\n",
    "5. Merges satellite data with ground truth labels\n",
    "6. Saves to zarr for efficient access\n",
    "\n",
    "**Workflow:**\n",
    "- Uses `ds_resampled` from `get_ds_resampled_gee()` (or loads from zarr)\n",
    "- Loads ground truth from parquet file (GCS or local)\n",
    "- Prepares datasets ready for tsfresh feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad93aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/gcsfs/core.py:317: UserWarning: GCS project not set - cannot list or create buckets\n",
      "  warnings.warn(\"GCS project not set - cannot list or create buckets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Forestry Carbon ARR initialized\n"
     ]
    }
   ],
   "source": [
    "import ee, eemont\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from forestry_carbon_arr.core import ForestryCarbonARR\n",
    "\n",
    "# Initialize Forestry Carbon ARR system\n",
    "forestry = ForestryCarbonARR(config_path='./00_input/korindo.json')\n",
    "print(\"‚úÖ Forestry Carbon ARR initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961c4af",
   "metadata": {},
   "source": [
    "## Step 1: Get ds_resampled (satellite time series data)\n",
    "\n",
    "Either load from existing zarr or create from GEE asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130793a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef797f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading dataset from GCS zarr: gs://remote_sensing_saas/01-korindo/timeseries_zarr/ds_resampled.zarr\n",
      "‚úÖ Dataset loaded: {'time': 81, 'x': 4489, 'y': 3213}\n",
      "‚úÖ Loaded ds_resampled from zarr: gs://remote_sensing_saas/01-korindo/timeseries_zarr/ds_resampled.zarr\n",
      "   Dimensions: {'time': 81, 'x': 4489, 'y': 3213}\n",
      "   Variables: ['EVI', 'NDVI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/forestry_carbon_arr/utils/zarr_utils.py:297: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"‚úÖ Dataset loaded: {dict(ds.dims)}\")\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Load from existing zarr (fastest)\n",
    "from forestry_carbon_arr.utils.zarr_utils import load_dataset_zarr\n",
    "import os\n",
    "\n",
    "zarr_path = os.getenv('GCS_ZARR_DIR', '')\n",
    "if zarr_path:\n",
    "    if not zarr_path.startswith('gs://'):\n",
    "        zarr_path = f\"gs://{zarr_path}/ds_resampled.zarr\"\n",
    "    else:\n",
    "        zarr_path = f\"{zarr_path}/ds_resampled.zarr\"\n",
    "    storage = 'gcs'\n",
    "else:\n",
    "    zarr_path = os.path.join(os.getcwd(), 'data', 'ds_resampled.zarr')\n",
    "    storage = 'local'\n",
    "\n",
    "try:\n",
    "    ds_resampled = load_dataset_zarr(zarr_path, storage=storage)\n",
    "    print(f\"‚úÖ Loaded ds_resampled from zarr: {zarr_path}\")\n",
    "    print(f\"   Dimensions: {dict(ds_resampled.sizes)}\")\n",
    "    print(f\"   Variables: {list(ds_resampled.data_vars)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not load from zarr: {e}\")\n",
    "    print(\"   Will create from GEE asset instead...\")\n",
    "    ds_resampled = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cfd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Create from GEE asset (if zarr not available)\n",
    "if ds_resampled is None:\n",
    "    print(\"Creating ds_resampled from GEE asset...\")\n",
    "    ds_resampled = forestry.get_ds_resampled_gee(\n",
    "        use_existing_asset=True,\n",
    "        asset_folder='projects/remote-sensing-476412/assets/korindo_sentinel2_monthly',\n",
    "        asset_is_monthly_composites=True,\n",
    "        save_to_zarr=True,  # Save for future use\n",
    "        zarr_path=None,\n",
    "        overwrite_zarr=False\n",
    "    )\n",
    "    print(f\"‚úÖ Created ds_resampled: {dict(ds_resampled.sizes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014cbe87",
   "metadata": {},
   "source": [
    "## Step 2: Prepare tsfresh data with ground truth\n",
    "\n",
    "This will:\n",
    "- Load ground truth training polygons\n",
    "- Clip satellite data to sample bounding boxes\n",
    "- Convert polygons to raster masks\n",
    "- Merge satellite data with ground truth labels\n",
    "- Save to zarr (one dataset per sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99c1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ds_resampled coordinate order:\n",
      "  X: 578619.54 to 623499.54 (ascending)\n",
      "  Y: 9949396.12 to 9981516.12 (ascending)\n",
      "\n",
      "Note: Dataset will be standardized to STAC convention (y descending, x ascending) automatically\n"
     ]
    }
   ],
   "source": [
    "# Reload module to get latest fixes\n",
    "import importlib\n",
    "import forestry_carbon_arr.utils.tsfresh_utils\n",
    "importlib.reload(forestry_carbon_arr.utils.tsfresh_utils)\n",
    "\n",
    "# Check coordinate order before processing\n",
    "print(\"Checking ds_resampled coordinate order:\")\n",
    "print(f\"  X: {ds_resampled.x.values[0]:.2f} to {ds_resampled.x.values[-1]:.2f} ({'ascending' if ds_resampled.x.values[0] < ds_resampled.x.values[-1] else 'descending'})\")\n",
    "print(f\"  Y: {ds_resampled.y.values[0]:.2f} to {ds_resampled.y.values[-1]:.2f} ({'ascending' if ds_resampled.y.values[0] < ds_resampled.y.values[-1] else 'descending'})\")\n",
    "print(\"\\nNote: Dataset will be standardized to STAC convention (y descending, x ascending) automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028e3942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/forestry_carbon_arr/utils/tsfresh_utils.py:407: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  x=slice(minx, maxx),\n",
      "/usr/src/app/forestry_carbon_arr/utils/tsfresh_utils.py:407: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  x=slice(minx, maxx),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Prepared 3 sample datasets\n",
      "   sample_3: {'time': 93, 'x': 414, 'y': 341, 'plot_id': 1}\n",
      "      Variables: ['EVI', 'NDVI', 'ground_truth', 'gt_valid']\n",
      "   sample_2: {'time': 93, 'x': 413, 'y': 301, 'plot_id': 1}\n",
      "      Variables: ['EVI', 'NDVI', 'ground_truth', 'gt_valid']\n",
      "   sample_1: {'time': 90, 'x': 322, 'y': 231, 'plot_id': 1}\n",
      "      Variables: ['EVI', 'NDVI', 'ground_truth', 'gt_valid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/forestry_carbon_arr/utils/tsfresh_utils.py:407: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  x=slice(minx, maxx),\n"
     ]
    }
   ],
   "source": [
    "# Prepare tsfresh data with ground truth\n",
    "# This is the main method that does everything!\n",
    "\n",
    "ground_truth_path = 'gs://remote_sensing_saas/01-korindo/sample_tsfresh/20251112_df_long.parquet'\n",
    "\n",
    "ds_gt_list = forestry.prepare_tsfresh_with_ground_truth(\n",
    "    ds_resampled=ds_resampled,  # From Step 1\n",
    "    ground_truth_path=ground_truth_path,  # GCS or local path to parquet\n",
    "    buffer_pixels=50,  # Buffer around sample bboxes\n",
    "    save_to_zarr=False,  # Save to zarr for efficient access\n",
    "    zarr_path=None,  # Auto-detects from GCS_ZARR_DIR env var\n",
    "    overwrite_zarr=False,  # Don't overwrite if exists\n",
    "    storage='auto'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Prepared {len(ds_gt_list)} sample datasets\")\n",
    "for i, ds_gt in enumerate(ds_gt_list):\n",
    "    plot_id = ds_gt.coords['plot_id'].values[0] if 'plot_id' in ds_gt.coords else f'sample_{i+1}'\n",
    "    print(f\"   {plot_id}: {dict(ds_gt.sizes)}\")\n",
    "    print(f\"      Variables: {list(ds_gt.data_vars)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e961a",
   "metadata": {},
   "source": [
    "## Step 3: Inspect results\n",
    "\n",
    "Each dataset in `ds_gt_list` contains:\n",
    "- **Dimensions:** (plot_id, time, x, y)\n",
    "- **Variables:**\n",
    "  - `EVI`, `NDVI`: Satellite time series\n",
    "  - `ground_truth`: Training labels (0=non-tree, 1=tree, NaN=no label)\n",
    "  - `gt_valid`: Pixels with labels for all times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f74f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: sample_3\n",
      "Dimensions: {'time': 93, 'x': 414, 'y': 341, 'plot_id': 1}\n",
      "Variables: ['EVI', 'NDVI', 'ground_truth', 'gt_valid']\n",
      "\n",
      "Time range: 2016-03-15 00:00:00 to 2025-09-15 00:00:00\n",
      "\n",
      "Ground Truth Statistics:\n",
      "  Total pixels: 13,129,182\n",
      "  NaN (no label): 10,912,539 (83.1%)\n",
      "  0 (non-tree): 1,112,030 (8.5%)\n",
      "  1 (tree): 1,104,613 (8.4%)\n",
      "\n",
      "Dataset structure:\n",
      "<xarray.Dataset> Size: 158MB\n",
      "Dimensions:       (time: 93, x: 414, y: 341, plot_id: 1)\n",
      "Coordinates:\n",
      "  * time          (time) datetime64[ns] 744B 2016-03-15 ... 2025-09-15\n",
      "  * x             (x) float64 3kB 5.828e+05 5.828e+05 ... 5.869e+05 5.869e+05\n",
      "  * y             (y) float64 3kB 9.971e+06 9.971e+06 ... 9.967e+06 9.967e+06\n",
      "  * plot_id       (plot_id) object 8B 'sample_3'\n",
      "    image_id      (time) object 744B dask.array<chunksize=(20,), meta=np.ndarray>\n",
      "    epsg          int64 8B 32749\n",
      "Data variables:\n",
      "    EVI           (plot_id, time, x, y) float32 53MB dask.array<chunksize=(1, 20, 128, 128), meta=np.ndarray>\n",
      "    NDVI          (plot_id, time, x, y) float32 53MB dask.array<chunksize=(1, 20, 128, 128), meta=np.ndarray>\n",
      "    ground_truth  (plot_id, time, y, x) float32 53MB dask.array<chunksize=(1, 20, 128, 128), meta=np.ndarray>\n",
      "    gt_valid      (plot_id, y, x) bool 141kB dask.array<chunksize=(1, 128, 128), meta=np.ndarray>\n",
      "Attributes:\n",
      "    crs:      EPSG:32749\n"
     ]
    }
   ],
   "source": [
    "# Inspect first sample dataset\n",
    "if len(ds_gt_list) > 0:\n",
    "    ds_gt = ds_gt_list[0]\n",
    "    plot_id = ds_gt.coords['plot_id'].values[0] if 'plot_id' in ds_gt.coords else 'sample_1'\n",
    "    \n",
    "    print(f\"Sample: {plot_id}\")\n",
    "    print(f\"Dimensions: {dict(ds_gt.sizes)}\")\n",
    "    print(f\"Variables: {list(ds_gt.data_vars)}\")\n",
    "    print(f\"\\nTime range: {pd.to_datetime(ds_gt.time.min().values)} to {pd.to_datetime(ds_gt.time.max().values)}\")\n",
    "    \n",
    "    # Check ground truth statistics\n",
    "    if 'ground_truth' in ds_gt.data_vars:\n",
    "        gt_values = ds_gt['ground_truth'].values.flatten()\n",
    "        n_total = len(gt_values)\n",
    "        n_nan = np.isnan(gt_values).sum()\n",
    "        n_zeros = (gt_values == 0).sum()\n",
    "        n_ones = (gt_values == 1).sum()\n",
    "        \n",
    "        print(f\"\\nGround Truth Statistics:\")\n",
    "        print(f\"  Total pixels: {n_total:,}\")\n",
    "        print(f\"  NaN (no label): {n_nan:,} ({100*n_nan/n_total:.1f}%)\")\n",
    "        print(f\"  0 (non-tree): {n_zeros:,} ({100*n_zeros/n_total:.1f}%)\")\n",
    "        print(f\"  1 (tree): {n_ones:,} ({100*n_ones/n_total:.1f}%)\")\n",
    "    \n",
    "    # Show dataset structure\n",
    "    print(f\"\\nDataset structure:\")\n",
    "    print(ds_gt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38acc3d0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **Workflow Complete!**\n",
    "\n",
    "The refactored `forestry.prepare_tsfresh_with_ground_truth()` method:\n",
    "1. ‚úÖ Loads ground truth training data\n",
    "2. ‚úÖ Clips satellite data to sample bounding boxes  \n",
    "3. ‚úÖ Converts polygons to raster masks (parallel processing)\n",
    "4. ‚úÖ Merges masks into 4D dataset (plot_id, time, y, x)\n",
    "5. ‚úÖ Merges satellite data with ground truth labels\n",
    "6. ‚úÖ Saves to zarr for efficient access\n",
    "\n",
    "**Result:** List of datasets ready for tsfresh feature extraction!\n",
    "\n",
    "Each dataset has:\n",
    "- Satellite time series (EVI, NDVI)\n",
    "- Ground truth labels (0=non-tree, 1=tree, NaN=no label)\n",
    "- Validity mask (pixels with labels for all times)\n",
    "\n",
    "**Next steps:**\n",
    "- Extract time series features using tsfresh\n",
    "- Train machine learning models\n",
    "- Apply to full AOI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87129c2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
