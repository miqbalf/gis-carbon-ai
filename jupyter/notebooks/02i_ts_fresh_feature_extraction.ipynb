{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b1f2c-553d-4e93-b1a7-91a8f04a6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115556f2-8318-45ef-9bac-07008a80535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee, eemont\n",
    "from forestry_carbon_arr.core import ForestryCarbonARR\n",
    "from forestry_carbon_arr.utils.zarr_utils import save_dataset_efficient_zarr, load_dataset_zarr\n",
    "\n",
    "import gcsfs\n",
    "import os\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project=os.getenv(\"GOOGLE_CLOUD_PROJECT\"), token='/usr/src/app/user_id.json')\n",
    "gcs_path_ds_train = 'gs://remote_sensing_saas/01-korindo/timeseries_zarr/ds_train.zarr'\n",
    "\n",
    "ds_train = load_dataset_zarr(gcs_path_ds_train)\n",
    "# ds_train\n",
    "\n",
    "forestry = ForestryCarbonARR(config_path='./00_input/korindo.json')\n",
    "forestry.initialize_gee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3300f4-6e14-4d9f-8987-32558320774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aoi\n",
    "from forestry_carbon_arr.core.utils import DataUtils\n",
    "import geopandas as gpd\n",
    "import geemap\n",
    "\n",
    "data_utils = DataUtils(forestry.config, use_gee=True)\n",
    "aoi_gpd, aoi_ee = data_utils.load_geodataframe_gee(forestry.config[\"AOI_path\"])\n",
    "\n",
    "aoi_gpd_utm = aoi_gpd.to_crs(epsg=32749)\n",
    "\n",
    "print(f\"âœ… AOI loaded: {len(aoi_gpd_utm)} features\")\n",
    "print(f\"   Area: {aoi_gpd_utm.geometry.area.sum()/10000:.2f} hectares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3040012-f481-4b20-87b8-753e6cacbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "def get_selected_ts_features_multi(X_array, selected_features, channel_names=(\"EVI\", \"NDVI\")):\n",
    "    \"\"\"\n",
    "    X_array: np.ndarray with shape (n_samples, seq_length, n_channels)\n",
    "    selected_features: dict like selected_features_top_150, with key 'value'\n",
    "    channel_names: names for each channel (must match n_channels)\n",
    "    \"\"\"\n",
    "    n_samples, seq_length, n_channels = X_array.shape\n",
    "    assert n_channels == len(channel_names), \"channel_names must match last dim of X_array\"\n",
    "\n",
    "    dfs = []\n",
    "    for ch_idx, ch_name in enumerate(channel_names):\n",
    "        df = pd.DataFrame(X_array[:, :, ch_idx])   # shape: (sample, timestep)\n",
    "        df[\"id\"] = df.index\n",
    "        df_long = df.melt(id_vars=\"id\", var_name=\"time\", value_name=\"value\")\n",
    "        df_long[\"kind\"] = ch_name\n",
    "        dfs.append(df_long)\n",
    "\n",
    "    df_long_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Use the same feature config for each kind (EVI, NDVI)\n",
    "    fc_params_per_kind = {ch: selected_features[\"value\"] for ch in channel_names}\n",
    "\n",
    "    extracted = extract_features(\n",
    "        df_long_all,\n",
    "        column_id=\"id\",\n",
    "        column_sort=\"time\",\n",
    "        column_kind=\"kind\",\n",
    "        column_value=\"value\",\n",
    "        chunksize=2_000,\n",
    "        n_jobs=40,\n",
    "        kind_to_fc_parameters=fc_params_per_kind,\n",
    "    )\n",
    "    impute(extracted)\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63298c-51bf-470d-8572-3bbe749dda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE EXTRACTION, feature\n",
    "# Feature configuration - Define this early so it's available for feature extraction\n",
    "selected_features_small = {'value': {'minimum': None,\n",
    "  'quantile': [{'q': 0.1}, {'q': 0.2}, {'q': 0.3}],\n",
    "  'variation_coefficient': None,\n",
    "  'ar_coefficient': [{'coeff': 1, 'k': 10},\n",
    "   {'coeff': 5, 'k': 10},\n",
    "   {'coeff': 4, 'k': 10}],\n",
    "  'cwt_coefficients': [{'coeff': 1, 'w': 2, 'widths': (2, 5, 10, 20)},\n",
    "   {'coeff': 6, 'w': 2, 'widths': (2, 5, 10, 20)},\n",
    "   {'coeff': 7, 'w': 2, 'widths': (2, 5, 10, 20)},\n",
    "   {'coeff': 5, 'w': 2, 'widths': (2, 5, 10, 20)},\n",
    "   {'coeff': 3, 'w': 2, 'widths': (2, 5, 10, 20)}],\n",
    "  'energy_ratio_by_chunks': [{'num_segments': 10, 'segment_focus': 3},\n",
    "   {'num_segments': 10, 'segment_focus': 5},\n",
    "   {'num_segments': 10, 'segment_focus': 9},\n",
    "   {'num_segments': 10, 'segment_focus': 7},\n",
    "   {'num_segments': 10, 'segment_focus': 6}],\n",
    "  'fft_coefficient': [{'attr': 'real', 'coeff': 2},\n",
    "   {'attr': 'imag', 'coeff': 36},\n",
    "   {'attr': 'abs', 'coeff': 2},\n",
    "   {'attr': 'real', 'coeff': 5},\n",
    "   {'attr': 'angle', 'coeff': 13},\n",
    "   {'attr': 'real', 'coeff': 10},\n",
    "   {'attr': 'angle', 'coeff': 5},\n",
    "   {'attr': 'abs', 'coeff': 0},\n",
    "   {'attr': 'abs', 'coeff': 3},\n",
    "   {'attr': 'angle', 'coeff': 4},\n",
    "   {'attr': 'imag', 'coeff': 35},\n",
    "   {'attr': 'imag', 'coeff': 5},\n",
    "   {'attr': 'imag', 'coeff': 4},\n",
    "   {'attr': 'angle', 'coeff': 23},\n",
    "   {'attr': 'imag', 'coeff': 2}],\n",
    "  'change_quantiles': [{'f_agg': 'mean', 'isabs': True, 'qh': 0.6, 'ql': 0.0},\n",
    "   {'f_agg': 'var', 'isabs': False, 'qh': 0.8, 'ql': 0.0},\n",
    "   {'f_agg': 'mean', 'isabs': True, 'qh': 0.8, 'ql': 0.0},\n",
    "   {'f_agg': 'var', 'isabs': False, 'qh': 0.6, 'ql': 0.0},\n",
    "   {'f_agg': 'mean', 'isabs': True, 'qh': 1.0, 'ql': 0.0},\n",
    "   {'f_agg': 'var', 'isabs': False, 'qh': 0.8, 'ql': 0.4},\n",
    "   {'f_agg': 'var', 'isabs': False, 'qh': 1.0, 'ql': 0.0}],\n",
    "  'benford_correlation': None,\n",
    "  'spkt_welch_density': [{'coeff': 5}],\n",
    "  'mean': None,\n",
    "  'partial_autocorrelation': [{'lag': 3}],\n",
    "  'number_cwt_peaks': [{'n': 1}],\n",
    "  'first_location_of_maximum': None,\n",
    "  'cid_ce': [{'normalize': False}],\n",
    "  'agg_linear_trend': [{'attr': 'intercept', 'chunk_len': 5, 'f_agg': 'min'},\n",
    "   {'attr': 'slope', 'chunk_len': 50, 'f_agg': 'max'},\n",
    "   {'attr': 'intercept', 'chunk_len': 50, 'f_agg': 'mean'}]}}\n",
    "\n",
    "print(\"Feature configuration loaded successfully\")\n",
    "print(f\"Number of feature types: {len(selected_features_small['value'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f29d7-d2a2-4cbe-af51-063892f650a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018487d-a11d-4e6a-8ac2-21877370f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_features_small = get_selected_ts_features_multi(\n",
    "    ds_train.X.values, selected_features_small, channel_names=(\"EVI\", \"NDVI\")\n",
    ")\n",
    "\n",
    "ds_train[\"X_features_small\"] = ((\"sample\", \"features_big\"), X_features_small.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64681f-4b49-4f3e-8417-39c2c5c86cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
