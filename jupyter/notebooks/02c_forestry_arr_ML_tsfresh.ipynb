{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9327f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2ccb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gcsfs in /opt/venv/lib/python3.12/site-packages (2025.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/venv/lib/python3.12/site-packages (from gcsfs) (3.13.2)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/venv/lib/python3.12/site-packages (from gcsfs) (5.1.1)\n",
      "Requirement already satisfied: fsspec==2025.10.0 in /opt/venv/lib/python3.12/site-packages (from gcsfs) (2025.10.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/venv/lib/python3.12/site-packages (from gcsfs) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/venv/lib/python3.12/site-packages (from gcsfs) (1.2.3)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/venv/lib/python3.12/site-packages (from gcsfs) (2.14.0)\n",
      "Requirement already satisfied: requests in /opt/venv/lib/python3.12/site-packages (from gcsfs) (2.31.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (3.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/venv/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/venv/lib/python3.12/site-packages (from google-auth>=1.2->gcsfs) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/venv/lib/python3.12/site-packages (from google-auth>=1.2->gcsfs) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/venv/lib/python3.12/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs) (0.5.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/venv/lib/python3.12/site-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/venv/lib/python3.12/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/venv/lib/python3.12/site-packages (from requests->gcsfs) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/venv/lib/python3.12/site-packages (from requests->gcsfs) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.12/site-packages (from requests->gcsfs) (2023.11.17)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/venv/lib/python3.12/site-packages (from google-cloud-storage->gcsfs) (2.15.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/venv/lib/python3.12/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/venv/lib/python3.12/site-packages (from google-cloud-storage->gcsfs) (2.7.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/venv/lib/python3.12/site-packages (from google-cloud-storage->gcsfs) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (4.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdc9b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simplified zarr saving functions loaded!\n",
      "\n",
      "Key simplifications:\n",
      "  - No complex auto-detection\n",
      "  - Always uses compute=True (let dask handle parallelism)\n",
      "  - Simple, reliable, focuses on parallelism\n",
      "  - Works with both lazy and in-memory arrays\n"
     ]
    }
   ],
   "source": [
    "# SIMPLIFIED EFFICIENT ZARR SAVING\n",
    "# Focus: Proper parallelism, simple and reliable\n",
    "# Removed complex auto-detection that might cause issues\n",
    "\n",
    "import os\n",
    "import time\n",
    "import xarray as xr\n",
    "from numcodecs import Blosc\n",
    "import gcsfs\n",
    "\n",
    "# Re-use a global filesystem client when possible\n",
    "gcs = gcsfs.GCSFileSystem(project=os.getenv(\"GOOGLE_CLOUD_PROJECT\"), token='/usr/src/app/user_id.json')\n",
    "# Initialize GCS filesystem\n",
    "fs = gcs # same same\n",
    "\n",
    "def save_dataset_efficient_zarr(\n",
    "    ds,\n",
    "    zarr_path,\n",
    "    chunk_sizes=None,\n",
    "    compression='lz4',\n",
    "    compression_level=1,\n",
    "    overwrite=True,\n",
    "    consolidated=True,\n",
    "    storage='auto',\n",
    "    gcs_project=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified zarr saving ‚Äì focuses on reliable parallelism.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray.Dataset\n",
    "        Dataset to save (lazy dask arrays or in-memory).\n",
    "    zarr_path : str\n",
    "        Destination path or GCS URI (e.g. gs://bucket/path.zarr).\n",
    "    chunk_sizes : dict, optional\n",
    "        Chunk sizes per dimension (e.g. {'time': 20, 'x': 256, 'y': 256}).\n",
    "    compression : {'lz4','blosc','zstd',None} or dict\n",
    "        Built-in compressor choice or explicit encoding dict.\n",
    "    compression_level : int\n",
    "        Compression level (1 fastest, 9 best compression).\n",
    "    overwrite : bool\n",
    "        Overwrite existing zarr store.\n",
    "    consolidated : bool\n",
    "        Create consolidated metadata (recommended).\n",
    "    storage : {'auto','local','gcs'}\n",
    "        Force storage backend or infer from path when 'auto'.\n",
    "    gcs_project : str, optional\n",
    "        Explicit GCP project for a fresh filesystem client.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The zarr_path that was written.\n",
    "    \"\"\"\n",
    "    def _format_size(num_bytes: int) -> str:\n",
    "        size_mb = num_bytes / (1024 * 1024)\n",
    "        size_gb = size_mb / 1024\n",
    "        return f\"{size_gb:.2f} GB\" if size_gb >= 1 else f\"{size_mb:.2f} MB\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    storage = storage.lower()\n",
    "    if storage == 'auto':\n",
    "        storage = 'gcs' if zarr_path.startswith('gs://') else 'local'\n",
    "    if storage not in {'local', 'gcs'}:\n",
    "        raise ValueError(\"storage must be one of {'auto', 'local', 'gcs'}\")\n",
    "\n",
    "    fs = None\n",
    "    if storage == 'gcs':\n",
    "        fs = gcs if gcs_project is None else gcsfs.GCSFileSystem(project=gcs_project)\n",
    "    else:\n",
    "        zarr_dir = os.path.dirname(zarr_path) if os.path.dirname(zarr_path) else '.'\n",
    "        if zarr_dir and not os.path.exists(zarr_dir):\n",
    "            os.makedirs(zarr_dir, exist_ok=True)\n",
    "\n",
    "    # Handle overwrite\n",
    "    if storage == 'gcs':\n",
    "        if fs.exists(zarr_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(\n",
    "                    f\"Zarr store already exists on GCS: {zarr_path}\\n\"\n",
    "                    \"Set overwrite=True to replace it.\"\n",
    "                )\n",
    "            print(f\"üóëÔ∏è  Removing existing GCS zarr store: {zarr_path}\")\n",
    "            fs.rm(zarr_path, recursive=True)\n",
    "    else:\n",
    "        if os.path.exists(zarr_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(\n",
    "                    f\"Zarr store already exists: {zarr_path}\\n\"\n",
    "                    \"Set overwrite=True to replace it.\"\n",
    "                )\n",
    "            import shutil\n",
    "            print(f\"üóëÔ∏è  Removing existing zarr store: {zarr_path}\")\n",
    "            shutil.rmtree(zarr_path)\n",
    "\n",
    "    # Default chunk sizes\n",
    "    if chunk_sizes is None:\n",
    "        chunk_sizes = {}\n",
    "        dims = ds.dims\n",
    "        if 'time' in dims:\n",
    "            chunk_sizes['time'] = min(20, dims['time'])\n",
    "        if 'x' in dims:\n",
    "            chunk_sizes['x'] = min(256, dims['x'])\n",
    "        if 'y' in dims:\n",
    "            chunk_sizes['y'] = min(256, dims['y'])\n",
    "        for dim_name, dim_len in dims.items():\n",
    "            chunk_sizes.setdefault(dim_name, min(100, dim_len))\n",
    "\n",
    "    print(f\"üì¶ Saving to zarr: {zarr_path}\")\n",
    "    print(f\"   Dimensions: {dict(ds.dims)}\")\n",
    "    print(f\"   Chunks: {chunk_sizes}\")\n",
    "    print(f\"   Compression: {compression} (level {compression_level})\")\n",
    "    print(f\"   Storage: {storage}\")\n",
    "\n",
    "    # Prepare compression\n",
    "    if compression == 'lz4':\n",
    "        compressor = Blosc(cname='lz4', clevel=compression_level, shuffle=Blosc.SHUFFLE, blocksize=0)\n",
    "        encoding = {var: {'compressor': compressor} for var in ds.data_vars}\n",
    "    elif compression == 'blosc':\n",
    "        compressor = Blosc(cname='blosclz', clevel=compression_level, shuffle=Blosc.SHUFFLE, blocksize=0)\n",
    "        encoding = {var: {'compressor': compressor} for var in ds.data_vars}\n",
    "    elif compression == 'zstd':\n",
    "        compressor = Blosc(cname='zstd', clevel=compression_level, shuffle=Blosc.SHUFFLE, blocksize=0)\n",
    "        encoding = {var: {'compressor': compressor} for var in ds.data_vars}\n",
    "    elif compression is None:\n",
    "        encoding = {}\n",
    "    else:\n",
    "        encoding = compression  # assume dict supplied\n",
    "\n",
    "    # Chunk and save\n",
    "    ds_chunked = ds.chunk(chunk_sizes)\n",
    "    print(\"üíæ Writing to zarr (with automatic parallelism)...\")\n",
    "\n",
    "    store = fs.get_mapper(zarr_path) if storage == 'gcs' else zarr_path\n",
    "    try:\n",
    "        from dask.diagnostics import ProgressBar\n",
    "        with ProgressBar():\n",
    "            ds_chunked.to_zarr(\n",
    "                store,\n",
    "                mode='w',\n",
    "                encoding=encoding,\n",
    "                consolidated=consolidated,\n",
    "                compute=True,\n",
    "                zarr_version=2,  # ADD THIS LINE\n",
    "            )\n",
    "    except ImportError:\n",
    "        ds_chunked.to_zarr(\n",
    "            store,\n",
    "            mode='w',\n",
    "            encoding=encoding,\n",
    "            consolidated=consolidated,\n",
    "            compute=True,\n",
    "            zarr_version=2,  # ADD THIS LINE\n",
    "        )\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Size reporting\n",
    "    total_size = None\n",
    "    if storage == 'gcs':\n",
    "        try:\n",
    "            size_info = fs.du(zarr_path)\n",
    "            if isinstance(size_info, dict):\n",
    "                total_size = sum(size_info.values())\n",
    "            elif isinstance(size_info, (int, float)):\n",
    "                total_size = size_info\n",
    "        except Exception as exc:\n",
    "            print(f\"‚ö†Ô∏è  Could not compute GCS store size: {exc}\")\n",
    "    else:\n",
    "        if os.path.exists(zarr_path):\n",
    "            total_size = 0\n",
    "            for dirpath, _, filenames in os.walk(zarr_path):\n",
    "                for f in filenames:\n",
    "                    fp = os.path.join(dirpath, f)\n",
    "                    total_size += os.path.getsize(fp)\n",
    "\n",
    "    if total_size is not None:\n",
    "        size_str = _format_size(total_size)\n",
    "        write_speed = total_size / elapsed / (1024 * 1024)\n",
    "        print(\"‚úÖ Dataset saved successfully!\")\n",
    "        print(f\"   Store size: {size_str}\")\n",
    "        print(f\"   Time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "        print(f\"   Write speed: {write_speed:.1f} MB/s\")\n",
    "        print(f\"   Path: {zarr_path}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Dataset saved successfully! (size unavailable)\")\n",
    "        print(f\"   Time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "        print(f\"   Path: {zarr_path}\")\n",
    "\n",
    "    return zarr_path\n",
    "\n",
    "\n",
    "def load_dataset_zarr(zarr_path, consolidated=True, storage='auto', gcs_project=None):\n",
    "    \"\"\"\n",
    "    Load a dataset from a zarr store located locally or on GCS.\n",
    "    \"\"\"\n",
    "    storage = storage.lower()\n",
    "    if storage == 'auto':\n",
    "        storage = 'gcs' if zarr_path.startswith('gs://') else 'local'\n",
    "    if storage not in {'local', 'gcs'}:\n",
    "        raise ValueError(\"storage must be one of {'auto', 'local', 'gcs'}\")\n",
    "\n",
    "    if storage == 'gcs':\n",
    "        fs = gcs if gcs_project is None else gcsfs.GCSFileSystem(project=gcs_project)\n",
    "        if not fs.exists(zarr_path):\n",
    "            raise FileNotFoundError(f\"Zarr store not found on GCS: {zarr_path}\")\n",
    "        mapper = fs.get_mapper(zarr_path)\n",
    "        print(f\"üìÇ Loading dataset from GCS zarr: {zarr_path}\")\n",
    "        ds = xr.open_zarr(mapper, consolidated=consolidated)\n",
    "    else:\n",
    "        if not os.path.exists(zarr_path):\n",
    "            raise FileNotFoundError(f\"Zarr store not found: {zarr_path}\")\n",
    "        print(f\"üìÇ Loading dataset from zarr: {zarr_path}\")\n",
    "        ds = xr.open_zarr(zarr_path, consolidated=consolidated)\n",
    "\n",
    "    print(f\"‚úÖ Dataset loaded: {dict(ds.dims)}\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "print(\"‚úÖ Simplified zarr saving functions loaded!\")\n",
    "print(\"\\nKey simplifications:\")\n",
    "print(\"  - No complex auto-detection\")\n",
    "print(\"  - Always uses compute=True (let dask handle parallelism)\")\n",
    "print(\"  - Simple, reliable, focuses on parallelism\")\n",
    "print(\"  - Works with both lazy and in-memory arrays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c3f0df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading dataset from GCS zarr: gs://remote_sensing_saas/01-korindo/timeseries_zarr/ds_resampled.zarr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded: {'time': 81, 'x': 4489, 'y': 3213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33/3039169824.py:218: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"‚úÖ Dataset loaded: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"‚ñ∫\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"‚ñº\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 9GB\n",
       "Dimensions:   (time: 81, x: 4489, y: 3213)\n",
       "Coordinates:\n",
       "    image_id  (time) &lt;U17 6kB dask.array&lt;chunksize=(40,), meta=np.ndarray&gt;\n",
       "  * time      (time) datetime64[ns] 648B 2018-02-15 2018-05-15 ... 2025-08-15\n",
       "  * x         (x) float64 36kB 5.786e+05 5.786e+05 ... 6.235e+05 6.235e+05\n",
       "  * y         (y) float64 26kB 9.949e+06 9.949e+06 ... 9.982e+06 9.982e+06\n",
       "Data variables:\n",
       "    EVI       (time, x, y) float32 5GB dask.array&lt;chunksize=(40, 1024, 1024), meta=np.ndarray&gt;\n",
       "    NDVI      (time, x, y) float32 5GB dask.array&lt;chunksize=(40, 1024, 1024), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    crs:      EPSG:32749</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-29716d37-b17a-4e5e-a370-07d76a9bb23a' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-29716d37-b17a-4e5e-a370-07d76a9bb23a' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 81</li><li><span class='xr-has-index'>x</span>: 4489</li><li><span class='xr-has-index'>y</span>: 3213</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-8b867fba-2036-4d73-a32d-c9ceef790c5c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-8b867fba-2036-4d73-a32d-c9ceef790c5c' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>image_id</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>&lt;U17</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(40,), meta=np.ndarray&gt;</div><input id='attrs-23e2545c-b1e0-4a61-81a1-d513620f21b7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-23e2545c-b1e0-4a61-81a1-d513620f21b7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-69d7b865-31fd-4a40-b1b7-45ec9764ac2e' class='xr-var-data-in' type='checkbox'><label for='data-69d7b865-31fd-4a40-b1b7-45ec9764ac2e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 5.38 kiB </td>\n",
       "                        <td> 2.66 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (81,) </td>\n",
       "                        <td> (40,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 3 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> <U17 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"76\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"26\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"59\" y1=\"0\" x2=\"59\" y2=\"26\" />\n",
       "  <line x1=\"118\" y1=\"0\" x2=\"118\" y2=\"26\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,26.449828939817746 0.0,26.449828939817746\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"46.449829\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >81</text>\n",
       "  <text x=\"140.000000\" y=\"13.224914\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,13.224914)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2018-02-15 ... 2025-08-15</div><input id='attrs-dd4c8a5b-a32f-460c-b2d5-7bde59b64f3c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-dd4c8a5b-a32f-460c-b2d5-7bde59b64f3c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c4a8a724-d81e-4c0a-9b8b-149b8d8b3b9e' class='xr-var-data-in' type='checkbox'><label for='data-c4a8a724-d81e-4c0a-9b8b-149b8d8b3b9e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2018-02-15T00:00:00.000000000&#x27;, &#x27;2018-05-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-12-15T00:00:00.000000000&#x27;, &#x27;2019-01-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-02-15T00:00:00.000000000&#x27;, &#x27;2019-03-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-04-15T00:00:00.000000000&#x27;, &#x27;2019-05-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-06-15T00:00:00.000000000&#x27;, &#x27;2019-07-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-08-15T00:00:00.000000000&#x27;, &#x27;2019-09-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-10-15T00:00:00.000000000&#x27;, &#x27;2019-11-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-12-15T00:00:00.000000000&#x27;, &#x27;2020-01-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-02-15T00:00:00.000000000&#x27;, &#x27;2020-03-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-04-15T00:00:00.000000000&#x27;, &#x27;2020-05-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-06-15T00:00:00.000000000&#x27;, &#x27;2020-07-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-08-15T00:00:00.000000000&#x27;, &#x27;2020-09-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-15T00:00:00.000000000&#x27;, &#x27;2020-11-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-12-15T00:00:00.000000000&#x27;, &#x27;2021-01-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-02-15T00:00:00.000000000&#x27;, &#x27;2021-03-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-04-15T00:00:00.000000000&#x27;, &#x27;2021-05-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-06-15T00:00:00.000000000&#x27;, &#x27;2021-07-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-08-15T00:00:00.000000000&#x27;, &#x27;2021-09-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-10-15T00:00:00.000000000&#x27;, &#x27;2021-11-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-12-15T00:00:00.000000000&#x27;, &#x27;2022-01-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-02-15T00:00:00.000000000&#x27;, &#x27;2022-03-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-04-15T00:00:00.000000000&#x27;, &#x27;2022-05-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-06-15T00:00:00.000000000&#x27;, &#x27;2022-07-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-08-15T00:00:00.000000000&#x27;, &#x27;2022-09-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-10-15T00:00:00.000000000&#x27;, &#x27;2022-11-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-12-15T00:00:00.000000000&#x27;, &#x27;2023-02-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2023-03-15T00:00:00.000000000&#x27;, &#x27;2023-04-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2023-05-15T00:00:00.000000000&#x27;, &#x27;2023-06-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2023-07-15T00:00:00.000000000&#x27;, &#x27;2023-08-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2023-09-15T00:00:00.000000000&#x27;, &#x27;2023-10-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2023-11-15T00:00:00.000000000&#x27;, &#x27;2023-12-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-01-15T00:00:00.000000000&#x27;, &#x27;2024-02-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-03-15T00:00:00.000000000&#x27;, &#x27;2024-04-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-05-15T00:00:00.000000000&#x27;, &#x27;2024-06-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-07-15T00:00:00.000000000&#x27;, &#x27;2024-08-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-09-15T00:00:00.000000000&#x27;, &#x27;2024-10-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-11-15T00:00:00.000000000&#x27;, &#x27;2024-12-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2025-01-15T00:00:00.000000000&#x27;, &#x27;2025-03-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2025-04-15T00:00:00.000000000&#x27;, &#x27;2025-05-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2025-06-15T00:00:00.000000000&#x27;, &#x27;2025-07-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2025-08-15T00:00:00.000000000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>5.786e+05 5.786e+05 ... 6.235e+05</div><input id='attrs-8090e094-b6b3-403a-b48e-f4a8e5771bd6' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8090e094-b6b3-403a-b48e-f4a8e5771bd6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-74e8b51a-1bcd-4278-845c-9abf6ad0a5c0' class='xr-var-data-in' type='checkbox'><label for='data-74e8b51a-1bcd-4278-845c-9abf6ad0a5c0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([578619.536409, 578629.536409, 578639.536409, ..., 623479.536409,\n",
       "       623489.536409, 623499.536409])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>9.949e+06 9.949e+06 ... 9.982e+06</div><input id='attrs-54750e8c-a5f1-469f-a416-983ef2a878fa' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-54750e8c-a5f1-469f-a416-983ef2a878fa' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-84c9c4ed-4a8d-44ef-8dcc-b6aa2b842da0' class='xr-var-data-in' type='checkbox'><label for='data-84c9c4ed-4a8d-44ef-8dcc-b6aa2b842da0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([9949396.122267, 9949406.122267, 9949416.122267, ..., 9981496.122267,\n",
       "       9981506.122267, 9981516.122267])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-4bf678df-d2e5-40c5-bd62-4241839ee297' class='xr-section-summary-in' type='checkbox'  checked><label for='section-4bf678df-d2e5-40c5-bd62-4241839ee297' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>EVI</span></div><div class='xr-var-dims'>(time, x, y)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(40, 1024, 1024), meta=np.ndarray&gt;</div><input id='attrs-d7ae4d00-576d-42ce-875b-bd95eeae6e31' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d7ae4d00-576d-42ce-875b-bd95eeae6e31' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cf20c275-3394-476e-914b-06d9205ec111' class='xr-var-data-in' type='checkbox'><label for='data-cf20c275-3394-476e-914b-06d9205ec111' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs :</span></dt><dd>EPSG:32749</dd><dt><span>crs_transform :</span></dt><dd>[8.983152841195215e-05, 0, 111.70640389554661, 0, -8.983152841195215e-05, -0.16717647437464295]</dd><dt><span>data_type :</span></dt><dd>{&#x27;type&#x27;: &#x27;PixelType&#x27;, &#x27;precision&#x27;: &#x27;double&#x27;}</dd><dt><span>id :</span></dt><dd>EVI</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.35 GiB </td>\n",
       "                        <td> 160.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (81, 4489, 3213) </td>\n",
       "                        <td> (40, 1024, 1024) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 60 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"162\" height=\"186\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"27\" x2=\"26\" y2=\"44\" />\n",
       "  <line x1=\"10\" y1=\"54\" x2=\"26\" y2=\"71\" />\n",
       "  <line x1=\"10\" y1=\"82\" x2=\"26\" y2=\"98\" />\n",
       "  <line x1=\"10\" y1=\"109\" x2=\"26\" y2=\"126\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"128\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.739551270052704,16.739551270052704 26.739551270052704,136.73955127005271 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"95\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"104\" y2=\"8\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"112\" y2=\"16\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"112\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"54\" y2=\"16\" />\n",
       "  <line x1=\"64\" y1=\"0\" x2=\"81\" y2=\"16\" />\n",
       "  <line x1=\"92\" y1=\"0\" x2=\"108\" y2=\"16\" />\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"112\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 95.88995321897973,0.0 112.62950448903243,16.739551270052704 26.739551270052704,16.739551270052704\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"112\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"44\" x2=\"112\" y2=\"44\" />\n",
       "  <line x1=\"26\" y1=\"71\" x2=\"112\" y2=\"71\" />\n",
       "  <line x1=\"26\" y1=\"98\" x2=\"112\" y2=\"98\" />\n",
       "  <line x1=\"26\" y1=\"126\" x2=\"112\" y2=\"126\" />\n",
       "  <line x1=\"26\" y1=\"136\" x2=\"112\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"54\" y1=\"16\" x2=\"54\" y2=\"136\" />\n",
       "  <line x1=\"81\" y1=\"16\" x2=\"81\" y2=\"136\" />\n",
       "  <line x1=\"108\" y1=\"16\" x2=\"108\" y2=\"136\" />\n",
       "  <line x1=\"112\" y1=\"16\" x2=\"112\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.739551270052704,16.739551270052704 112.62950448903243,16.739551270052704 112.62950448903243,136.73955127005271 26.739551270052704,136.73955127005271\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"69.684528\" y=\"156.739551\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3213</text>\n",
       "  <text x=\"132.629504\" y=\"76.739551\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,132.629504,76.739551)\">4489</text>\n",
       "  <text x=\"8.369776\" y=\"148.369776\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.369776,148.369776)\">81</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>NDVI</span></div><div class='xr-var-dims'>(time, x, y)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(40, 1024, 1024), meta=np.ndarray&gt;</div><input id='attrs-4afe5e16-ce85-49cb-9cf3-14d6ed44c44e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4afe5e16-ce85-49cb-9cf3-14d6ed44c44e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fa526c58-9371-4041-b9cd-65577db5a3a5' class='xr-var-data-in' type='checkbox'><label for='data-fa526c58-9371-4041-b9cd-65577db5a3a5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs :</span></dt><dd>EPSG:32749</dd><dt><span>crs_transform :</span></dt><dd>[8.983152841195215e-05, 0, 111.70640389554661, 0, -8.983152841195215e-05, -0.16717647437464295]</dd><dt><span>data_type :</span></dt><dd>{&#x27;type&#x27;: &#x27;PixelType&#x27;, &#x27;precision&#x27;: &#x27;double&#x27;}</dd><dt><span>id :</span></dt><dd>NDVI</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 4.35 GiB </td>\n",
       "                        <td> 160.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (81, 4489, 3213) </td>\n",
       "                        <td> (40, 1024, 1024) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 60 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"162\" height=\"186\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"27\" x2=\"26\" y2=\"44\" />\n",
       "  <line x1=\"10\" y1=\"54\" x2=\"26\" y2=\"71\" />\n",
       "  <line x1=\"10\" y1=\"82\" x2=\"26\" y2=\"98\" />\n",
       "  <line x1=\"10\" y1=\"109\" x2=\"26\" y2=\"126\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"128\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.739551270052704,16.739551270052704 26.739551270052704,136.73955127005271 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"95\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"104\" y2=\"8\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"112\" y2=\"16\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"112\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"54\" y2=\"16\" />\n",
       "  <line x1=\"64\" y1=\"0\" x2=\"81\" y2=\"16\" />\n",
       "  <line x1=\"92\" y1=\"0\" x2=\"108\" y2=\"16\" />\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"112\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 95.88995321897973,0.0 112.62950448903243,16.739551270052704 26.739551270052704,16.739551270052704\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"112\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"44\" x2=\"112\" y2=\"44\" />\n",
       "  <line x1=\"26\" y1=\"71\" x2=\"112\" y2=\"71\" />\n",
       "  <line x1=\"26\" y1=\"98\" x2=\"112\" y2=\"98\" />\n",
       "  <line x1=\"26\" y1=\"126\" x2=\"112\" y2=\"126\" />\n",
       "  <line x1=\"26\" y1=\"136\" x2=\"112\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"54\" y1=\"16\" x2=\"54\" y2=\"136\" />\n",
       "  <line x1=\"81\" y1=\"16\" x2=\"81\" y2=\"136\" />\n",
       "  <line x1=\"108\" y1=\"16\" x2=\"108\" y2=\"136\" />\n",
       "  <line x1=\"112\" y1=\"16\" x2=\"112\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.739551270052704,16.739551270052704 112.62950448903243,16.739551270052704 112.62950448903243,136.73955127005271 26.739551270052704,136.73955127005271\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"69.684528\" y=\"156.739551\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3213</text>\n",
       "  <text x=\"132.629504\" y=\"76.739551\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,132.629504,76.739551)\">4489</text>\n",
       "  <text x=\"8.369776\" y=\"148.369776\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.369776,148.369776)\">81</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-30a6c122-c4a8-4481-afc1-daf6e2d9a0b6' class='xr-section-summary-in' type='checkbox'  ><label for='section-30a6c122-c4a8-4481-afc1-daf6e2d9a0b6' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-ebf0ff35-7d83-4273-9bc0-2de44b912358' class='xr-index-data-in' type='checkbox'/><label for='index-ebf0ff35-7d83-4273-9bc0-2de44b912358' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2018-02-15&#x27;, &#x27;2018-05-15&#x27;, &#x27;2018-12-15&#x27;, &#x27;2019-01-15&#x27;,\n",
       "               &#x27;2019-02-15&#x27;, &#x27;2019-03-15&#x27;, &#x27;2019-04-15&#x27;, &#x27;2019-05-15&#x27;,\n",
       "               &#x27;2019-06-15&#x27;, &#x27;2019-07-15&#x27;, &#x27;2019-08-15&#x27;, &#x27;2019-09-15&#x27;,\n",
       "               &#x27;2019-10-15&#x27;, &#x27;2019-11-15&#x27;, &#x27;2019-12-15&#x27;, &#x27;2020-01-15&#x27;,\n",
       "               &#x27;2020-02-15&#x27;, &#x27;2020-03-15&#x27;, &#x27;2020-04-15&#x27;, &#x27;2020-05-15&#x27;,\n",
       "               &#x27;2020-06-15&#x27;, &#x27;2020-07-15&#x27;, &#x27;2020-08-15&#x27;, &#x27;2020-09-15&#x27;,\n",
       "               &#x27;2020-10-15&#x27;, &#x27;2020-11-15&#x27;, &#x27;2020-12-15&#x27;, &#x27;2021-01-15&#x27;,\n",
       "               &#x27;2021-02-15&#x27;, &#x27;2021-03-15&#x27;, &#x27;2021-04-15&#x27;, &#x27;2021-05-15&#x27;,\n",
       "               &#x27;2021-06-15&#x27;, &#x27;2021-07-15&#x27;, &#x27;2021-08-15&#x27;, &#x27;2021-09-15&#x27;,\n",
       "               &#x27;2021-10-15&#x27;, &#x27;2021-11-15&#x27;, &#x27;2021-12-15&#x27;, &#x27;2022-01-15&#x27;,\n",
       "               &#x27;2022-02-15&#x27;, &#x27;2022-03-15&#x27;, &#x27;2022-04-15&#x27;, &#x27;2022-05-15&#x27;,\n",
       "               &#x27;2022-06-15&#x27;, &#x27;2022-07-15&#x27;, &#x27;2022-08-15&#x27;, &#x27;2022-09-15&#x27;,\n",
       "               &#x27;2022-10-15&#x27;, &#x27;2022-11-15&#x27;, &#x27;2022-12-15&#x27;, &#x27;2023-02-15&#x27;,\n",
       "               &#x27;2023-03-15&#x27;, &#x27;2023-04-15&#x27;, &#x27;2023-05-15&#x27;, &#x27;2023-06-15&#x27;,\n",
       "               &#x27;2023-07-15&#x27;, &#x27;2023-08-15&#x27;, &#x27;2023-09-15&#x27;, &#x27;2023-10-15&#x27;,\n",
       "               &#x27;2023-11-15&#x27;, &#x27;2023-12-15&#x27;, &#x27;2024-01-15&#x27;, &#x27;2024-02-15&#x27;,\n",
       "               &#x27;2024-03-15&#x27;, &#x27;2024-04-15&#x27;, &#x27;2024-05-15&#x27;, &#x27;2024-06-15&#x27;,\n",
       "               &#x27;2024-07-15&#x27;, &#x27;2024-08-15&#x27;, &#x27;2024-09-15&#x27;, &#x27;2024-10-15&#x27;,\n",
       "               &#x27;2024-11-15&#x27;, &#x27;2024-12-15&#x27;, &#x27;2025-01-15&#x27;, &#x27;2025-03-15&#x27;,\n",
       "               &#x27;2025-04-15&#x27;, &#x27;2025-05-15&#x27;, &#x27;2025-06-15&#x27;, &#x27;2025-07-15&#x27;,\n",
       "               &#x27;2025-08-15&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-af477014-fb1e-4513-92cf-ab273b2d38ab' class='xr-index-data-in' type='checkbox'/><label for='index-af477014-fb1e-4513-92cf-ab273b2d38ab' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([578619.5364090556, 578629.5364090556, 578639.5364090556,\n",
       "       578649.5364090556, 578659.5364090556, 578669.5364090556,\n",
       "       578679.5364090556, 578689.5364090556, 578699.5364090556,\n",
       "       578709.5364090556,\n",
       "       ...\n",
       "       623409.5364090556, 623419.5364090556, 623429.5364090556,\n",
       "       623439.5364090556, 623449.5364090556, 623459.5364090556,\n",
       "       623469.5364090556, 623479.5364090556, 623489.5364090556,\n",
       "       623499.5364090556],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;x&#x27;, length=4489))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>y</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-6d968030-0c87-4fcd-b525-68065ed2423f' class='xr-index-data-in' type='checkbox'/><label for='index-6d968030-0c87-4fcd-b525-68065ed2423f' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([9949396.122266518, 9949406.122266518, 9949416.122266518,\n",
       "       9949426.122266518, 9949436.122266518, 9949446.122266518,\n",
       "       9949456.122266518, 9949466.122266518, 9949476.122266518,\n",
       "       9949486.122266518,\n",
       "       ...\n",
       "       9981426.122266518, 9981436.122266518, 9981446.122266518,\n",
       "       9981456.122266518, 9981466.122266518, 9981476.122266518,\n",
       "       9981486.122266518, 9981496.122266518, 9981506.122266518,\n",
       "       9981516.122266518],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;y&#x27;, length=3213))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-293f9bac-ea8c-4972-8f22-09701e6343cf' class='xr-section-summary-in' type='checkbox'  checked><label for='section-293f9bac-ea8c-4972-8f22-09701e6343cf' class='xr-section-summary' >Attributes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>crs :</span></dt><dd>EPSG:32749</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 9GB\n",
       "Dimensions:   (time: 81, x: 4489, y: 3213)\n",
       "Coordinates:\n",
       "    image_id  (time) <U17 6kB dask.array<chunksize=(40,), meta=np.ndarray>\n",
       "  * time      (time) datetime64[ns] 648B 2018-02-15 2018-05-15 ... 2025-08-15\n",
       "  * x         (x) float64 36kB 5.786e+05 5.786e+05 ... 6.235e+05 6.235e+05\n",
       "  * y         (y) float64 26kB 9.949e+06 9.949e+06 ... 9.982e+06 9.982e+06\n",
       "Data variables:\n",
       "    EVI       (time, x, y) float32 5GB dask.array<chunksize=(40, 1024, 1024), meta=np.ndarray>\n",
       "    NDVI      (time, x, y) float32 5GB dask.array<chunksize=(40, 1024, 1024), meta=np.ndarray>\n",
       "Attributes:\n",
       "    crs:      EPSG:32749"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_path = os.getenv('GCS_ZARR_DIR') + '/ds_resampled.zarr'\n",
    "# zarr_path = 'data/ds_resampled.zarr'\n",
    "# storage = 'local'\n",
    "storage = 'gcs'\n",
    "\n",
    "ds_resampled = load_dataset_zarr(zarr_path, storage=storage)\n",
    "ds_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355374aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 9GB\n",
      "Dimensions:   (time: 81, x: 4489, y: 3213)\n",
      "Coordinates:\n",
      "    image_id  (time) <U17 6kB dask.array<chunksize=(40,), meta=np.ndarray>\n",
      "  * time      (time) datetime64[ns] 648B 2018-02-15 2018-05-15 ... 2025-08-15\n",
      "  * x         (x) float64 36kB 5.786e+05 5.786e+05 ... 6.235e+05 6.235e+05\n",
      "  * y         (y) float64 26kB 9.949e+06 9.949e+06 ... 9.982e+06 9.982e+06\n",
      "Data variables:\n",
      "    EVI       (time, x, y) float32 5GB dask.array<chunksize=(40, 1024, 1024), meta=np.ndarray>\n",
      "    NDVI      (time, x, y) float32 5GB dask.array<chunksize=(40, 1024, 1024), meta=np.ndarray>\n",
      "Attributes:\n",
      "    crs:      EPSG:32749\n"
     ]
    }
   ],
   "source": [
    "print(ds_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2209e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs_ds = ds_resampled.attrs.get('crs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc02f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crs_ds = 'EPSG:32749'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b02bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape:  (78, 71)\n"
     ]
    }
   ],
   "source": [
    "#### DS TRAIN CHECK RESAMPLING\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "path_training = '00_input/training_shp/'\n",
    "\n",
    "layers = [shp for shp in os.listdir(path_training) if shp.endswith('.shp') and shp.startswith('sample')]\n",
    "gcs_path = 'gs://remote_sensing_saas/01-korindo/sample_tsfresh/20251112_training_gdf_col_filtered.parquet'\n",
    "\n",
    "use_parquet_training = True\n",
    "\n",
    "if use_parquet_training != True:\n",
    "    gdf_list = []\n",
    "\n",
    "    for lyr in layers:\n",
    "        print(lyr)\n",
    "        gdf = gpd.read_file(os.path.join(path_training,lyr))\n",
    "        gdf['layer'] = lyr.replace('.shp', '')\n",
    "        print(gdf.crs)\n",
    "        print('check size, if too big, you need to recheck: ',gdf.shape)\n",
    "        gdf_utm = gdf.to_crs(crs_ds)       \n",
    "        print('transforming to crs: ',gdf_utm.crs)\n",
    "\n",
    "        # data dissolve to clean, if the data is too big, use ArcGIS or QGIS instead\n",
    "        list_columns_time = [i for i in gdf_utm.columns if i.startswith('t_') and not i.endswith('D')]\n",
    "        gdf_utm = gdf_utm.dissolve(by=['layer']+list_columns_time)\n",
    "        gdf_utm = gdf_utm.reset_index()\n",
    "        gdf_list.append(gdf_utm)\n",
    "\n",
    "    training_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))\n",
    "    # training_gdf = gpd.read_file('00_input/training_shp/sample_1.shp')\n",
    "    # training_gdf.head()\n",
    "    # training_gdf.head()\n",
    "\n",
    "    # training_gdf.crs\n",
    "\n",
    "    # training_gdf.geometry.head()\n",
    "    # training_gdf.columns\n",
    "\n",
    "    list_columns_time = [i for i in training_gdf.columns if i.startswith('t_') and not i.endswith('D')]\n",
    "    list_columns_time = list(sorted(list_columns_time))\n",
    "    # list_columns_time\n",
    "\n",
    "    columns_filter = ['layer'] + list_columns_time + ['geometry']\n",
    "\n",
    "    training_gdf_col_filtered = training_gdf[columns_filter]\n",
    "    # training_gdf_col_filtered = training_gdf_col_filtered.dissolve(by=['layer']+list_columns_time)\n",
    "    # training_gdf_col_filtered = training_gdf_col_filtered.reset_index()\n",
    "    # training_gdf_col_filtered.head()\n",
    "    # training_gdf_col_filtered.plot()\n",
    "\n",
    "    # Save as GeoParquet (BEST option)\n",
    "    gcs_path = gcs_path    \n",
    "    training_gdf_col_filtered.to_parquet(gcs_path, filesystem=fs, compression='snappy')\n",
    "\n",
    "else:\n",
    "    training_gdf_col_filtered = gpd.read_parquet(gcs_path, filesystem=fs)\n",
    "print('final shape: ',training_gdf_col_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a3ce277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in training_gdf.columns:\n",
    "#     print(i)\n",
    "# # training_gdf_col_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "688271e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>t_201603</th>\n",
       "      <th>t_201606</th>\n",
       "      <th>t_201609</th>\n",
       "      <th>t_201612</th>\n",
       "      <th>t_201703</th>\n",
       "      <th>t_201706</th>\n",
       "      <th>t_201709</th>\n",
       "      <th>t_201712</th>\n",
       "      <th>t_201803</th>\n",
       "      <th>...</th>\n",
       "      <th>t_202501</th>\n",
       "      <th>t_202502</th>\n",
       "      <th>t_202503</th>\n",
       "      <th>t_202504</th>\n",
       "      <th>t_202505</th>\n",
       "      <th>t_202506</th>\n",
       "      <th>t_202507</th>\n",
       "      <th>t_202508</th>\n",
       "      <th>t_202509</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((592439.970 9950624.446, 592472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((591963.540 9951127.666, 591985.528 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((592062.841 9950226.187, 592071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((590310.884 9951179.496, 590319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((590565.026 9950696.784, 590564.841 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      layer  t_201603  t_201606  t_201609  t_201612  t_201703  t_201706  \\\n",
       "0  sample_2       NaN       0.0       0.0       0.0       0.0       0.0   \n",
       "1  sample_2       NaN       0.0       0.0       0.0       0.0       0.0   \n",
       "2  sample_2       NaN       0.0       0.0       0.0       0.0       0.0   \n",
       "3  sample_2       NaN       0.0       0.0       0.0       0.0       0.0   \n",
       "4  sample_2       NaN       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   t_201709  t_201712  t_201803  ...  t_202501  t_202502  t_202503  t_202504  \\\n",
       "0       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   t_202505  t_202506  t_202507  t_202508  t_202509  \\\n",
       "0       0.0       0.0       0.0       0.0       NaN   \n",
       "1       0.0       0.0       0.0       0.0       NaN   \n",
       "2       0.0       0.0       0.0       0.0       NaN   \n",
       "3       0.0       0.0       0.0       0.0       NaN   \n",
       "4       0.0       0.0       0.0       0.0       NaN   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((592439.970 9950624.446, 592472...  \n",
       "1  POLYGON ((591963.540 9951127.666, 591985.528 9...  \n",
       "2  MULTIPOLYGON (((592062.841 9950226.187, 592071...  \n",
       "3  MULTIPOLYGON (((590310.884 9951179.496, 590319...  \n",
       "4  POLYGON ((590565.026 9950696.784, 590564.841 9...  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_gdf_col_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3da5d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TAKES TIME FOR THIS GEE since we will upload data to GEE\n",
    "# # import os\n",
    "# import ee\n",
    "# # import geemap.foliumap as geemap\n",
    "\n",
    "# service_account = os.getenv('SERVICE_ACCOUNT')\n",
    "# key_path = '/usr/src/app/user_id.json'\n",
    "\n",
    "# credentials = ee.ServiceAccountCredentials(service_account, key_path)\n",
    "# ee.Initialize(credentials)\n",
    "\n",
    "# # gdf_wgs84 = training_gdf_col_filtered.to_crs(epsg=4326)\n",
    "\n",
    "# # centroid = gdf_wgs84.geometry.centroid.unary_union.centroid\n",
    "# # m = geemap.Map(center=[centroid.y, centroid.x], zoom=9, ee_initialize=False)\n",
    "# # m.add_gdf(gdf_wgs84, layer_name=\"training_gdf_col_filtered\")\n",
    "# # m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b35bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_gdf_col_filtered.to_file(\"00_input/training_shp/training_gdf_col_filtered_4326.shp\") # local non gcs parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3730fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##no need to plot for the second time if the data is the same\n",
    "# Quick plot (very fast)\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# training_gdf_col_filtered.plot(figsize=(12, 10), markersize=0.5)\n",
    "# plt.title(f\"Training Data ({len(training_gdf_col_filtered):,} features)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8accf650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## lets load in wmts from gdf, its LOADING TOO SLOW TO LOAD AS THE GDF IF LOAD FROM WFS ee.featureCollection\n",
    "# gdf_wgs84 = training_gdf_col_filtered.to_crs(epsg=4326)\n",
    "\n",
    "# #### wmts loading\n",
    "# from wfs_manager import WFSManager\n",
    "# import geemap\n",
    "\n",
    "# fc = geemap.gdf_to_ee(gdf_wgs84)\n",
    "\n",
    "# wfs = WFSManager(fastapi_url=\"http://fastapi:8000\", wfs_base_url=\"http://localhost:8001\")\n",
    "# wfs.addLayer(fc, \"Training data collected\")\n",
    "# wfs.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7309f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_gdf_col_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6bd9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "use_existing_df_long = True\n",
    "gcs_path_df_long = 'gs://remote_sensing_saas/01-korindo/sample_tsfresh/20251112_df_long.parquet'\n",
    "\n",
    "if use_existing_df_long != True:\n",
    "    # training_gdf_col_filtered\n",
    "\n",
    "    t_cols = [col for col in training_gdf_col_filtered.columns if col.startswith('t_')]\n",
    "\n",
    "    # Melt the dataframe with geometry as id_var\n",
    "    df_long = pd.melt(\n",
    "        training_gdf_col_filtered, \n",
    "        id_vars=['layer','geometry'],\n",
    "        value_vars=t_cols,\n",
    "        var_name='time_period',\n",
    "        value_name='value'\n",
    "    )\n",
    "\n",
    "    # Set geometry as index\n",
    "    # df_long = df_long.set_index('geometry')\n",
    "\n",
    "    print(f\"Original shape: {training_gdf_col_filtered.shape}\")\n",
    "    print(f\"Long format shape: {df_long.shape}\")\n",
    "    print(f\"Time columns found: {len(t_cols)}\")\n",
    "    # print(f\"\\nFirst few rows:\")\n",
    "    # df_long.head()\n",
    "    # df_long.layer.unique()\n",
    "\n",
    "    # df_long.reset_index(inplace=True)\n",
    "    # df_long.head()\n",
    "\n",
    "    ## reformating the column (date)\n",
    "    df_long = df_long.rename(columns={'value': 'type'})\n",
    "    df_long['date'] = df_long['time_period'].str[2:].astype(int)\n",
    "    # df_long.head()\n",
    "\n",
    "    # type(df_long)\n",
    "\n",
    "    training_gdf = df_long.copy()\n",
    "    # Remove multipolygons\n",
    "    training_gdf = training_gdf.explode(index_parts=False)\n",
    "    print(training_gdf.crs)\n",
    "\n",
    "    ##### conversion\n",
    "    # Drop rows where 'type' is NA\n",
    "    training_gdf = training_gdf.copy()\n",
    "    training_gdf = training_gdf.dropna(subset=['type'])\n",
    "    training_gdf['date'] = pd.to_datetime(training_gdf['date'], format='%Y%m')\n",
    "\n",
    "    # add year columnt\n",
    "    training_gdf['year'] = training_gdf['date'].dt.year\n",
    "\n",
    "    # convert column 'type' from string to int\n",
    "    training_gdf['type'] = training_gdf['type'].astype(int)\n",
    "    print('shape of training_gdf after drop NA:', training_gdf.shape)\n",
    "    \n",
    "    training_gdf.to_parquet(gcs_path_df_long, filesystem=fs, compression='snappy')\n",
    "\n",
    "else:\n",
    "    training_gdf = gpd.read_parquet(gcs_path_df_long, filesystem=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12df05c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>time_period</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131213</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>POLYGON ((584180.083 9968585.299, 584157.366 9...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131214</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>POLYGON ((583509.394 9968409.259, 583519.222 9...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131215</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>POLYGON ((585435.167 9969315.480, 585465.247 9...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131216</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>POLYGON ((585162.142 9969842.168, 585157.111 9...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131217</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>POLYGON ((584315.521 9969957.392, 584316.046 9...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           layer time_period  type       date  \\\n",
       "131213  sample_3    t_201603     1 2016-03-01   \n",
       "131214  sample_3    t_201603     1 2016-03-01   \n",
       "131215  sample_3    t_201603     1 2016-03-01   \n",
       "131216  sample_3    t_201603     1 2016-03-01   \n",
       "131217  sample_3    t_201603     1 2016-03-01   \n",
       "\n",
       "                                                 geometry  year  \n",
       "131213  POLYGON ((584180.083 9968585.299, 584157.366 9...  2016  \n",
       "131214  POLYGON ((583509.394 9968409.259, 583519.222 9...  2016  \n",
       "131215  POLYGON ((585435.167 9969315.480, 585465.247 9...  2016  \n",
       "131216  POLYGON ((585162.142 9969842.168, 585157.111 9...  2016  \n",
       "131217  POLYGON ((584315.521 9969957.392, 584316.046 9...  2016  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1b0a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = 't_202509'\n",
    "# test[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e0c103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_gdf['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "762d5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_gdf['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b958f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to minimize the ram usage, we can delete the ram usage to variables\n",
    "# del training_gdf_col_filtered\n",
    "# del df_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4380aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
    "# ============================================================================\n",
    "from multiprocessing import Pool  # For parallel processing (running multiple tasks at once)\n",
    "from functools import partial     # For creating functions with pre-filled arguments\n",
    "import xarray as xr              # For working with multi-dimensional arrays (like netCDF, zarr)\n",
    "import numpy as np               # For numerical operations\n",
    "import pandas as pd              # For data manipulation\n",
    "import multiprocessing as mp     # For getting CPU count\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DEFINE FUNCTION TO CREATE MASK FOR ONE DATE-LAYER COMBINATION\n",
    "# ============================================================================\n",
    "def get_raster_mask_with_layer(date_layer_tuple, ds, gdf_1_dissolved, gdf_0_dissolved):\n",
    "    \"\"\"\n",
    "    Creates a raster mask from vector polygons for a specific date and layer.\n",
    "    \n",
    "    What this does:\n",
    "    - Takes polygons (shapes) from your training data\n",
    "    - Converts them into a grid (raster) matching your satellite data\n",
    "    - Assigns value 1 for tree areas, 0 for non-tree areas, NaN for no data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    date_layer_tuple : tuple (date, layer)\n",
    "        The specific date and layer (e.g., 'sample_1') to process\n",
    "    ds : xarray.Dataset\n",
    "        Your satellite dataset (to match grid size and coordinates)\n",
    "    gdf_1_dissolved : GeoDataFrame\n",
    "        Pre-processed polygons for tree areas (type=1)\n",
    "    gdf_0_dissolved : GeoDataFrame\n",
    "        Pre-processed polygons for non-tree areas (type=0)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    mask_da : xarray.DataArray\n",
    "        A grid with 1s (trees), 0s (non-trees), and NaN (no label)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import rasterio.features  # For converting vector shapes to raster grids\n",
    "    from affine import Affine  # For coordinate transformations\n",
    "    \n",
    "    # --- Unpack the date and layer from input tuple ---\n",
    "    date, layer = date_layer_tuple\n",
    "    \n",
    "    # --- Filter polygons for this specific date and layer ---\n",
    "    # MultiIndex means the index has multiple levels (date AND layer)\n",
    "    # We need to match BOTH date and layer to get the right polygons\n",
    "    trees = gdf_1_dissolved[\n",
    "        (gdf_1_dissolved.index.get_level_values('date') == date) & \n",
    "        (gdf_1_dissolved.index.get_level_values('layer') == layer)\n",
    "    ]\n",
    "    non_trees = gdf_0_dissolved[\n",
    "        (gdf_0_dissolved.index.get_level_values('date') == date) & \n",
    "        (gdf_0_dissolved.index.get_level_values('layer') == layer)\n",
    "    ]\n",
    "    \n",
    "    # --- Prepare features for rasterization ---\n",
    "    # Features are tuples of (geometry, value)\n",
    "    # All tree geometries get value 1, all non-tree geometries get value 0\n",
    "    features = [(geom, 1) for geom in trees.geometry] + \\\n",
    "               [(geom, 0) for geom in non_trees.geometry]\n",
    "    \n",
    "    # --- Get the grid dimensions from your satellite dataset ---\n",
    "    x = ds.coords['x'].values  # X coordinates (longitude-like)\n",
    "    y = ds.coords['y'].values  # Y coordinates (latitude-like)\n",
    "    \n",
    "    # --- Handle case where there are no training labels for this date-layer ---\n",
    "    if not features:\n",
    "        # Create an empty grid filled with NaN (no data)\n",
    "        mask_raster = np.full((len(y), len(x)), np.nan, dtype=\"float32\")\n",
    "    else:\n",
    "        # --- Calculate pixel resolution (size of each grid cell) ---\n",
    "        # Resolution is the distance between adjacent pixels\n",
    "        res_x = (x[-1] - x[0]) / (len(x) - 1)  # Horizontal resolution\n",
    "        res_y = (y[0] - y[-1]) / (len(y) - 1)  # Vertical resolution\n",
    "        \n",
    "        # --- Create affine transformation ---\n",
    "        # This tells rasterio how to map real-world coordinates to pixel indices\n",
    "        # Translation: moves origin to top-left corner of top-left pixel\n",
    "        # Scale: defines pixel size (negative y because images start from top)\n",
    "        transform = Affine.translation(x[0] - res_x / 2, y[0] + res_y / 2) * \\\n",
    "                   Affine.scale(res_x, -res_y)\n",
    "        \n",
    "        # --- Rasterize: convert vector polygons to raster grid ---\n",
    "        mask_raster = rasterio.features.rasterize(\n",
    "            features,              # List of (geometry, value) tuples\n",
    "            out_shape=(len(y), len(x)),  # Output grid size\n",
    "            transform=transform,   # Coordinate transformation\n",
    "            fill=np.nan,          # Value for pixels outside all polygons\n",
    "            dtype=\"float32\"       # Data type (float to allow NaN)\n",
    "        )\n",
    "    \n",
    "    # --- Wrap the numpy array in an xarray DataArray ---\n",
    "    # This adds coordinate labels and metadata to the grid\n",
    "    mask_da = xr.DataArray(\n",
    "        mask_raster,              # The actual data (2D grid)\n",
    "        dims=(\"y\", \"x\"),         # Dimension names\n",
    "        coords={\n",
    "            \"y\": ds.coords[\"y\"],  # Y coordinate values\n",
    "            \"x\": ds.coords[\"x\"],  # X coordinate values\n",
    "            \"date\": date,         # Date as scalar coordinate\n",
    "            \"layer\": layer        # Layer as scalar coordinate\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    return mask_da\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: DEFINE FUNCTION FOR PARALLEL PROCESSING\n",
    "# ============================================================================\n",
    "def parallel_rasterize_with_layer(date_layer_combinations, ds, gdf_1_dissolved, \n",
    "                                   gdf_0_dissolved, n_workers=4):\n",
    "    \"\"\"\n",
    "    Process multiple date-layer combinations in parallel (at the same time).\n",
    "    \n",
    "    Why parallel?\n",
    "    - Instead of processing dates one by one (slow), we process multiple at once\n",
    "    - Uses multiple CPU cores to speed up computation\n",
    "    - Example: 4 workers = ~4x faster for independent tasks\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    date_layer_combinations : list of tuples\n",
    "        All (date, layer) pairs to process\n",
    "    ds : xarray.Dataset\n",
    "        Your satellite dataset\n",
    "    gdf_1_dissolved, gdf_0_dissolved : GeoDataFrames\n",
    "        Pre-processed training polygons\n",
    "    n_workers : int\n",
    "        Number of parallel processes (usually = number of CPU cores)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    masks : list of xarray.DataArray\n",
    "        One mask for each date-layer combination\n",
    "    \"\"\"\n",
    "    # --- Create a partial function with pre-filled arguments ---\n",
    "    # This is needed because pool.map() can only pass one argument\n",
    "    # We \"freeze\" ds, gdf_1_dissolved, gdf_0_dissolved so only date_layer changes\n",
    "    func = partial(\n",
    "        get_raster_mask_with_layer, \n",
    "        ds=ds, \n",
    "        gdf_1_dissolved=gdf_1_dissolved,\n",
    "        gdf_0_dissolved=gdf_0_dissolved\n",
    "    )\n",
    "    \n",
    "    # --- Create a pool of worker processes and run in parallel ---\n",
    "    with Pool(n_workers) as pool:\n",
    "        masks = pool.map(func, date_layer_combinations)\n",
    "    \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c39cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 142 date-layer combinations\n",
      "Example: [(Timestamp('2016-03-01 00:00:00'), 'sample_3'), (Timestamp('2016-06-01 00:00:00'), 'sample_2'), (Timestamp('2016-06-01 00:00:00'), 'sample_3')]\n",
      "Using 2.0 parallel workers\n",
      "Dissolving geometries by date and layer...\n",
      "  Trees (type=1): 142 date-layer groups\n",
      "  Non-trees (type=0): 140 date-layer groups\n",
      "Creating masks in parallel...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# --- Run parallel processing to create all masks ---\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating masks in parallel...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_rasterize_with_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_layer_combos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# All date-layer combinations\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Your satellite dataset\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdf_1_dissolved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Pre-dissolved tree polygons\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdf_0_dissolved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Pre-dissolved non-tree polygons\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_workers\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Number of parallel processes\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Created \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(masks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m masks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Each mask shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 150\u001b[0m, in \u001b[0;36mparallel_rasterize_with_layer\u001b[0;34m(date_layer_combinations, ds, gdf_1_dissolved, gdf_0_dissolved, n_workers)\u001b[0m\n\u001b[1;32m    142\u001b[0m func \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    143\u001b[0m     get_raster_mask_with_layer, \n\u001b[1;32m    144\u001b[0m     ds\u001b[38;5;241m=\u001b[39mds, \n\u001b[1;32m    145\u001b[0m     gdf_1_dissolved\u001b[38;5;241m=\u001b[39mgdf_1_dissolved,\n\u001b[1;32m    146\u001b[0m     gdf_0_dissolved\u001b[38;5;241m=\u001b[39mgdf_0_dissolved\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# --- Create a pool of worker processes and run in parallel ---\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_workers\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m    151\u001b[0m     masks \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(func, date_layer_combinations)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m masks\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/context.py:119\u001b[0m, in \u001b[0;36mBaseContext.Pool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Returns a process pool object'''\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:215\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes \u001b[38;5;241m=\u001b[39m processes\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repopulate_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:306\u001b[0m, in \u001b[0;36mPool._repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repopulate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repopulate_pool_static\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inqueue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:321\u001b[0m, in \u001b[0;36mPool._repopulate_pool_static\u001b[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repopulate_pool_static\u001b[39m(ctx, Process, processes, pool, inqueue,\n\u001b[1;32m    316\u001b[0m                             outqueue, initializer, initargs,\n\u001b[1;32m    317\u001b[0m                             maxtasksperchild, wrap_exception):\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Bring the number of pool processes up to the specified number,\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    for use after reaping workers which have exited.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    322\u001b[0m         w \u001b[38;5;241m=\u001b[39m Process(ctx, target\u001b[38;5;241m=\u001b[39mworker,\n\u001b[1;32m    323\u001b[0m                     args\u001b[38;5;241m=\u001b[39m(inqueue, outqueue,\n\u001b[1;32m    324\u001b[0m                           initializer,\n\u001b[1;32m    325\u001b[0m                           initargs, maxtasksperchild,\n\u001b[1;32m    326\u001b[0m                           wrap_exception))\n\u001b[1;32m    327\u001b[0m         w\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoolWorker\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: PREPARE DATA AND RUN PARALLEL PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "# --- Get all unique date-layer combinations from training data ---\n",
    "# drop_duplicates() removes repeated combinations\n",
    "# itertuples() converts each row to a tuple (date, layer)\n",
    "date_layer_combos = list(\n",
    "    training_gdf[['date', 'layer']]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "print(f\"Processing {len(date_layer_combos)} date-layer combinations\")\n",
    "print(f\"Example: {date_layer_combos[:3]}\")  # Show first 3 combinations\n",
    "\n",
    "# --- Determine number of parallel workers ---\n",
    "# Use all available CPU cores, but not more than we have combinations\n",
    "n_workers = int(min(mp.cpu_count(), len(date_layer_combos))/2) #lets half\n",
    "print(f\"Using {n_workers} parallel workers\")\n",
    "\n",
    "# --- Pre-process: Dissolve geometries by date AND layer ---\n",
    "# dissolve() merges overlapping/touching polygons into single shapes\n",
    "# Why? Faster rasterization and avoids duplicate pixels\n",
    "# This is done ONCE here instead of inside the loop (huge speed-up!)\n",
    "# print(\"Dissolving geometries by date and layer...\")\n",
    "# gdf_1_dissolved = training_gdf[training_gdf['type'] == 1].dissolve(by=['date', 'layer'])\n",
    "# gdf_0_dissolved = training_gdf[training_gdf['type'] == 0].dissolve(by=['date', 'layer'])\n",
    "print('using dissolved gdf, dissolve is done in arcgis separately because its too slow in geopandas')\n",
    "\n",
    "print(f\"  Trees (type=1): {len(gdf_1_dissolved)} date-layer groups\")\n",
    "print(f\"  Non-trees (type=0): {len(gdf_0_dissolved)} date-layer groups\")\n",
    "\n",
    "# --- Run parallel processing to create all masks ---\n",
    "print(\"Creating masks in parallel...\")\n",
    "masks = parallel_rasterize_with_layer(\n",
    "    date_layer_combos,     # All date-layer combinations\n",
    "    ds_resampled,         # Your satellite dataset\n",
    "    gdf_1_dissolved,      # Pre-dissolved tree polygons\n",
    "    gdf_0_dissolved,      # Pre-dissolved non-tree polygons\n",
    "    n_workers=n_workers   # Number of parallel processes\n",
    ")\n",
    "\n",
    "print(f\"‚úì Created {len(masks)} masks\")\n",
    "print(f\"  Each mask shape: {masks[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae82b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: ORGANIZE MASKS INTO A 3D DATASET WITH LAYER AS COORDINATE\n",
    "# ============================================================================\n",
    "def merge_all_masks_3d(masks):\n",
    "    \"\"\"\n",
    "    Combine individual masks into a single 3D dataset.\n",
    "    \n",
    "    What this does:\n",
    "    - Takes a list of 2D masks (y, x)\n",
    "    - Organizes them into a 3D array (date, y, x)\n",
    "    - Keeps 'layer' (plot) as a coordinate label for each date\n",
    "    \n",
    "    Result: Each date-layer combination is a separate time point\n",
    "    Example: date=2020-01-01 with layer='sample_1', date=2020-01-01 with layer='sample_2'\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    masks : list of xarray.DataArray\n",
    "        Individual masks from parallel processing\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    gt : xarray.Dataset\n",
    "        3D dataset (date, y, x) with layer/plot as coordinate\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # --- Extract date and layer from each mask ---\n",
    "    # We'll create unique date-layer combinations as separate time points\n",
    "    dates_with_layer = []\n",
    "    layers = []\n",
    "    \n",
    "    for mask in masks:\n",
    "        date = pd.Timestamp(mask.coords['date'].values)\n",
    "        layer = mask.coords['layer'].values\n",
    "        dates_with_layer.append(date)\n",
    "        layers.append(layer)\n",
    "    \n",
    "    print(f\"Organizing into 3D dataset:\")\n",
    "    print(f\"  {len(masks)} total date-layer combinations\")\n",
    "    print(f\"  Will be stored as {len(masks)} time points\")\n",
    "    \n",
    "    # --- Stack all masks along a new dimension ---\n",
    "    # Each mask becomes one time slice\n",
    "    # Remove the old scalar coordinates first to avoid conflicts\n",
    "    masks_cleaned = []\n",
    "    for mask in masks:\n",
    "        # Keep only the spatial data, drop scalar coordinates temporarily\n",
    "        mask_clean = mask.drop_vars(['date', 'layer'], errors='ignore')\n",
    "        masks_cleaned.append(mask_clean)\n",
    "    \n",
    "    # Concatenate all masks along a new 'date' dimension\n",
    "    combined = xr.concat(masks_cleaned, dim='date')\n",
    "    \n",
    "    # --- Add date and layer as coordinates ---\n",
    "    # 'date' is the dimension (time axis)\n",
    "    # 'layer' (or 'plot') is a coordinate that varies along date\n",
    "    combined = combined.assign_coords({\n",
    "        'date': dates_with_layer,  # Actual dates\n",
    "        'plot': ('date', layers)   # Layer/plot name for each date\n",
    "    })\n",
    "    \n",
    "    # --- Create Dataset with proper structure ---\n",
    "    gt = xr.Dataset(\n",
    "        {\n",
    "            'ground_truth': combined\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # --- Add metadata attributes ---\n",
    "    gt.attrs['description'] = 'Ground truth training masks'\n",
    "    gt.attrs['values'] = '0=non-tree, 1=tree, NaN=no label'\n",
    "    gt['ground_truth'].attrs['units'] = 'category'\n",
    "    gt.coords['plot'].attrs['description'] = 'Training plot/layer identifier'\n",
    "    \n",
    "    # --- Show summary ---\n",
    "    unique_plots = list(set(layers))\n",
    "    print(f\"  {len(unique_plots)} unique plots: {unique_plots}\")\n",
    "    print(f\"  Final dimensions: date={len(dates_with_layer)}, y={len(gt.y)}, x={len(gt.x)}\")\n",
    "    \n",
    "    return gt\n",
    "\n",
    "\n",
    "# --- Run the merge function ---\n",
    "print(\"\\nMerging masks into 3D dataset...\")\n",
    "gt = merge_all_masks_3d(masks)\n",
    "\n",
    "# --- Display the result ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL DATASET:\")\n",
    "print(\"=\"*60)\n",
    "print(gt)\n",
    "print(\"\\nCoordinates:\")\n",
    "print(f\"  date: {len(gt.date)} time points\")\n",
    "print(f\"  plot: {len(gt.plot)} labels (one per date)\")\n",
    "print(f\"  x: {len(gt.x)} pixels\")\n",
    "print(f\"  y: {len(gt.y)} pixels\")\n",
    "\n",
    "# --- Examples of accessing the data ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE USAGE:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example 1: Select by date (may have multiple plots for same date)\n",
    "print(\"\\n1. Get all data for a specific date:\")\n",
    "print(\"   gt.sel(date='2025-01-01')\")\n",
    "print(\"   Note: May return multiple entries if multiple plots have this date\")\n",
    "\n",
    "# Example 2: Filter by plot name\n",
    "print(\"\\n2. Get all dates for a specific plot:\")\n",
    "print(\"   gt.where(gt.plot == 'sample_1', drop=True)\")\n",
    "\n",
    "# Example 3: Select specific date AND plot\n",
    "print(\"\\n3. Get data for specific date and plot:\")\n",
    "print(\"   gt.sel(date=gt.date[gt.plot == 'sample_1'])\")\n",
    "\n",
    "# Example 4: Get plot name for each date\n",
    "print(\"\\n4. See which plot each date corresponds to:\")\n",
    "print(\"   gt.plot.values\")\n",
    "\n",
    "# Example 5: Group by plot\n",
    "print(\"\\n5. Work with one plot at a time:\")\n",
    "print(\"   for plot_name in gt.plot.values:\")\n",
    "print(\"       plot_data = gt.where(gt.plot == plot_name, drop=True)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: CREATE VALIDITY MASK\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VALIDITY MASK:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create validity mask: pixels that have non-NaN values for all dates\n",
    "# We check across all date-layer combinations\n",
    "gt['valid'] = gt['ground_truth'].notnull().all(dim='date')\n",
    "\n",
    "print(\"‚úì Added 'valid' variable showing pixels with labels for ALL date-layer combinations\")\n",
    "print(f\"  Shape: {gt['valid'].shape}\")\n",
    "print(f\"  Valid pixels: {gt['valid'].sum().values:,}\")\n",
    "\n",
    "# If you want validity per plot, you can compute it separately:\n",
    "print(\"\\nValid pixels per plot:\")\n",
    "for plot_name in sorted(set(gt.plot.values)):\n",
    "    # Get all dates for this plot\n",
    "    plot_mask = gt.where(gt.plot == plot_name, drop=True)\n",
    "    n_valid = plot_mask['ground_truth'].notnull().all(dim='date').sum().values\n",
    "    n_dates = (gt.plot == plot_name).sum().values\n",
    "    print(f\"  {plot_name}: {n_valid:,} pixels (across {n_dates} dates)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTION: SELECT BY DATE AND PLOT\n",
    "# ============================================================================\n",
    "def select_by_date_and_plot(gt, date, plot_name):\n",
    "    \"\"\"\n",
    "    Helper function to easily select data for a specific date and plot.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gt : xarray.Dataset\n",
    "        Your ground truth dataset\n",
    "    date : str or pd.Timestamp\n",
    "        The date to select\n",
    "    plot_name : str\n",
    "        The plot/layer name\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data : xarray.Dataset\n",
    "        Subset of data matching the criteria\n",
    "    \"\"\"\n",
    "    date = pd.Timestamp(date)  # Ensure date is in correct format\n",
    "    \n",
    "    # Find indices where both date and plot match\n",
    "    mask = (gt.date == date) & (gt.plot == plot_name)\n",
    "    \n",
    "    if not mask.any():\n",
    "        print(f\"Warning: No data found for date={date} and plot={plot_name}\")\n",
    "        return None\n",
    "    \n",
    "    return gt.sel(date=gt.date[mask])\n",
    "\n",
    "\n",
    "# --- Example usage of helper function ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HELPER FUNCTION EXAMPLE:\")\n",
    "print(\"=\"*60)\n",
    "print(\"# Get data for specific date and plot:\")\n",
    "print(\"result = select_by_date_and_plot(gt, '2025-01-01', 'sample_1')\")\n",
    "print(\"print(result)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96273f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_gdf.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge mask data\n",
    "mask_da = xr.concat(masks, dim='date')\n",
    "\n",
    "# create mask that will containt True if all pixles in year range have valid value (ie. not nan)\n",
    "mask = mask_da.notnull().all(dim='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataset \n",
    "gt = mask_da.to_dataset(name='ground_truth')\n",
    "gt['valid'] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets check RAM usage\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4abe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### if RAM too much consumed, we can delete object\n",
    "del mask_da\n",
    "del masks\n",
    "del gdf_1_dissolved\n",
    "del gdf_0_dissolved\n",
    "del training_gdf\n",
    "\n",
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# If you're using Dask (which you are with zarr data), clear the cache\n",
    "from distributed import Client\n",
    "try:\n",
    "    client = Client.current()\n",
    "    client.restart()  # Restart workers to clear memory\n",
    "except ValueError:\n",
    "    # No distributed client, use local cache clearing\n",
    "    import dask\n",
    "    dask.config.set(scheduler='synchronous')\n",
    "    \n",
    "# Or simply clear local Dask cache\n",
    "try:\n",
    "    from dask.cache import Cache\n",
    "    Cache(2e9).clear()  # Clear cache\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f427fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0281226",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4518b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving the xarray ds -> gt - sample groundtruth to the bucket\n",
    "gcs_path_gt = 'gs://remote_sensing_saas/01-korindo/timeseries_zarr/20251112_gt.zarr'\n",
    "# gt.to_zarr(gcs_path_gt, mode='w', compute=True, consolidated=True,)\n",
    "# Save to GCS\n",
    "save_dataset_efficient_zarr(\n",
    "    gt,\n",
    "    gcs_path_gt,\n",
    "    chunk_sizes={'date':20, 'x':512, 'y':512},\n",
    "    compression='lz4',\n",
    "    compression_level=1,\n",
    "    overwrite=True,\n",
    "    consolidated=True,\n",
    "    storage='gcs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT\n",
    "resampling_freq = 'MS'\n",
    "# gt.date is already datetime, so just convert to pandas Timestamp\n",
    "start_date = pd.Timestamp(gt.date.min().values)\n",
    "cut_off_date = pd.Timestamp(gt.date.max().values)\n",
    "print(f\"Start date: {start_date}\")\n",
    "print(f\"Cut-off date: {cut_off_date}\")\n",
    "cut_off_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_gt_mask(gdf, gt, show=True, save=False)\n",
    "# plot_gt_usable_data(gt, show=True, save=False)\n",
    "\n",
    "# convert yeart in gt from int to datetime\n",
    "# gt['date'] = pd.to_datetime(gt['date'].astype(str),  format='%Y%-m')\n",
    "\n",
    "gt = gt.sortby('date').rename({'date': 'time'})\n",
    "monthly_time = pd.date_range(start_date, cut_off_date, freq=resampling_freq)\n",
    "# This will repeat the value from January 1 throughout the year until the next available time.\n",
    "gt = gt.reindex(time=monthly_time, method='ffill').sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b74fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250508a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(gt.sel(time='2025-9-01').valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02995561",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.sel(time='2025-01-01').valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
