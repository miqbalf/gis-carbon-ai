{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d76aa2",
   "metadata": {},
   "source": [
    "# Forestry ARR Eligibility - GEE AND STAC Approach\n",
    "\n",
    "This notebook demonstrates the STAC-based approach for forestry ARR eligibility analysis when historical Sentinel data is not available from Google Earth Engine.\n",
    "\n",
    "## üì¶ Required Libraries Installation\n",
    "\n",
    "Before running this notebook, install the required libraries:\n",
    "\n",
    "```bash\n",
    "# Core STAC and GEE-xarray integration (REQUIRED)\n",
    "pip install xarray>=2023.1.0 rioxarray>=0.15.0 xee>=0.0.8\n",
    "\n",
    "# STAC client libraries\n",
    "pip install planetary-computer>=0.4.0 pystac-client>=0.7.0 stackstac>=0.4.0\n",
    "\n",
    "# Optional but recommended for better performance\n",
    "pip install dask>=2023.1.0\n",
    "```\n",
    "\n",
    "Or install all at once:\n",
    "```bash\n",
    "pip install xarray rioxarray xee planetary-computer pystac-client stackstac dask\n",
    "```\n",
    "\n",
    "**Note:** `xarray` and `xee` are **required dependencies** - they enable Google Earth Engine integration with xarray for time series processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2207262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê xarray is installed\n",
      "‚≠ê rioxarray is installed\n",
      "‚≠ê xee is installed\n",
      "‚úÖ planetary_computer is installed\n",
      "‚úÖ pystac_client is installed\n",
      "‚úÖ stackstac is installed\n",
      "‚úÖ geopandas is installed\n",
      "‚úÖ geemap is installed\n",
      "\n",
      "‚úÖ All required libraries are installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for STAC processing\n",
    "# Uncomment the line below if libraries are not installed\n",
    "# !pip install xarray rioxarray xee planetary-computer pystac-client stackstac dask\n",
    "\n",
    "# Verify installation - xarray and xee are REQUIRED\n",
    "required_libs = {\n",
    "    'xarray': 'xarray',  # REQUIRED - core dependency\n",
    "    'rioxarray': 'rioxarray',  # REQUIRED - for geospatial raster operations\n",
    "    'xee': 'xee',  # REQUIRED - Google Earth Engine to xarray bridge\n",
    "    'planetary_computer': 'planetary-computer',  # For STAC access\n",
    "    'pystac_client': 'pystac-client',  # For STAC client\n",
    "    'stackstac': 'stackstac',  # For stacking STAC items\n",
    "    'geopandas': 'geopandas',  # Core geospatial library\n",
    "    'geemap': 'geemap'  # Optional - for GEE visualization\n",
    "}\n",
    "\n",
    "critical_libs = ['xarray', 'rioxarray', 'xee']  # Must-have libraries\n",
    "missing_libs = []\n",
    "missing_critical = []\n",
    "\n",
    "for module_name, package_name in required_libs.items():\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        status = \"‚≠ê\" if module_name in critical_libs else \"‚úÖ\"\n",
    "        print(f\"{status} {module_name} is installed\")\n",
    "    except ImportError:\n",
    "        status = \"üö®\" if module_name in critical_libs else \"‚ùå\"\n",
    "        print(f\"{status} {module_name} is MISSING - install with: pip install {package_name}\")\n",
    "        missing_libs.append(package_name)\n",
    "        if module_name in critical_libs:\n",
    "            missing_critical.append(package_name)\n",
    "\n",
    "if missing_critical:\n",
    "    print(f\"\\nüö® CRITICAL: Missing required libraries! Install them with:\")\n",
    "    print(f\"   pip install {' '.join(missing_critical)}\")\n",
    "    raise ImportError(f\"Required libraries missing: {', '.join(missing_critical)}\")\n",
    "elif missing_libs:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing optional libraries. Install them with:\")\n",
    "    print(f\"   pip install {' '.join(missing_libs)}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required libraries are installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33b3607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install xarray rioxarray xee planetary-computer pystac-client stackstac dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03da43e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/gcsfs/core.py:317: UserWarning: GCS project not set - cannot list or create buckets\n",
      "  warnings.warn(\"GCS project not set - cannot list or create buckets\")\n"
     ]
    }
   ],
   "source": [
    "import ee, eemont\n",
    "from forestry_carbon_arr.core import ForestryCarbonARR\n",
    "\n",
    "# Initialize Forestry Carbon ARR system\n",
    "forestry = ForestryCarbonARR(config_path='./00_input/korindo.json')\n",
    "from_gee_version_1_config = forestry.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3208c4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'project': {'name': 'forestry_carbon_project',\n",
       "  'region': 'asia',\n",
       "  'description': 'Forestry Carbon ARR Analysis Project',\n",
       "  'version': '1.0.0'},\n",
       " 'gee': {'project_id': None,\n",
       "  'service_account': None,\n",
       "  'initialize': True,\n",
       "  'max_pixels': 10000000000000.0,\n",
       "  'scale': 30,\n",
       "  'crs': 'EPSG:4326'},\n",
       " 'satellite': {'provider': 'Custom',\n",
       "  'date_range': ['2025-8-1', '2025-8-31'],\n",
       "  'cloud_cover_threshold': 80,\n",
       "  'bands': {'Sentinel': ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'],\n",
       "   'Planet': ['red', 'green', 'blue', 'nir'],\n",
       "   'Landsat': ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']},\n",
       "  'composite_method': 'median',\n",
       "  'mask_clouds': True},\n",
       " 'ml': {'algorithm': 'gbm',\n",
       "  'training_samples': 1000,\n",
       "  'validation_split': 0.2,\n",
       "  'cross_validation': True,\n",
       "  'n_folds': 5,\n",
       "  'random_state': 42,\n",
       "  'hyperparameter_tuning': True},\n",
       " 'fcd': {'method': 'pca',\n",
       "  'thresholds': {'high_forest': 65,\n",
       "   'yrf_forest': 45,\n",
       "   'shrub_grass': 45,\n",
       "   'open_land': 30},\n",
       "  'apply_smoothing': True,\n",
       "  'smoothing_kernel': 3},\n",
       " 'classification': {'classes': {'1': 'forest_trees',\n",
       "   '2': 'shrubland',\n",
       "   '3': 'grassland',\n",
       "   '4': 'openland',\n",
       "   '5': 'waterbody_wet_area',\n",
       "   '6': 'plantation',\n",
       "   '7': 'infrastructure',\n",
       "   '8': 'oil_palm',\n",
       "   '9': 'cropland',\n",
       "   '10': 'waterbody',\n",
       "   '11': 'wetlands',\n",
       "   '12': 'forest_trees_regrowth',\n",
       "   '13': 'historical_treeloss_10years',\n",
       "   '14': 'paddy_irrigated'},\n",
       "  'palette': {'1': '#83ff5a',\n",
       "   '2': '#ffe3b3',\n",
       "   '3': '#ffff33',\n",
       "   '4': '#f89696',\n",
       "   '5': '#1900ff',\n",
       "   '6': '#e6e6fa',\n",
       "   '7': '#FFFFFF',\n",
       "   '8': '#4B0082',\n",
       "   '9': '#8B4513',\n",
       "   '10': '#87CEEB',\n",
       "   '11': '#2F4F4F',\n",
       "   '12': '#ADFF2F',\n",
       "   '13': '#8B0000',\n",
       "   '14': '#DAA520'}},\n",
       " 'output': {'format': 'geotiff',\n",
       "  'compression': 'lzw',\n",
       "  'nodata_value': -9999,\n",
       "  'save_intermediate': True,\n",
       "  'output_directory': './outputs',\n",
       "  'create_visualizations': True,\n",
       "  'export_to_gee': False},\n",
       " 'processing': {'max_workers': 4,\n",
       "  'chunk_size': 1000,\n",
       "  'memory_limit': '8GB',\n",
       "  'use_gpu': False,\n",
       "  'cache_results': True,\n",
       "  'cache_directory': './cache'},\n",
       " 'dependencies': {'gee_forestry_path': None,\n",
       "  'auto_setup': True,\n",
       "  'check_dependencies': True,\n",
       "  'install_missing': False},\n",
       " 'logging': {'level': 'INFO',\n",
       "  'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
       "  'file': None,\n",
       "  'console': True},\n",
       " 'validation': {'validate_aoi': True,\n",
       "  'validate_training_data': True,\n",
       "  'validate_outputs': True,\n",
       "  'strict_mode': False},\n",
       " 'pca_scaling': 1,\n",
       " 'tileScale': 2,\n",
       " 'AOI_path': './00_input/aoi_korindo.shp',\n",
       " 'OID_field_name': 'id',\n",
       " 'algo_ml_selected': 'gbm',\n",
       " 'input_training': 'gs://remote_sensing_saas/01-korindo/pl_sampling/sampling_korindo.shp',\n",
       " 'label_column': 'type',\n",
       " 'project_name': 'korindo',\n",
       " 'super_pixel_size': 17,\n",
       " 'pixel_number': 3,\n",
       " 'year_start_loss': 14,\n",
       " 'tree_cover_forest': 30,\n",
       " 'band_name_image': 'Class',\n",
       " 'valid_pixel_threshold': 20,\n",
       " 'crs_input': 'EPSG:4326',\n",
       " 'output_crs': 'EPSG:32749',\n",
       " 'IsThermal': False,\n",
       " 'fcd_selected': 21,\n",
       " 'ndwi_hi_sentinel': 0.05,\n",
       " 'ndwi_hi_landsat': 0.1,\n",
       " 'ndwi_hi_planet': -0.2,\n",
       " 'resolution_satellite': 10,\n",
       " 'url_satellite_cloud': 'https://planetarycomputer.microsoft.com/api/stac/v1',\n",
       " 'collection_mpc': 'sentinel-2-l2a',\n",
       " 'mpc_date_range': ['2014-08-15', '2018-01-31'],\n",
       " 'mpc_zarr_path': 'gs://remote_sensing_saas/01-korindo/timeseries_zarr/sentinel-2-l2a_korindo_2014-08-15_2018-01-31_gee.zarr',\n",
       " 'mpc_zarr_monthly': 'gs://remote_sensing_saas/01-korindo/timeseries_zarr/sentinel-2-l2a_korindo_2014-08-15_2018-01-31_gee_monthly.zarr',\n",
       " 'mpc_monthly_col': 'projects/remote-sensing-476412/assets/korindo_sentinel2_monthly_mpc',\n",
       " 'gee_monthly_col': 'projects/remote-sensing-476412/assets/korindo_sentinel2_monthly',\n",
       " 'assets_satellite': ['B01',\n",
       "  'B02',\n",
       "  'B03',\n",
       "  'B04',\n",
       "  'B05',\n",
       "  'B06',\n",
       "  'B07',\n",
       "  'B08',\n",
       "  'B09',\n",
       "  'B11',\n",
       "  'B12',\n",
       "  'B8A',\n",
       "  'SCL'],\n",
       " 'band_mapping': {'B01': 'coastal',\n",
       "  'B02': 'blue',\n",
       "  'B03': 'green',\n",
       "  'B04': 'red',\n",
       "  'B05': 'redE1',\n",
       "  'B06': 'redE2',\n",
       "  'B07': 'redE3',\n",
       "  'B08': 'nir',\n",
       "  'B09': 'nir2',\n",
       "  'B11': 'swir1',\n",
       "  'B12': 'swir2',\n",
       "  'B8A': 'redE4',\n",
       "  'SCL': 'scl'},\n",
       " 'pl_dir_jul1': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_jul1_fix_8bands_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_jul30': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_jul_30_fix_8bands_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_apr27': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_apr27_20250427-cog_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_jun8': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_june8_20250608_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_sep21_2024': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_sep_20_21_20240920-21-cog_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_sep3_2024': 'gs://planet-orders-t/korindo/2024-09-03/25ef326f-ac78-4b7a-a71a-0fe25f6fa1b5',\n",
       " 'tsfresh_feature_path': 'gs://remote_sensing_saas/01-korindo/tsfresh_features/tsfresh_features_132576samples_50features_20251125_170042.parquet',\n",
       " 'I_satellite': 'Custom',\n",
       " 'date_start_end': ['2025-8-1', '2025-8-31'],\n",
       " 'open_land': 30,\n",
       " 'shrub_grass': 45,\n",
       " 'yrf_forest': 45,\n",
       " 'high_forest': 65}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_gee_version_1_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c1a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area: (Ha)  145272.7744003245\n"
     ]
    }
   ],
   "source": [
    "### START TO WORK WITH STAC, check availability of historical sentinel data\n",
    "import json\n",
    "import geopandas as gpd\n",
    "config = from_gee_version_1_config\n",
    "\n",
    "#INPUT VARIABLES\n",
    "is_export_image_to_drive = False\n",
    "\n",
    "aoi_gpd = gpd.GeoDataFrame.from_file(config[\"AOI_path\"])\n",
    "aoi_gpd = aoi_gpd.to_crs(epsg=int(config['gee'][\"crs\"].split(\":\")[-1])) # satellite crs is epsg code of projected UTM crs\n",
    "if aoi_gpd.crs.to_string() == 'EPSG:4326':\n",
    "    aoi_gpd = aoi_gpd.to_crs(epsg=3857)\n",
    "\n",
    "aoi_ha = aoi_gpd.geometry.area.sum()/10000\n",
    "print('area: (Ha) ', aoi_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f06fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'project': {'name': 'forestry_carbon_project',\n",
       "  'region': 'asia',\n",
       "  'description': 'Forestry Carbon ARR Analysis Project',\n",
       "  'version': '1.0.0'},\n",
       " 'gee': {'project_id': None,\n",
       "  'service_account': None,\n",
       "  'initialize': True,\n",
       "  'max_pixels': 10000000000000.0,\n",
       "  'scale': 30,\n",
       "  'crs': 'EPSG:4326'},\n",
       " 'satellite': {'provider': 'Custom',\n",
       "  'date_range': ['2025-8-1', '2025-8-31'],\n",
       "  'cloud_cover_threshold': 80,\n",
       "  'bands': {'Sentinel': ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'],\n",
       "   'Planet': ['red', 'green', 'blue', 'nir'],\n",
       "   'Landsat': ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']},\n",
       "  'composite_method': 'median',\n",
       "  'mask_clouds': True},\n",
       " 'ml': {'algorithm': 'gbm',\n",
       "  'training_samples': 1000,\n",
       "  'validation_split': 0.2,\n",
       "  'cross_validation': True,\n",
       "  'n_folds': 5,\n",
       "  'random_state': 42,\n",
       "  'hyperparameter_tuning': True},\n",
       " 'fcd': {'method': 'pca',\n",
       "  'thresholds': {'high_forest': 65,\n",
       "   'yrf_forest': 45,\n",
       "   'shrub_grass': 45,\n",
       "   'open_land': 30},\n",
       "  'apply_smoothing': True,\n",
       "  'smoothing_kernel': 3},\n",
       " 'classification': {'classes': {'1': 'forest_trees',\n",
       "   '2': 'shrubland',\n",
       "   '3': 'grassland',\n",
       "   '4': 'openland',\n",
       "   '5': 'waterbody_wet_area',\n",
       "   '6': 'plantation',\n",
       "   '7': 'infrastructure',\n",
       "   '8': 'oil_palm',\n",
       "   '9': 'cropland',\n",
       "   '10': 'waterbody',\n",
       "   '11': 'wetlands',\n",
       "   '12': 'forest_trees_regrowth',\n",
       "   '13': 'historical_treeloss_10years',\n",
       "   '14': 'paddy_irrigated'},\n",
       "  'palette': {'1': '#83ff5a',\n",
       "   '2': '#ffe3b3',\n",
       "   '3': '#ffff33',\n",
       "   '4': '#f89696',\n",
       "   '5': '#1900ff',\n",
       "   '6': '#e6e6fa',\n",
       "   '7': '#FFFFFF',\n",
       "   '8': '#4B0082',\n",
       "   '9': '#8B4513',\n",
       "   '10': '#87CEEB',\n",
       "   '11': '#2F4F4F',\n",
       "   '12': '#ADFF2F',\n",
       "   '13': '#8B0000',\n",
       "   '14': '#DAA520'}},\n",
       " 'output': {'format': 'geotiff',\n",
       "  'compression': 'lzw',\n",
       "  'nodata_value': -9999,\n",
       "  'save_intermediate': True,\n",
       "  'output_directory': './outputs',\n",
       "  'create_visualizations': True,\n",
       "  'export_to_gee': False},\n",
       " 'processing': {'max_workers': 4,\n",
       "  'chunk_size': 1000,\n",
       "  'memory_limit': '8GB',\n",
       "  'use_gpu': False,\n",
       "  'cache_results': True,\n",
       "  'cache_directory': './cache'},\n",
       " 'dependencies': {'gee_forestry_path': None,\n",
       "  'auto_setup': True,\n",
       "  'check_dependencies': True,\n",
       "  'install_missing': False},\n",
       " 'logging': {'level': 'INFO',\n",
       "  'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
       "  'file': None,\n",
       "  'console': True},\n",
       " 'validation': {'validate_aoi': True,\n",
       "  'validate_training_data': True,\n",
       "  'validate_outputs': True,\n",
       "  'strict_mode': False},\n",
       " 'pca_scaling': 1,\n",
       " 'tileScale': 2,\n",
       " 'AOI_path': './00_input/aoi_korindo.shp',\n",
       " 'OID_field_name': 'id',\n",
       " 'algo_ml_selected': 'gbm',\n",
       " 'input_training': 'gs://remote_sensing_saas/01-korindo/pl_sampling/sampling_korindo.shp',\n",
       " 'label_column': 'type',\n",
       " 'project_name': 'korindo',\n",
       " 'super_pixel_size': 17,\n",
       " 'pixel_number': 3,\n",
       " 'year_start_loss': 14,\n",
       " 'tree_cover_forest': 30,\n",
       " 'band_name_image': 'Class',\n",
       " 'valid_pixel_threshold': 20,\n",
       " 'crs_input': 'EPSG:4326',\n",
       " 'output_crs': 'EPSG:32749',\n",
       " 'IsThermal': False,\n",
       " 'fcd_selected': 21,\n",
       " 'ndwi_hi_sentinel': 0.05,\n",
       " 'ndwi_hi_landsat': 0.1,\n",
       " 'ndwi_hi_planet': -0.2,\n",
       " 'resolution_satellite': 10,\n",
       " 'url_satellite_cloud': 'https://planetarycomputer.microsoft.com/api/stac/v1',\n",
       " 'collection_mpc': 'sentinel-2-l2a',\n",
       " 'mpc_date_range': ['2014-08-15', '2018-01-31'],\n",
       " 'mpc_zarr_path': 'gs://remote_sensing_saas/01-korindo/timeseries_zarr/sentinel-2-l2a_korindo_2014-08-15_2018-01-31_gee.zarr',\n",
       " 'mpc_zarr_monthly': 'gs://remote_sensing_saas/01-korindo/timeseries_zarr/sentinel-2-l2a_korindo_2014-08-15_2018-01-31_gee_monthly.zarr',\n",
       " 'mpc_monthly_col': 'projects/remote-sensing-476412/assets/korindo_sentinel2_monthly_mpc',\n",
       " 'gee_monthly_col': 'projects/remote-sensing-476412/assets/korindo_sentinel2_monthly',\n",
       " 'assets_satellite': ['B01',\n",
       "  'B02',\n",
       "  'B03',\n",
       "  'B04',\n",
       "  'B05',\n",
       "  'B06',\n",
       "  'B07',\n",
       "  'B08',\n",
       "  'B09',\n",
       "  'B11',\n",
       "  'B12',\n",
       "  'B8A',\n",
       "  'SCL'],\n",
       " 'band_mapping': {'B01': 'coastal',\n",
       "  'B02': 'blue',\n",
       "  'B03': 'green',\n",
       "  'B04': 'red',\n",
       "  'B05': 'redE1',\n",
       "  'B06': 'redE2',\n",
       "  'B07': 'redE3',\n",
       "  'B08': 'nir',\n",
       "  'B09': 'nir2',\n",
       "  'B11': 'swir1',\n",
       "  'B12': 'swir2',\n",
       "  'B8A': 'redE4',\n",
       "  'SCL': 'scl'},\n",
       " 'pl_dir_jul1': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_jul1_fix_8bands_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_jul30': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_jul_30_fix_8bands_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_apr27': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_apr27_20250427-cog_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_jun8': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_june8_20250608_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_sep21_2024': 'gs://remote_sensing_saas/01-korindo/planet_scope/kor_sep_20_21_20240920-21-cog_psscene_analytic_8b_sr_udm2',\n",
       " 'pl_dir_sep3_2024': 'gs://planet-orders-t/korindo/2024-09-03/25ef326f-ac78-4b7a-a71a-0fe25f6fa1b5',\n",
       " 'tsfresh_feature_path': 'gs://remote_sensing_saas/01-korindo/tsfresh_features/tsfresh_features_132576samples_50features_20251125_170042.parquet',\n",
       " 'I_satellite': 'Custom',\n",
       " 'date_start_end': ['2025-8-1', '2025-8-31'],\n",
       " 'open_land': 30,\n",
       " 'shrub_grass': 45,\n",
       " 'yrf_forest': 45,\n",
       " 'high_forest': 65}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70375599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì GEE Initialized successfully\n",
      "  Credentials Path: /usr/src/app/user_id.json - loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from forestry_carbon_arr.core.utils import DataUtils\n",
    "\n",
    "d = DataUtils(config)\n",
    "aoi_gpd, aoi_ee = d.load_geodataframe_gee(config[\"AOI_path\"])\n",
    "\n",
    "# we shall use the STAC approach if historical data of sentinel is not available from GEE \n",
    "# first we need to check in the AOI, date range availability, and do the historical data similar to the Hansen approach\n",
    "\n",
    "# We should change the use_gee = True as use_hansen_gee = True vs use_tsfresh = True\n",
    "# use_hansen_gee = True, is the first version of eligibility check that use landcover, and hansen tree cover\n",
    "# use_tsfresh = True, is the second version of eligibility check that use tsfresh to extract the features from the time series of satellite data (replacing hansen) and current model will at the moment use \n",
    "## trees vs non-trees classification in use_tsfresh\n",
    "\n",
    "# check the date range availability of the sentinel data - GEE xee, let's leverage the GEE with xarray,\n",
    "from gee_lib.osi.image_collection.main import ImageCollection\n",
    "\n",
    "# Create configuration for GEE ImageCollection\n",
    "\n",
    "year_end = int(config['date_start_end'][1].split('-')[0])\n",
    "ten_years_prior = year_end -10\n",
    "\n",
    "new_date_start_end = [f'{ten_years_prior}-01-01', f\"{config['date_start_end'][1]}\"]\n",
    "\n",
    "gee_config = {\n",
    "    'AOI': aoi_ee,\n",
    "    'date_start_end': new_date_start_end,\n",
    "    'cloud_cover_threshold': config['satellite']['cloud_cover_threshold'],\n",
    "    'config': {'IsThermal': False}\n",
    "}\n",
    "\n",
    "# Initialize ImageCollection\n",
    "image_collection = ImageCollection(\n",
    "    I_satellite=config['I_satellite'],\n",
    "    region=aoi_gpd,\n",
    "    **gee_config\n",
    ")\n",
    "\n",
    "# Get the raw ImageCollection (not mosaicked)\n",
    "raw_collection = image_collection.image_collection_mask()\n",
    "## masking cloud, get xarray with applied cloud mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82932262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### adding the existing analysis as the loaded data result, after initialization\n",
    "asset_folder = 'projects/remote-sensing-476412/assets/korindo_sentinel2_monthly'  # Change to your asset path\n",
    "use_aset = True\n",
    "if use_aset:\n",
    "    monthly_mosaick = ee.ImageCollection(asset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea9eb3",
   "metadata": {},
   "source": [
    "## Step 2: Convert to UTM CRS (meters)\n",
    "\n",
    "**Why UTM?**\n",
    "- UTM uses meters as units (not degrees like EPSG:4326)\n",
    "- Scale parameter in xee should match CRS units\n",
    "- Sentinel-2: 10m pixels means 10 meters, which only makes sense in UTM\n",
    "- Better for spatial analysis and area calculations\n",
    "\n",
    "**Steps:**\n",
    "1. Determine UTM zone from AOI centroid longitude\n",
    "2. Reproject raw_collection in Earth Engine to UTM\n",
    "3. Update xee parameters to use UTM CRS and meter scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a0b615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç AOI Centroid: (-0.3125¬∞, 111.9082¬∞)\n",
      "üó∫Ô∏è  UTM Zone: 49S\n",
      "üî¢ UTM EPSG Code: EPSG:32749\n",
      "üìê CRS Units: Meters (‚úÖ matches scale units)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_860/3455030237.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid_lon = aoi_wgs84.geometry.centroid.x.mean()\n",
      "/tmp/ipykernel_860/3455030237.py:13: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid_lat = aoi_wgs84.geometry.centroid.y.mean()\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Determine UTM zone from AOI centroid\n",
    "# UTM zones are calculated based on longitude: zone = floor((lon + 180) / 6) + 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get centroid longitude (must be in WGS84/ EPSG:4326 for UTM calculation)\n",
    "if aoi_gpd.crs.to_string() != 'EPSG:4326':\n",
    "    aoi_wgs84 = aoi_gpd.to_crs('EPSG:4326')\n",
    "else:\n",
    "    aoi_wgs84 = aoi_gpd\n",
    "\n",
    "centroid_lon = aoi_wgs84.geometry.centroid.x.mean()\n",
    "centroid_lat = aoi_wgs84.geometry.centroid.y.mean()\n",
    "\n",
    "# Calculate UTM zone\n",
    "utm_zone = int(np.floor((centroid_lon + 180) / 6)) + 1\n",
    "\n",
    "# Determine hemisphere (N or S) based on latitude\n",
    "hemisphere = 'N' if centroid_lat >= 0 else 'S'\n",
    "\n",
    "# UTM EPSG code format: EPSG:326XX (northern) or EPSG:327XX (southern)\n",
    "if hemisphere == 'N':\n",
    "    utm_epsg = 32600 + utm_zone  # Northern hemisphere\n",
    "else:\n",
    "    utm_epsg = 32700 + utm_zone  # Southern hemisphere\n",
    "\n",
    "print(f\"üìç AOI Centroid: ({centroid_lat:.4f}¬∞, {centroid_lon:.4f}¬∞)\")\n",
    "print(f\"üó∫Ô∏è  UTM Zone: {utm_zone}{hemisphere}\")\n",
    "print(f\"üî¢ UTM EPSG Code: EPSG:{utm_epsg}\")\n",
    "print(f\"üìê CRS Units: Meters (‚úÖ matches scale units)\")\n",
    "\n",
    "# Update config with UTM CRS\n",
    "config['utm_crs'] = f'EPSG:{utm_epsg}'\n",
    "config['utm_zone'] = utm_zone\n",
    "config['utm_hemisphere'] = hemisphere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706d81b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Using existing asset collection\n"
     ]
    }
   ],
   "source": [
    "if config['I_satellite'] == 'Sentinel':\n",
    "        pixel_scale = 10  # meters for Sentinel-2\n",
    "elif config['I_satellite'] == 'Landsat':\n",
    "    pixel_scale = 30  # meters for Landsat\n",
    "else:\n",
    "    pixel_scale = 10  # default\n",
    "    \n",
    "if use_aset == False:\n",
    "    # Step 2: Reproject raw_collection to UTM in Earth Engine\n",
    "    # This ensures the ImageCollection is in meters before xee conversion\n",
    "\n",
    "    print(\"üîÑ Reprojecting raw_collection to UTM...\")\n",
    "\n",
    "    # Reproject each image in the collection to UTM\n",
    "    # scale: pixel size in meters (10m for Sentinel-2)\n",
    "    # crs: UTM EPSG code\n",
    "\n",
    "    # Reproject the collection\n",
    "    raw_collection_utm = raw_collection.map(\n",
    "        lambda image: image.reproject(\n",
    "            crs=f'EPSG:{utm_epsg}',\n",
    "            scale=pixel_scale\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Reprojected to {config['utm_crs']}\")\n",
    "    print(f\"   Scale: {pixel_scale}m (matches CRS units)\")\n",
    "\n",
    "    # Update the collection variable\n",
    "    raw_collection = raw_collection_utm\n",
    "\n",
    "else:\n",
    "    print(\"üîÑ Using existing asset collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4f840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Raw Collection Info:\n",
      "Type: <class 'NoneType'>\n",
      "Is ImageCollection: False\n",
      "\n",
      "üîÑ Converting AOI geometry to UTM (EPSG:32749)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>descriptio</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>altitudeMo</th>\n",
       "      <th>tessellate</th>\n",
       "      <th>extrude</th>\n",
       "      <th>visibility</th>\n",
       "      <th>drawOrder</th>\n",
       "      <th>icon</th>\n",
       "      <th>HECTARES</th>\n",
       "      <th>Km</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40022.861</td>\n",
       "      <td>400.228614</td>\n",
       "      <td>0.403343</td>\n",
       "      <td>0.290644</td>\n",
       "      <td>0.117229</td>\n",
       "      <td>1.387972</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((578614.536 9949391.122, 578616.697 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name descriptio timestamp begin   end altitudeMo  tessellate  extrude  \\\n",
       "0  None       None      None  None  None       None          -1        0   \n",
       "\n",
       "   visibility drawOrder  icon   HECTARES          Km     width    height  \\\n",
       "0          -1      None  None  40022.861  400.228614  0.403343  0.290644   \n",
       "\n",
       "       area  perimeter  id                                           geometry  \n",
       "0  0.117229   1.387972   0  POLYGON ((578614.536 9949391.122, 578616.697 9...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Check the raw_collection structure\n",
    "print(\"üìä Raw Collection Info:\")\n",
    "print(f\"Type: {type(raw_collection)}\")\n",
    "print(f\"Is ImageCollection: {isinstance(raw_collection, ee.ImageCollection)}\")\n",
    "\n",
    "# Step 3: Get the AOI bounding box in UTM (required for xee)\n",
    "# First, transform aoi_ee geometry to UTM so bounds are in meters\n",
    "print(f\"\\nüîÑ Converting AOI geometry to UTM ({config['utm_crs']})...\")\n",
    "aoi_gpd_utm = aoi_gpd.to_crs(f'EPSG:{utm_epsg}')\n",
    "aoi_gpd_utm.set_crs(f'EPSG:{utm_epsg}', inplace=True)\n",
    "\n",
    "# aoi_ee_utm_geom = geemap.geopandas_to_ee(aoi_gpd_utm) # not possible, uploaded fc will automatically 4326\n",
    "\n",
    "# # Get bounds from UTM geometry (now in meters)\n",
    "# aoi_bounds_utm = aoi_ee_utm_geom.bounds().getInfo()\n",
    "# print(f\"üìç AOI Bounds (UTM): {aoi_bounds_utm}\")\n",
    "\n",
    "# # Extract the coordinates from UTM bounds\n",
    "# coordinates_utm = aoi_bounds_utm['coordinates'][0]\n",
    "# # xee expects region as a list: [west, south, east, north] or a GeoJSON-like dict\n",
    "# # Bounds are now in meters (UTM)\n",
    "# from shapely.geometry import box\n",
    "# bounds_list_utm = [coordinates_utm[0][0], coordinates_utm[0][1], coordinates_utm[2][0], coordinates_utm[2][1]]\n",
    "# print(f\"Bounds list format [west, south, east, north] in meters: {bounds_list_utm}\")\n",
    "# print(f\"   Note: These coordinates are in UTM meters, not degrees!\")\n",
    "\n",
    "# Also keep the UTM geometry for later use\n",
    "# aoi_ee_utm = aoi_ee_utm_geom  # Save for use in xee conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524ebbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aoi_gpd_utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574345f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aoi_gpd_utm.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82efbedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Pixel Scale: 10m (Custom)\n",
      "üåç CRS: EPSG:32749 (UTM Zone 49S)\n",
      "‚úÖ Scale and CRS units both in meters - correct!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Configure xee parameters for UTM\n",
    "# Now we use UTM CRS (meters) which matches the scale units\n",
    "\n",
    "# Scale is already set from previous step (10m for Sentinel-2)\n",
    "print(f\"üìê Pixel Scale: {pixel_scale}m ({config['I_satellite']})\")\n",
    "\n",
    "# Use UTM CRS (already calculated)\n",
    "utm_crs = config['utm_crs']\n",
    "print(f\"üåç CRS: {utm_crs} (UTM Zone {config['utm_zone']}{config['utm_hemisphere']})\")\n",
    "print(f\"‚úÖ Scale and CRS units both in meters - correct!\")\n",
    "\n",
    "# Extract EPSG code for xee\n",
    "epsg_code = utm_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e96bc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(aoi_gpd)\n",
    "# Simple way to plot geometry - just call .plot() method\n",
    "aoi_gpd.plot(figsize=(12, 12), color='blue', edgecolor='black', alpha=0.5)\n",
    "\n",
    "# Or use the geometry directly\n",
    "# geom = aoi_gpd.geometry\n",
    "# geom.plot(figsize=(10, 10), color='green', edgecolor='red', linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa775372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa7d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a41ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c765f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list_month_year = [f'{i}-{j}' for i in range(2015, 2025) for j in range(1, 13)]\n",
    "\n",
    "# list_month_year\n",
    "# raw_collection.filterDate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3543be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Using existing asset collection\n"
     ]
    }
   ],
   "source": [
    "if use_aset == False:\n",
    "    ### FINAL FILTERING CLOUD COVER AND CLOUD MASK\n",
    "    # Calculate total grid pixels using the SAME method as xarray would\n",
    "    print(\"üìê Calculating total grid pixels (matching xarray method)...\")\n",
    "\n",
    "    # Transform geometry to UTM (same as xarray does)\n",
    "    aoi_geom_utm = aoi_ee.geometry().transform(\n",
    "        f'EPSG:{utm_epsg}',\n",
    "        maxError=1\n",
    "    )\n",
    "\n",
    "    # Get bounding box in UTM\n",
    "    aoi_bounds_utm = aoi_geom_utm.bounds(maxError=1)\n",
    "\n",
    "    # Use a constant image to count ALL pixels in the bounding box\n",
    "    # This matches exactly what xarray does: creates grid over bounding box\n",
    "    scale = 10\n",
    "    crs_utm = f'EPSG:{utm_epsg}'\n",
    "\n",
    "    # ============================================================================\n",
    "    # COMMENTED OUT: Previous approach using total AOI grid pixels\n",
    "    # ============================================================================\n",
    "    # WHY COMMENTED: Key difference between STAC (Microsoft Planetary Computer) and GEE:\n",
    "    #\n",
    "    # STAC/MPC BEHAVIOR:\n",
    "    #   - Same tile-ID = Same scene/image (one-to-one mapping)\n",
    "    #   - Each tile-ID corresponds to a single, unique scene\n",
    "    #   - No mosaic processing: tile-ID uniquely identifies the scene\n",
    "    #\n",
    "    # GEE BEHAVIOR:\n",
    "    #   - Same tile-ID = Can be split/mosaicked into multiple scenes\n",
    "    #   - One tile-ID can appear in multiple images (mosaic processing)\n",
    "    #   - Different processing times can create different mosaics from same tile-ID\n",
    "    #   - GEE combines multiple tiles with same ID but different timestamps into mosaic\n",
    "    #\n",
    "    # IMPLICATION:\n",
    "    #   - In STAC: Total AOI grid pixels makes sense (consistent per tile-ID)\n",
    "    #   - In GEE: Need intersected pixels only (mosaic varies per processing time)\n",
    "    #   - Therefore, we should NOT use total AOI as the divider, but total intersected pixels\n",
    "    # ============================================================================\n",
    "    # Create constant image (1 everywhere)\n",
    "    # constant_img = ee.Image.constant(1)\n",
    "\n",
    "    # Count pixels in bounding box using same parameters as xarray\n",
    "    # xarray uses: geometry (transformed), crs, scale ---> we cant use the MPC xarray approach in GEE\n",
    "    # total_grid_pixels_result = constant_img.reduceRegion(\n",
    "    #     reducer=ee.Reducer.sum(),\n",
    "    #     geometry=aoi_bounds_utm,  # Use bounding box, not polygon\n",
    "    #     scale=scale,               # Same as xarray scale\n",
    "    #     crs=crs_utm,              # Same as xarray CRS\n",
    "    #     bestEffort=True,\n",
    "    #     maxPixels=1e10\n",
    "    # )\n",
    "\n",
    "    # Get the value\n",
    "    # total_grid_pixels = total_grid_pixels_result.get('constant').getInfo()\n",
    "    # print(f\"üìä Total grid pixels: {total_grid_pixels:,}\") \n",
    "    # ============================================================================\n",
    "    # END OF COMMENTED SECTION\n",
    "    # ============================================================================\n",
    "\n",
    "    # STAC I meant is the MPC (Microsoft Planetary Computer):\n",
    "    #   - In MPC/STAC: Same tile-ID = same scene (no mosaic processing)\n",
    "    #   - In GEE: Same tile-ID can be mosaicked but processed at different times\n",
    "    # THEREFORE, WE SHOULD NOT USE THE TOTAL AOI AS THE DIVIDER, BUT THE TOTAL INTERSECTED PIXELS \n",
    "    # (No need to put NA - we count actual intersected pixels per scene)\n",
    "\n",
    "    print(f\"   Scale: {scale}m\")\n",
    "    print(f\"   CRS: {crs_utm}\")\n",
    "    print(f\"   ‚ö†Ô∏è  CHANGED: Using total intersected pixels (valid + invalid) instead of total AOI grid\")\n",
    "    print(f\"   Reason: GEE mosaics same tile-ID across different processing times, STAC keeps tile-ID unique\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # COMMENTED OUT: Alternative verification method\n",
    "    # ============================================================================\n",
    "    # This section was for debugging/verification but not needed in production\n",
    "    # ============================================================================\n",
    "    # # Verify it's reasonable (should be similar to 801 x 531 = 425,331)\n",
    "    # if total_grid_pixels == 0:\n",
    "    #     print(\"\\n‚ö†Ô∏è WARNING: Could not calculate grid pixels!\")\n",
    "    #     print(\"   Trying alternative method...\")\n",
    "        \n",
    "    #     # Alternative: use pixelLonLat to get extent\n",
    "    #     sample_img = raw_collection.first().select('cloudM')\n",
    "    #     lonlat = sample_img.select('cloudM').addBands(ee.Image.pixelLonLat())\n",
    "        \n",
    "    #     # This is more complex, so let's stick with the constant image approach\n",
    "    #     # But check if geometry transform worked\n",
    "    #     print(\"   Checking transformed geometry...\")\n",
    "    #     aoi_geom_utm_info = aoi_geom_utm.getInfo()\n",
    "    #     print(f\"   Transformed geometry: {aoi_geom_utm_info.get('type', 'unknown')}\")\n",
    "        \n",
    "    # else:\n",
    "    #     print(f\"‚úì Grid pixels calculated successfully!\")\n",
    "    # ============================================================================\n",
    "    # END OF COMMENTED SECTION\n",
    "    # ============================================================================\n",
    "\n",
    "    def add_cloudm_stats(image):\n",
    "        \"\"\"\n",
    "        Calculate cloudM percentages - only cloudM=1 is valid\n",
    "        \n",
    "        CHANGED: Now uses total intersected pixels (valid + invalid) as denominator\n",
    "        instead of total AOI grid pixels.\n",
    "        \n",
    "        FIXED: Uses frequencyHistogram instead of two separate reduceRegion calls\n",
    "        This reduces concurrent aggregations by 50% (one call instead of two)\n",
    "        \n",
    "        FIXED: Properly handles ee.Dictionary.get() return values by converting to ee.Number\n",
    "        \n",
    "        This accounts for GEE mosaic processing where:\n",
    "        - Same tile-ID can appear in multiple scenes (mosaicked at different times)\n",
    "        - STAC/MPC: Same tile-ID = same scene (no mosaic)\n",
    "        - GEE: Same tile-ID = can be mosaicked but processed at different times\n",
    "        \"\"\"\n",
    "        cloudm_band = image.select('cloudM')\n",
    "        \n",
    "        # FIXED: Use frequencyHistogram to get both 0 and 1 counts in ONE reduceRegion call\n",
    "        # This reduces concurrent aggregations by 50% compared to two separate calls\n",
    "        # Histogram returns dict like {'0': count0, '1': count1}\n",
    "        histogram = cloudm_band.reduceRegion(\n",
    "            reducer=ee.Reducer.frequencyHistogram(),\n",
    "            geometry=aoi_bounds_utm,  # Bounding box (matches xarray grid extent)\n",
    "            scale=scale,              # Same as xarray\n",
    "            crs=crs_utm,             # Same as xarray\n",
    "            bestEffort=True,\n",
    "            maxPixels=1e11\n",
    "        ).get('cloudM')\n",
    "        \n",
    "        # FIXED: Extract counts from histogram dictionary properly\n",
    "        # Handle case where histogram might be None or missing values\n",
    "        # Use plain number (0) as default, then convert to ee.Number\n",
    "        hist_dict = ee.Dictionary(histogram)\n",
    "        count_0_raw = hist_dict.get('0', 0)  # Invalid/cloudy pixels - use plain 0, not ee.Number(0)\n",
    "        count_1_raw = hist_dict.get('1', 0)  # Valid pixels - use plain 0, not ee.Number(0)\n",
    "        \n",
    "        # Convert to ee.Number explicitly (handles both plain numbers and ComputedObjects)\n",
    "        count_0 = ee.Number(count_0_raw)\n",
    "        count_1 = ee.Number(count_1_raw)\n",
    "        \n",
    "        # CHANGED: Calculate percentage using total intersected pixels\n",
    "        # OLD: pct_valid = ee.Number(count_valid).divide(total_grid_pixels).multiply(100)\n",
    "        # NEW: Use sum of valid + invalid (only intersected pixels, not full AOI grid)\n",
    "        # Reason: GEE mosaics same tile-ID across different processing times,\n",
    "        #         so we need per-scene intersected pixels, not total AOI grid\n",
    "        sum_pixels = count_0.add(count_1)\n",
    "        pct_valid = count_1.divide(sum_pixels).multiply(100)\n",
    "        \n",
    "        # ADDED: Store additional stats for debugging\n",
    "        return image.set({\n",
    "            'cloudM_pct_valid': pct_valid,\n",
    "            'cloudM_count_valid': count_1,\n",
    "            'cloudM_count_invalid': count_0,\n",
    "            'cloudM_total_intersected': sum_pixels\n",
    "        })\n",
    "\n",
    "    # Get valid pixel threshold with error handling\n",
    "    # ADDED: Default value if not in config\n",
    "    valid_pixel_threshold = config.get('valid_pixel_threshold', 70)\n",
    "\n",
    "    # Add statistics\n",
    "    print(\"\\nüîÑ Calculating cloudM statistics for each scene...\")\n",
    "    collection_with_stats = raw_collection.map(add_cloudm_stats)\n",
    "\n",
    "    # Get statistics\n",
    "    print(\"üìä Computing statistics...\")\n",
    "    pct_array = collection_with_stats.aggregate_array('cloudM_pct_valid').getInfo()\n",
    "    pct_array = [float(x) if x is not None else 0.0 for x in pct_array]\n",
    "\n",
    "    # Print same format as xarray version\n",
    "    # IMPROVED: Added mean and better formatting\n",
    "    if len(pct_array) > 0:\n",
    "        print(f\"\\nValid pixel percentages: min={min(pct_array):.1f}%, max={max(pct_array):.1f}%\")\n",
    "        print(f\"Mean: {sum(pct_array)/len(pct_array):.1f}%\")\n",
    "        \n",
    "        n_valid = sum(1 for p in pct_array if p > valid_pixel_threshold)\n",
    "        n_total = len(pct_array)\n",
    "        print(f\"Scenes with >{valid_pixel_threshold}% valid pixels: {n_valid}/{n_total}\")\n",
    "        \n",
    "        # ADDED: Warning if no scenes pass threshold\n",
    "        if n_valid == 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  WARNING: No scenes passed the threshold!\")\n",
    "            print(f\"   Consider lowering valid_pixel_threshold (current: {valid_pixel_threshold}%)\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: No statistics computed!\")\n",
    "\n",
    "    # Filter\n",
    "    collection_filtered = collection_with_stats.filter(\n",
    "        ee.Filter.gt('cloudM_pct_valid', valid_pixel_threshold)\n",
    "    )\n",
    "\n",
    "    # Get sizes\n",
    "    original_size = raw_collection.size().getInfo()\n",
    "    filtered_size = collection_filtered.size().getInfo()\n",
    "\n",
    "    print(f\"\\nAfter valid pixel filtering:\")\n",
    "    print(f\"  Filtered: {filtered_size} scenes\")\n",
    "    print(f\"  Removed: {original_size - filtered_size} scenes\")\n",
    "    # IMPROVED: Added retention rate\n",
    "    print(f\"  Retention rate: {(filtered_size/original_size*100):.1f}%\")\n",
    "\n",
    "    # collection_with_eemont_indices = collection_filtered\n",
    "    # collection_filtered.size().getInfo()\n",
    "else:\n",
    "    print(\"üîÑ Using existing asset collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "700b9418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## UNCOMMENT TO GET INFO ABOUT DATA AVAILABILITY\n",
    "# # Method 1: Get dates using system:time_start (most common)\n",
    "# dates_timestamps = collection_filtered.aggregate_array('system:time_start').getInfo()\n",
    "\n",
    "# # Convert timestamps (milliseconds) to Python datetime objects\n",
    "# import datetime\n",
    "# dates_list = [datetime.datetime.fromtimestamp(ts / 1000) for ts in dates_timestamps]\n",
    "\n",
    "# # Or as date strings\n",
    "# dates_str_list = [datetime.datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d') for ts in dates_timestamps]\n",
    "\n",
    "# print(f\"Total dates: {len(dates_list)}\")\n",
    "# print(f\"Date range: {dates_list[0]} to {dates_list[-1]}\")\n",
    "# print(f\"Dates: {dates_str_list}\")\n",
    "\n",
    "# ## data availability\n",
    "# start_date = dates_list[0]\n",
    "# end_date = dates_list[-1]\n",
    "\n",
    "# print(f\"Data availability: {start_date} to {end_date}\")\n",
    "\n",
    "# start_year = start_date.year\n",
    "# end_year = end_date.year\n",
    "\n",
    "# print(f\"Year range: {start_year} to {end_year}\")\n",
    "\n",
    "# # check if all year has the representative image\n",
    "\n",
    "# for i in range(start_year, end_year + 1):\n",
    "#     if i not in [date.year for date in dates_list]:\n",
    "#         print(f\"Year {i} does not have a representative image\")\n",
    "#     else:\n",
    "#         print(f\"Year {i} has a representative image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ee92263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# print(\"üìÖ Creating quarterly composites...\")\n",
    "\n",
    "# # Get date list (for the initial info)\n",
    "# dates_list = collection_filtered.aggregate_array('system:time_start').getInfo()\n",
    "# print(f\"   Input: collection_filtered ({len(dates_list)} scenes)\")\n",
    "# print(f\"   Output: Quarterly composites (every 3 months, end-of-quarter dates)\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # STEP 1 ‚Äî build quarterly ee.Image objects, keep them in a Python list\n",
    "# # ------------------------------------------------------------------\n",
    "# quarterly_images = []\n",
    "\n",
    "# # Pre-compute available years so we can print them\n",
    "# years = sorted({pd.Timestamp(ts, unit='ms').year for ts in dates_list})\n",
    "\n",
    "# for year in years:\n",
    "#     for quarter in [1, 2, 3, 4]:\n",
    "#         # Quarter start/end\n",
    "#         start_month = (quarter - 1) * 3 + 1\n",
    "#         start = ee.Date.fromYMD(year, start_month, 1)\n",
    "#         end = start.advance(3, 'month').advance(-1, 'day')\n",
    "\n",
    "#         quarter_collection = collection_filtered.filterDate(start, end.advance(1, 'day'))\n",
    "\n",
    "#         count = quarter_collection.size().getInfo()\n",
    "#         if count == 0:\n",
    "#             continue\n",
    "\n",
    "#         composite = quarter_collection.reduce(ee.Reducer.median()) \\\n",
    "#             .set({\n",
    "#                 'system:time_start': end.millis(),\n",
    "#                 'year': year,\n",
    "#                 'quarter': quarter,\n",
    "#                 'n_images': count,\n",
    "#                 'system:id': f'Sentinel2_{year}_q{quarter}'\n",
    "#             }).clip(aoi_ee.geometry())\n",
    "\n",
    "#         quarterly_images.append(composite)\n",
    "#         print(f\"   Q{quarter} {year}: {count} images ‚Üí composite (ID: Sentinel2_{year}_q{quarter}, Date: {end.format('YYYY-MM-dd').getInfo()})\")\n",
    "\n",
    "# print(f\"\\n‚úÖ Step 1 complete; built {len(quarterly_images)} quarterly images (stored client-side as ee.Image objects)\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # STEP 2 ‚Äî assemble ImageCollection and print summary (keep existing prints)\n",
    "# # ------------------------------------------------------------------\n",
    "# collection_quarterly = ee.ImageCollection(quarterly_images) \\\n",
    "#     .filterMetadata('n_images', 'greater_than', 0) \\\n",
    "#     .sort('system:time_start')\n",
    "\n",
    "# n_quarters = collection_quarterly.size().getInfo()\n",
    "# print(f\"\\n‚úÖ Quarterly aggregation complete!\")\n",
    "# print(f\"   Number of quarterly composites: {n_quarters}\")\n",
    "\n",
    "# if n_quarters > 0:\n",
    "#     quarterly_dates = collection_quarterly.aggregate_array('system:time_start').getInfo()\n",
    "#     quarterly_dates_str = [pd.Timestamp(ts, unit='ms').strftime('%Y-%m-%d') for ts in quarterly_dates]\n",
    "\n",
    "#     quarterly_ids = collection_quarterly.aggregate_array('system:id').getInfo()\n",
    "\n",
    "#     print(f\"\\nüìä Quarterly composites:\")\n",
    "#     for i, (date_str, q_id) in enumerate(zip(quarterly_dates_str, quarterly_ids), 1):\n",
    "#         print(f\"   {i}. {q_id}: {date_str}\")\n",
    "\n",
    "#     sample_quarter = collection_quarterly.first()\n",
    "#     sample_info = {\n",
    "#         'id': sample_quarter.get('system:id').getInfo(),\n",
    "#         'year': sample_quarter.get('year').getInfo(),\n",
    "#         'quarter': sample_quarter.get('quarter').getInfo(),\n",
    "#         'n_images': sample_quarter.get('n_images').getInfo(),\n",
    "#         'date': pd.Timestamp(sample_quarter.get('system:time_start').getInfo(), unit='ms').strftime('%Y-%m-%d'),\n",
    "#     }\n",
    "#     print(f\"\\n   Sample composite: {sample_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ba3744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Using existing asset collection\n"
     ]
    }
   ],
   "source": [
    "if use_aset == False:\n",
    "    import pandas as pd\n",
    "\n",
    "    print(\"üìÖ Creating monthly composites...\")\n",
    "\n",
    "    # Get date list (for the initial info)\n",
    "    dates_list = collection_filtered.aggregate_array('system:time_start').getInfo()\n",
    "    print(f\"   Input: collection_filtered ({len(dates_list)} scenes)\")\n",
    "    print(f\"   Output: Monthly composites (each month stamped at the 15th)\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 1 ‚Äî build monthly ee.Image objects and keep them in a Python list\n",
    "    # ------------------------------------------------------------------\n",
    "    monthly_images = []\n",
    "\n",
    "    # Pre-compute available months per year from the collection's dates\n",
    "    dates_df = pd.DataFrame({\n",
    "        'timestamp': dates_list,\n",
    "        'date': pd.to_datetime(dates_list, unit='ms')\n",
    "    })\n",
    "    dates_df['year'] = dates_df['date'].dt.year\n",
    "    dates_df['month'] = dates_df['date'].dt.month\n",
    "\n",
    "    # Sort by year, month\n",
    "    unique_year_month = sorted(\n",
    "        {(row.year, row.month) for row in dates_df.itertuples()}\n",
    "    )\n",
    "\n",
    "    for year, month in unique_year_month:\n",
    "        start = ee.Date.fromYMD(year, month, 1)\n",
    "        end = start.advance(1, 'month').advance(-1, 'day')  # end of month\n",
    "\n",
    "        month_collection = collection_filtered.filterDate(start, end.advance(1, 'day'))\n",
    "        count = month_collection.size().getInfo()\n",
    "        if count == 0:\n",
    "            continue\n",
    "\n",
    "        # Timestamp at mid-month (15th)\n",
    "        mid = ee.Date.fromYMD(year, month, 15)\n",
    "\n",
    "        composite = month_collection.reduce(ee.Reducer.median()) \\\n",
    "            .set({\n",
    "                'system:time_start': mid.millis(),\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'n_images': count,\n",
    "                'system:id': f'Sentinel2_{year}_{month:02d}'\n",
    "            }).clip(aoi_ee.geometry())\n",
    "\n",
    "        monthly_images.append(composite)\n",
    "        print(f\"   {year}-{month:02d}: {count} images ‚Üí composite \"\n",
    "            f\"(ID: Sentinel2_{year}_{month:02d}, Date stamp: {mid.format('YYYY-MM-dd').getInfo()})\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Step 1 complete; built {len(monthly_images)} monthly images (stored client-side as ee.Image objects)\")\n",
    "else:\n",
    "    print(\"üîÑ Using existing asset collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "311a5f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### IT TAKES TOO HEAVY TO RUN THIS STEP IN SERVER SIDE\n",
    "# # ------------------------------------------------------------------\n",
    "# # STEP 2 ‚Äî assemble ImageCollection and print summary (keep existing prints)\n",
    "# # ------------------------------------------------------------------\n",
    "# collection_monthly = ee.ImageCollection(monthly_images) \\\n",
    "#     .filterMetadata('n_images', 'greater_than', 0) \\\n",
    "#     .sort('system:time_start')\n",
    "\n",
    "# n_months = collection_monthly.size().getInfo()\n",
    "# print(f\"\\n‚úÖ Monthly aggregation complete!\")\n",
    "# print(f\"   Number of monthly composites: {n_months}\")\n",
    "\n",
    "# if n_months > 0:\n",
    "#     monthly_dates = collection_monthly.aggregate_array('system:time_start').getInfo()\n",
    "#     monthly_dates_str = [pd.Timestamp(ts, unit='ms').strftime('%Y-%m-%d') for ts in monthly_dates]\n",
    "\n",
    "#     monthly_ids = collection_monthly.aggregate_array('system:id').getInfo()\n",
    "\n",
    "#     print(f\"\\nüìä Monthly composites:\")\n",
    "#     for i, (date_str, m_id) in enumerate(zip(monthly_dates_str, monthly_ids), 1):\n",
    "#         print(f\"   {i}. {m_id}: {date_str}\")\n",
    "\n",
    "#     sample_month = collection_monthly.first()\n",
    "#     sample_info = {\n",
    "#         'id': sample_month.get('system:id').getInfo(),\n",
    "#         'year': sample_month.get('year').getInfo(),\n",
    "#         'month': sample_month.get('month').getInfo(),\n",
    "#         'n_images': sample_month.get('n_images').getInfo(),\n",
    "#         'date': pd.Timestamp(sample_month.get('system:time_start').getInfo(), unit='ms').strftime('%Y-%m-%d'),\n",
    "#     }\n",
    "#     print(f\"\\n   Sample composite: {sample_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a791e723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import os\n",
    "# import geemap\n",
    "\n",
    "# Map = geemap.Map(ee_initialize=False)\n",
    "# Map.add_layer(collection_quarterly.first(), {}, 'First image')\n",
    "# Map.add_layer(aoi_ee.geometry(), {}, 'AOI')\n",
    "# Map.centerObject(aoi_ee.geometry(), 10)\n",
    "# Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "090d8851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## skip this in gcp environment, we already see that its there\n",
    "# from wfs_manager import WFSManager\n",
    "\n",
    "# wfs = WFSManager(fastapi_url=\"http://fastapi:8000\", wfs_base_url=\"http://localhost:8001\")\n",
    "# wfs.addLayer(aoi_ee.geometry(), \"AOI Boundary\")\n",
    "# wfs.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2884833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monthly_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "114d3abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Using existing asset collection\n"
     ]
    }
   ],
   "source": [
    "######### ONLY ONE TIME TO EXPORT TO MAKE PROCESS FASTER LATER TO USE THE ASSETS!\n",
    "### LETS EXPORT FIRST THE ee.ImageCollection (Computed --> Quarterly data)\n",
    "# After collection_quarterly is built\n",
    "scale = 10\n",
    "region = aoi_ee.geometry()\n",
    "\n",
    "if use_aset == False:\n",
    "    len_monthly_images = len(monthly_images)\n",
    "    print(f\"Submitting {len_monthly_images} export tasks...\")\n",
    "\n",
    "    for i, image in enumerate(monthly_images):\n",
    "        image_id = image.get('system:id').getInfo()  # e.g. Sentinel2_2024_q1\n",
    "        asset_id = f'{asset_folder}/{image_id}'\n",
    "\n",
    "        # Ensure unique description; use .format() or f-string\n",
    "        task = ee.batch.Export.image.toAsset(\n",
    "            image=image,\n",
    "            description=f'export_{image_id}',\n",
    "            assetId=asset_id,\n",
    "            scale=scale,\n",
    "            region=region,\n",
    "            maxPixels=1e13\n",
    "        )\n",
    "        task.start()\n",
    "        print(f'  üöÄ Started export: {asset_id}')\n",
    "\n",
    "    print('All tasks submitted; monitor them in the Tasks tab.')\n",
    "\n",
    "else:\n",
    "    print(\"üîÑ Using existing asset collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81c5733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLEASE WAIT FOR THE ASSET TO BE UPLOADED TO GEE ASSET\n"
     ]
    }
   ],
   "source": [
    "print('PLEASE WAIT FOR THE ASSET TO BE UPLOADED TO GEE ASSET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0496bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_img = monthly_mosaick.filterDate('2025-8-1','2025-8-31')\n",
    "aug_img.size().getInfo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5aef3b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## skip this for gcp docker environment (visual is not needed yet into fastapi)\n",
    "# from wmts_manager import WMTSManager\n",
    "\n",
    "# wmts = WMTSManager(project_name=config['project']['name'], aoi=aoi_ee.geometry())\n",
    "# # wmts.addLayer(collection_quarterly.first(), {'bands': ['swir2_median', 'nir_median', 'red_median'],\n",
    "# #    'min': 0,\n",
    "# #    'max': 0.6,\n",
    "# #    'gamma': 1.5}, collection_quarterly.first().get('system:id').getInfo())\n",
    "\n",
    "# # sen_2025_q3 = ee.Image(collection_quarterly.filter(ee.Filter.eq('system:id', 'Sentinel2_2025_q3')).first())\n",
    "# sen_2025_aug = aug_img.first()\n",
    "\n",
    "# img_vis_params = {'bands': ['swir2_median', 'nir_median', 'red_median'],\n",
    "#    'min': 0,\n",
    "#    'max': 0.6,\n",
    "#    'gamma': 1.5}\n",
    "\n",
    "# wmts.addLayer( sen_2025_aug,img_vis_params , sen_2025_aug.get('system:id').getInfo())\n",
    "\n",
    "# wmts.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "177408ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81579ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['blue_median',\n",
       " 'green_median',\n",
       " 'red_median',\n",
       " 'redE1_median',\n",
       " 'redE2_median',\n",
       " 'redE3_median',\n",
       " 'nir_median',\n",
       " 'redE4_median',\n",
       " 'swir1_median',\n",
       " 'swir2_median',\n",
       " 'cloudM_median']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_mosaick.first().bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fcb2fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['blue',\n",
       " 'green',\n",
       " 'red',\n",
       " 'redE1',\n",
       " 'redE2',\n",
       " 'redE3',\n",
       " 'nir',\n",
       " 'redE4',\n",
       " 'swir1',\n",
       " 'swir2']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_band_names = [band for band in monthly_mosaick.first().bandNames().getInfo() if 'cloudM' not in band]\n",
    "clean_band_names = [band.replace('_median', '') for band in list_band_names]\n",
    "clean_band_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9b4cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['blue',\n",
       " 'green',\n",
       " 'red',\n",
       " 'redE1',\n",
       " 'redE2',\n",
       " 'redE3',\n",
       " 'nir',\n",
       " 'redE4',\n",
       " 'swir1',\n",
       " 'swir2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### no need to get cloudM median anymore, and all _median suffix should be removed\n",
    "# Add Spectral Indices to ImageCollection\n",
    "monthly_mosaick_cloud_free = monthly_mosaick.map(lambda img: img.select(list_band_names,clean_band_names))\n",
    "monthly_mosaick_cloud_free.first().bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38917193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Adding spectral indices to ImageCollection...\n",
      "   Satellite: Custom\n",
      "   Mapping indices over each image in collection...\n",
      "‚úÖ Spectral indices added to ImageCollection!\n",
      "   Added: NDVI, NDWI, MSAVI2, MTVI2, VARI\n",
      "\n",
      "üìä First image now has 15 bands:\n",
      "   Bands: blue, green, red, redE1, redE2, redE3, nir, redE4, swir1, swir2, NDVI, ndwi, msavi2, MTVI2, VARI\n"
     ]
    }
   ],
   "source": [
    "# Add Spectral Indices to ImageCollection\n",
    "# Map spectral indices over each image in the collection using SpectralAnalysis\n",
    "\n",
    "from gee_lib.osi.spectral_indices.spectral_analysis import SpectralAnalysis\n",
    "\n",
    "print(\"üîÑ Adding spectral indices to ImageCollection...\")\n",
    "print(f\"   Satellite: {config['I_satellite']}\")\n",
    "print(\"   Mapping indices over each image in collection...\")\n",
    "\n",
    "# Prepare config for SpectralAnalysis\n",
    "spectral_config = {\n",
    "    'I_satellite': config['I_satellite'],\n",
    "    'AOI': aoi_ee.geometry(),  # Use the AOI geometry\n",
    "    'pca_scaling': config.get('pca_scaling', 1),\n",
    "    'tileScale': config.get('tileScale', 2)\n",
    "}\n",
    "\n",
    "# Define function to add spectral indices to a single image\n",
    "def add_spectral_indices(image):\n",
    "    \"\"\"\n",
    "    Add spectral indices to a single image using SpectralAnalysis.\n",
    "    \n",
    "    Available indices based on satellite type:\n",
    "    - All: NDVI, NDWI, MSAVI2, MTVI2, VARI\n",
    "    - Sentinel/Landsat: BSI (requires swir1)\n",
    "    Note: AVI and SI require max_bands per image (expensive), typically calculated on mosaics\n",
    "    \"\"\"\n",
    "    # Create SpectralAnalysis instance for this image\n",
    "    spectral = SpectralAnalysis(image, spectral_config)\n",
    "    \n",
    "    # Start with original image\n",
    "    image_with_indices = image\n",
    "    \n",
    "    # Add simple indices (no max_bands calculation needed)\n",
    "    ndvi = spectral.NDVI_func()\n",
    "    ndwi = spectral.NDWI_func()\n",
    "    msavi2 = spectral.MSAVI2_func()\n",
    "    mtvi2 = spectral.MTVI2_func()\n",
    "    vari = spectral.VARI_func()\n",
    "    \n",
    "    image_with_indices = image_with_indices.addBands([ndvi, ndwi, msavi2, mtvi2, vari])\n",
    "    \n",
    "    # Add BSI for Sentinel/Landsat (requires swir1)\n",
    "    if config['I_satellite'] in ['Sentinel', 'Landsat']:\n",
    "        try:\n",
    "            bsi = spectral.BSI_func()\n",
    "            image_with_indices = image_with_indices.addBands(bsi)\n",
    "        except:\n",
    "            # BSI requires swir1 - skip if not available\n",
    "            pass\n",
    "    \n",
    "    return image_with_indices\n",
    "\n",
    "# Map the function over the ImageCollection\n",
    "collection_filtered = monthly_mosaick_cloud_free\n",
    "collection_with_indices = collection_filtered.map(add_spectral_indices)\n",
    "\n",
    "print(\"‚úÖ Spectral indices added to ImageCollection!\")\n",
    "print(\"   Added: NDVI, NDWI, MSAVI2, MTVI2, VARI\")\n",
    "if config['I_satellite'] in ['Sentinel', 'Landsat']:\n",
    "    print(\"   (BSI added if swir1 band available)\")\n",
    "\n",
    "# Get info about bands in first image\n",
    "first_image = ee.Image(collection_with_indices.first())\n",
    "band_names = first_image.bandNames().getInfo()\n",
    "print(f\"\\nüìä First image now has {len(band_names)} bands:\")\n",
    "print(f\"   Bands: {', '.join(band_names[:15])}{'...' if len(band_names) > 15 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dbac59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Adding FCD-related indices to ImageCollection...\n",
      "   Satellite: Custom\n",
      "   Note: Full FCD requires PCA (expensive per image), adding simplified indices...\n",
      "‚úÖ Pseudo-FCD indices added to ImageCollection!\n",
      "   Added: BI (Bare soil index), SI (Shadow index), pseudo_fcd_pct (0-100%)\n",
      "   Reused: NDVI, NDWI from spectral indices step\n",
      "   Based on: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/pseudo_forest_canopy_density/\n",
      "   No PCA required - computationally efficient for ImageCollection mapping\n",
      "\n",
      "üìä First image now has 18 bands:\n",
      "   Bands: blue, green, red, redE1, redE2, redE3, nir, redE4, swir1, swir2, NDVI, ndwi, msavi2, MTVI2, VARI, BI, SI, pseudo_fcd_pct\n",
      "\n",
      "üå≤ FCD-related bands: SI\n"
     ]
    }
   ],
   "source": [
    "# Add FCD-related indices to ImageCollection\n",
    "# \n",
    "# Simplified Forest Canopy Density (FCD) Proxy Approach\n",
    "# \n",
    "# This approach uses simplified vegetation density indicators as proxies for FCD\n",
    "# when full PCA-based FCD calculation is computationally prohibitive per image.\n",
    "# \n",
    "# Source Literature for Simplified Approach:\n",
    "# 1. Tucker, C. J. (1979). Red and photographic infrared linear combinations for monitoring vegetation. \n",
    "#    Remote Sensing of Environment, 8(2), 127-150.\n",
    "#    https://doi.org/10.1016/0034-4257(79)90013-0\n",
    "#    (NDVI foundation and vegetation monitoring)\n",
    "#\n",
    "# 2. Gao, B. C. (1996). NDWI‚ÄîA normalized difference water index for remote sensing of vegetation \n",
    "#    liquid water from space. Remote Sensing of Environment, 58(3), 257-266.\n",
    "#    https://doi.org/10.1016/S0034-4257(96)00067-3\n",
    "#    (NDWI for water/vegetation discrimination)\n",
    "#\n",
    "# 3. Huete, A., Didan, K., Miura, T., Rodriguez, E. P., Gao, X., & Ferreira, L. G. (2002). \n",
    "#    Overview of the radiometric and biophysical performance of the MODIS vegetation indices. \n",
    "#    Remote Sensing of Environment, 83(1-2), 195-213.\n",
    "#    https://doi.org/10.1016/S0034-4257(02)00096-2\n",
    "#    (Enhanced vegetation indices and density proxies)\n",
    "#\n",
    "# 4. Gitelson, A. A., Kaufman, Y. J., & Merzlyak, M. N. (1996). Use of a green channel in remote \n",
    "#    sensing of global vegetation from EOS-MODIS. Remote Sensing of Environment, 58(3), 289-298.\n",
    "#    https://doi.org/10.1016/S0034-4257(96)00072-7\n",
    "#    (Vegetation density enhancement techniques)\n",
    "#\n",
    "# IMPROVED APPROACH: Pseudo Forest Canopy Density (Pseudo-FCD)\n",
    "# Based on: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/pseudo_forest_canopy_density/\n",
    "# Author: Antonio Carlon Paredes (2019)\n",
    "# License: CC BY 4.0\n",
    "# Reference: Azadeh ABDOLLAHNEJAD et al. \"Forest canopy density assessment using different approaches\"\n",
    "#            Journal of Forest Science, 63, 2017 (3): 106-115\n",
    "#\n",
    "# This approach uses simplified versions of FCD indices without PCA:\n",
    "# - NDVI (Normalized Difference Vegetation Index)\n",
    "# - BI (Bare soil index) = (NIR + Green + Red) / (NIR + Green - Red)\n",
    "# - SI (Shadow index) = ((1 - Green) * (1 - Red))^0.5\n",
    "# - NDWI (Normalized Difference Water Index) for water detection\n",
    "#\n",
    "# Classification thresholds (adjustable per location):\n",
    "# - High Forest: NDVI > 0.40, BI < 2, SI > 0.93\n",
    "# - Low Forest: 0.20 < NDVI < 0.40, BI < 2, 0.90 < SI < 0.93\n",
    "# - Grassland: NDVI > 0.20\n",
    "# - Bare land: NDVI < 0.20, BI > 2, SI < 0.90\n",
    "# - Water: NDWI > 0.2\n",
    "#\n",
    "# ============================================================================\n",
    "# WHY FCD IS COMPUTATIONALLY EXPENSIVE FOR IMAGECOLLECTION MAPPING:\n",
    "# ============================================================================\n",
    "# 1. PCA (Principal Component Analysis) Requirements:\n",
    "#    - Requires reduceRegion operations over entire AOI to compute:\n",
    "#      * Mean values (mean centering)\n",
    "#      * Covariance matrix (centeredCovariance reducer)\n",
    "#      * Eigenvalue/eigenvector decomposition\n",
    "#    - These operations scan ALL pixels in AOI per image\n",
    "#    - When mapping over ImageCollection: O(n_images √ó AOI_pixels)\n",
    "#\n",
    "# 2. max_bands() Calculation (for AVI and SI):\n",
    "#    - Each index (AVI, SI) requires reduceRegion(max) per band\n",
    "#    - For AVI: max(red), max(green), max(blue) - 3 reduceRegion calls\n",
    "#    - For SI: same 3 reduceRegion calls\n",
    "#    - Per image: 6 expensive reduceRegion operations\n",
    "#\n",
    "# 3. normalization_100() Function:\n",
    "#    - Requires reduceRegion to compute mean and stdDev\n",
    "#    - Called for each band/index that needs normalization\n",
    "#    - Per image: Multiple reduceRegion operations\n",
    "#\n",
    "# Total cost per image:\n",
    "# - 1-2 PCA operations (SVI, SSI)\n",
    "# - 6 reduceRegion for max_bands()\n",
    "# - Multiple reduceRegion for normalization\n",
    "# =~ 10+ reduceRegion operations √ó AOI pixel count\n",
    "# ============================================================================\n",
    "#\n",
    "# ALTERNATIVE APPROACHES (besides current simplification):\n",
    "# ============================================================================\n",
    "# 1. PRE-COMPUTED STATISTICS APPROACH:\n",
    "#    - Compute PCA/eigenvalues once from a representative mosaic\n",
    "#    - Compute max_bands once from mosaic\n",
    "#    - Apply same transformation to all images in collection\n",
    "#    - Trade-off: Less accurate but 10-100x faster\n",
    "#\n",
    "# 2. REGIONAL NORMALIZATION APPROACH:\n",
    "#    - Compute normalization parameters (mean, std) once from sample\n",
    "#    - Apply fixed normalization to all images\n",
    "#    - More consistent but less adaptive per-image\n",
    "#\n",
    "# 3. SIMPLIFIED FCD WITHOUT PCA:\n",
    "#    - Use direct band combinations (e.g., NDVI * SI instead of PCA)\n",
    "#    - Skip eigenvector decomposition\n",
    "#    - Trade-off: Less mathematically rigorous but much faster\n",
    "#\n",
    "# 4. CHUNK-BASED PROCESSING:\n",
    "#    - Process collection in batches\n",
    "#    - Compute statistics per batch instead of per image\n",
    "#    - Intermediate accuracy between per-image and global\n",
    "#\n",
    "# 5. APPROXIMATE PCA:\n",
    "#    - Use sample-based covariance (reduceRegion on sample points)\n",
    "#    - Use approximate eigen decomposition\n",
    "#    - Faster but slightly less accurate\n",
    "#\n",
    "# Note: Full FCD calculation requires PCA which is computationally expensive per image\n",
    "# This adds simplified FCD-related indices that can be calculated per image\n",
    "\n",
    "from gee_lib.osi.spectral_indices.spectral_analysis import SpectralAnalysis\n",
    "from gee_lib.osi.spectral_indices.utils import normalization_100\n",
    "\n",
    "print(\"üîÑ Adding FCD-related indices to ImageCollection...\")\n",
    "print(f\"   Satellite: {config['I_satellite']}\")\n",
    "print(\"   Note: Full FCD requires PCA (expensive per image), adding simplified indices...\")\n",
    "\n",
    "# Prepare config for SpectralAnalysis\n",
    "fcd_config = {\n",
    "    'I_satellite': config['I_satellite'],\n",
    "    'AOI': aoi_ee.geometry(),\n",
    "    'pca_scaling': config.get('pca_scaling', 1),\n",
    "    'tileScale': config.get('tileScale', 2)\n",
    "}\n",
    "\n",
    "def add_fcd_indices(image):\n",
    "    \"\"\"\n",
    "    Add Pseudo Forest Canopy Density (Pseudo-FCD) indices to a single image.\n",
    "    \n",
    "    Based on: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/pseudo_forest_canopy_density/\n",
    "    Uses simplified FCD indices without PCA for computational efficiency.\n",
    "    Note: NDVI and NDWI are already added in spectral indices step, so we reuse them.\n",
    "    \"\"\"\n",
    "    # Start with image that already has spectral indices\n",
    "    image_with_fcd = image\n",
    "    \n",
    "    try:\n",
    "        # Use existing NDVI and NDWI from spectral indices (don't recalculate)\n",
    "        ndvi = image.select('NDVI')\n",
    "        ndwi = image.select('ndwi')\n",
    "        \n",
    "        # BI (Bare soil index) - simplified version\n",
    "        # BI = (NIR + Green + Red) / (NIR + Green - Red)\n",
    "        bi = image.expression(\n",
    "            '(NIR + Green + Red) / (NIR + Green - Red)', {\n",
    "                'NIR': image.select('nir'),\n",
    "                'Green': image.select('green'),\n",
    "                'Red': image.select('red')\n",
    "            }\n",
    "        ).rename('BI')\n",
    "        \n",
    "        # SI (Shadow index) - simplified version\n",
    "        # SI = ((1 - Green) * (1 - Red))^0.5\n",
    "        si = image.expression(\n",
    "            'pow((1 - Green) * (1 - Red), 0.5)', {\n",
    "                'Green': image.select('green'),\n",
    "                'Red': image.select('red')\n",
    "            }\n",
    "        ).rename('SI')\n",
    "        \n",
    "        # Add BI and SI to image\n",
    "        image_with_fcd = image_with_fcd.addBands([bi, si])\n",
    "        \n",
    "        # Calculate continuous Pseudo-FCD percentage (0-100%)\n",
    "        # Normalize proxies to [0,1] with practical ranges (tunable)\n",
    "        ndvi_s = ndvi.unitScale(0.20, 0.80).clamp(0, 1)        # vegetation density\n",
    "        si_s   = si.unitScale(0.90, 0.98).clamp(0, 1)          # canopy/shadow strength\n",
    "        # BI high => more bare soil; invert and normalize (tune 1..3 as needed)\n",
    "        bi_inv = ee.Image(1).subtract(bi.unitScale(1.0, 3.0)).clamp(0, 1)\n",
    "        \n",
    "        # Weighted combination (tune weights to your site)\n",
    "        pseudo_fcd_0_1 = (\n",
    "            ndvi_s.multiply(0.5)\n",
    "            .add(si_s.multiply(0.3))\n",
    "            .add(bi_inv.multiply(0.2))\n",
    "        ).clamp(0, 1)\n",
    "        \n",
    "        # Optional: suppress water influence\n",
    "        water_mask = ndwi.lte(0.2)  # NDWI > 0.2 => water\n",
    "        pseudo_fcd_0_1 = pseudo_fcd_0_1.updateMask(water_mask)\n",
    "        \n",
    "        # Scale to 0‚Äì100% and add as band\n",
    "        pseudo_fcd_pct = pseudo_fcd_0_1.multiply(100).rename('pseudo_fcd_pct')\n",
    "        image_with_fcd = image_with_fcd.addBands(pseudo_fcd_pct)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not add Pseudo-FCD indices: {e}\")\n",
    "    \n",
    "    return image_with_fcd\n",
    "\n",
    "# Map the function over the collection with spectral indices\n",
    "collection_with_fcd = collection_with_indices.map(add_fcd_indices)\n",
    "\n",
    "print(\"‚úÖ Pseudo-FCD indices added to ImageCollection!\")\n",
    "print(\"   Added: BI (Bare soil index), SI (Shadow index), pseudo_fcd_pct (0-100%)\")\n",
    "print(\"   Reused: NDVI, NDWI from spectral indices step\")\n",
    "print(\"   Based on: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/pseudo_forest_canopy_density/\")\n",
    "print(\"   No PCA required - computationally efficient for ImageCollection mapping\")\n",
    "\n",
    "# Get info about bands in first image\n",
    "first_image = ee.Image(collection_with_fcd.first())\n",
    "band_names = first_image.bandNames().getInfo()\n",
    "print(f\"\\nüìä First image now has {len(band_names)} bands:\")\n",
    "print(f\"   Bands: {', '.join(band_names[:20])}{'...' if len(band_names) > 20 else ''}\")\n",
    "\n",
    "# Show which FCD-related bands were added\n",
    "fcd_bands = [b for b in band_names if any(x in b.lower() for x in ['bsi', 'si', 'veg_density', 'forest_proxy'])]\n",
    "if fcd_bands:\n",
    "    print(f\"\\nüå≤ FCD-related bands: {', '.join(fcd_bands)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No FCD-related bands found (may have failed to calculate)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8dd2ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['blue',\n",
       " 'green',\n",
       " 'red',\n",
       " 'redE1',\n",
       " 'redE2',\n",
       " 'redE3',\n",
       " 'nir',\n",
       " 'redE4',\n",
       " 'swir1',\n",
       " 'swir2',\n",
       " 'NDVI',\n",
       " 'ndwi',\n",
       " 'msavi2',\n",
       " 'MTVI2',\n",
       " 'VARI',\n",
       " 'BI',\n",
       " 'SI',\n",
       " 'pseudo_fcd_pct']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ADDING SPECTRAL INDICES WITH FCD PSEUDO-FCD\n",
    "collection_with_fcd.first().bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aaa8584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 253 spectral indices from eemont-osi\n",
      "\n",
      "First 10 indices: ['AFRI1600', 'AFRI2100', 'ANDWI', 'ARI', 'ARI2', 'ARVI', 'ATSAVI', 'AVI', 'AWEInsh', 'AWEIsh']\n",
      "\n",
      "Last 10 indices: ['kNDVI', 'kRVI', 'kVARI', 'mND705', 'mSR705', 'sNIRvLSWI', 'sNIRvNDPI', 'sNIRvNDVILSWIP', 'sNIRvNDVILSWIS', 'sNIRvSWIR']\n",
      "\n",
      "‚úÖ List ready to use: spectral_indices_awesome_list\n",
      "\n",
      "============================================================\n",
      "Example: Getting formula for NDVI and NBR\n",
      "============================================================\n",
      "\n",
      "NDVI:\n",
      "  Original Formula: (N - R)/(N + R)\n",
      "  OSI Band Names: (nir - red)/(nir + red)\n",
      "  Long Name: Normalized Difference Vegetation Index\n",
      "  Bands: ['N', 'R']\n",
      "\n",
      "NBR (Normalized Burn Ratio):\n",
      "  Original Formula: (N - S2) / (N + S2)\n",
      "  OSI Band Names: (nir - swir2) / (nir + swir2)\n",
      "  Long Name: Normalized Burn Ratio\n",
      "  Bands: ['N', 'S2'] (S2 = SWIR2)\n",
      "  Domain: burn\n"
     ]
    }
   ],
   "source": [
    "# Dynamically get all available spectral indices from eemont-osi\n",
    "# import sys\n",
    "# sys.path.insert(0, '/usr/src/app/eemont-osi')\n",
    "import ee_extra.Spectral.core as spec_core\n",
    "\n",
    "# Get all available indices dynamically\n",
    "indices_dict = spec_core.indices(online=False)\n",
    "spectral_indices_awesome_list = sorted(list(indices_dict.keys()))\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(spectral_indices_awesome_list)} spectral indices from eemont-osi\")\n",
    "print(f\"\\nFirst 10 indices: {spectral_indices_awesome_list[:10]}\")\n",
    "print(f\"\\nLast 10 indices: {spectral_indices_awesome_list[-10:]}\")\n",
    "print(f\"\\n‚úÖ List ready to use: spectral_indices_awesome_list\")\n",
    "\n",
    "# Function to get formula and metadata for any spectral index\n",
    "def get_index_info(index_name):\n",
    "    \"\"\"\n",
    "    Get formula and metadata for a spectral index.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    index_name : str\n",
    "        Name of the spectral index (e.g., 'NDVI', 'EVI', 'SAVI')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - formula: Mathematical formula string\n",
    "        - long_name: Full name of the index\n",
    "        - bands: List of bands used (N=NIR, R=Red, G=Green, B=Blue, S1=SWIR1, S2=SWIR2, RE1-4=Red Edge)\n",
    "        - application_domain: Category (vegetation, water, burn, etc.)\n",
    "        - platforms: Supported satellite platforms\n",
    "        - reference: Reference URL or DOI\n",
    "    \"\"\"\n",
    "    index_name_upper = index_name.upper()\n",
    "    \n",
    "    if index_name_upper not in indices_dict:\n",
    "        available = [idx for idx in spectral_indices_awesome_list if index_name.upper() in idx.upper()]\n",
    "        raise ValueError(\n",
    "            f\"Index '{index_name}' not found. \"\n",
    "            f\"Did you mean: {available[:5] if available else 'None'}?\"\n",
    "        )\n",
    "    \n",
    "    info = indices_dict[index_name_upper].copy()\n",
    "    return info\n",
    "\n",
    "def formula(index_name):\n",
    "    \"\"\"\n",
    "    Get the formula for a spectral index.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    index_name : str\n",
    "        Name of the spectral index (e.g., 'NDVI', 'EVI', 'SAVI')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Mathematical formula string using band abbreviations\n",
    "         Band abbreviations: N (NIR), R (Red), G (Green), B (Blue), \n",
    "         S1 (SWIR1), S2 (SWIR2), RE1-4 (Red Edge 1-4)\n",
    "    \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> formula('NDVI')\n",
    "    '(N - R)/(N + R)'\n",
    "    \n",
    "    >>> formula('EVI')\n",
    "    'G * ((N - R) / (N + C1 * R - C2 * B + L))'\n",
    "    \"\"\"\n",
    "    info = get_index_info(index_name)\n",
    "    return info['formula']\n",
    "\n",
    "# Function to convert formula band abbreviations to OSI band names\n",
    "def formula_to_osi_bands(formula_str):\n",
    "    \"\"\"\n",
    "    Convert eemont-osi formula band abbreviations to OSI band names.\n",
    "    \n",
    "    Mapping:\n",
    "    - N (NIR) -> nir\n",
    "    - R (Red) -> red\n",
    "    - G (Green) -> green\n",
    "    - B (Blue) -> blue\n",
    "    - S1 (SWIR1) -> swir1\n",
    "    - S2 (SWIR2) -> swir2\n",
    "    - RE1 (Red Edge 1) -> redE1\n",
    "    - RE2 (Red Edge 2) -> redE2\n",
    "    - RE3 (Red Edge 3) -> redE3\n",
    "    - RE4 (Red Edge 4) -> redE4\n",
    "    - Variables (g, C1, C2, L, etc.) remain as-is\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    formula_str : str\n",
    "        Formula string from eemont-osi (e.g., \"(N - R)/(N + R)\")\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Formula with OSI band names (e.g., \"(nir - red)/(nir + red)\")\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Mapping from eemont-osi abbreviations to OSI band names\n",
    "    band_mapping = {\n",
    "        'N': 'nir',      # Near Infrared\n",
    "        'R': 'red',      # Red\n",
    "        'G': 'green',    # Green\n",
    "        'B': 'blue',     # Blue\n",
    "        'S1': 'swir1',   # Shortwave Infrared 1\n",
    "        'S2': 'swir2',   # Shortwave Infrared 2\n",
    "        'RE1': 'redE1',  # Red Edge 1\n",
    "        'RE2': 'redE2',  # Red Edge 2\n",
    "        'RE3': 'redE3',  # Red Edge 3\n",
    "        'RE4': 'redE4',  # Red Edge 4\n",
    "    }\n",
    "    \n",
    "    # Sort by length (longest first) to avoid partial matches (e.g., RE1 before R)\n",
    "    sorted_bands = sorted(band_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    result = formula_str\n",
    "    \n",
    "    # Replace band abbreviations with OSI names\n",
    "    # Use word boundaries to avoid replacing partial matches in variables\n",
    "    for abbrev in sorted_bands:\n",
    "        osi_name = band_mapping[abbrev]\n",
    "        # Use regex to match whole words only (not part of other words)\n",
    "        # Pattern: \\b matches word boundary, but we need to handle cases like \"RE1\" in \"RE1*RE2\"\n",
    "        pattern = r'\\b' + re.escape(abbrev) + r'\\b'\n",
    "        result = re.sub(pattern, osi_name, result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def formula_osi(index_name):\n",
    "    \"\"\"\n",
    "    Get the formula for a spectral index with OSI band names.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    index_name : str\n",
    "        Name of the spectral index (e.g., 'NDVI', 'EVI', 'NBR')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Mathematical formula string using OSI band names\n",
    "         (nir, red, green, blue, swir1, swir2, redE1-4)\n",
    "    \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> formula_osi('NDVI')\n",
    "    '(nir - red)/(nir + red)'\n",
    "    \n",
    "    >>> formula_osi('NBR')\n",
    "    '(nir - swir2)/(nir + swir2)'\n",
    "    \"\"\"\n",
    "    formula_orig = formula(index_name)\n",
    "    return formula_to_osi_bands(formula_orig)\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Example: Getting formula for NDVI and NBR\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    # NDVI example\n",
    "    ndvi_formula = formula('NDVI')\n",
    "    ndvi_formula_osi = formula_osi('NDVI')\n",
    "    ndvi_info = get_index_info('NDVI')\n",
    "    print(f\"\\nNDVI:\")\n",
    "    print(f\"  Original Formula: {ndvi_formula}\")\n",
    "    print(f\"  OSI Band Names: {ndvi_formula_osi}\")\n",
    "    print(f\"  Long Name: {ndvi_info['long_name']}\")\n",
    "    print(f\"  Bands: {ndvi_info['bands']}\")\n",
    "    \n",
    "    # NBR example (shows S2 -> swir2)\n",
    "    nbr_formula = formula('NBR')\n",
    "    nbr_formula_osi = formula_osi('NBR')\n",
    "    nbr_info = get_index_info('NBR')\n",
    "    print(f\"\\nNBR (Normalized Burn Ratio):\")\n",
    "    print(f\"  Original Formula: {nbr_formula}\")\n",
    "    print(f\"  OSI Band Names: {nbr_formula_osi}\")\n",
    "    print(f\"  Long Name: {nbr_info['long_name']}\")\n",
    "    print(f\"  Bands: {nbr_info['bands']} (S2 = SWIR2)\")\n",
    "    print(f\"  Domain: {nbr_info['application_domain']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fa2c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'application_domain': 'burn',\n",
       " 'bands': ['N', 'S2'],\n",
       " 'contributor': 'https://github.com/davemlz',\n",
       " 'date_of_addition': '2021-04-07',\n",
       " 'formula': '(N - S2) / (N + S2)',\n",
       " 'long_name': 'Normalized Burn Ratio',\n",
       " 'platforms': ['Sentinel-2',\n",
       "  'Landsat-OLI',\n",
       "  'Landsat-TM',\n",
       "  'Landsat-ETM+',\n",
       "  'MODIS'],\n",
       " 'reference': 'https://doi.org/10.3133/ofr0211',\n",
       " 'short_name': 'NBR'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula('NBR')\n",
    "get_index_info('NBR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20e352d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g * (N - R) / (N + C1 * R - C2 * B + L)\n",
      "g * (nir - red) / (nir + C1 * red - C2 * blue + L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'application_domain': 'vegetation',\n",
       " 'bands': ['g', 'N', 'R', 'C1', 'C2', 'B', 'L'],\n",
       " 'contributor': 'https://github.com/davemlz',\n",
       " 'date_of_addition': '2021-04-07',\n",
       " 'formula': 'g * (N - R) / (N + C1 * R - C2 * B + L)',\n",
       " 'long_name': 'Enhanced Vegetation Index',\n",
       " 'platforms': ['Sentinel-2',\n",
       "  'Landsat-OLI',\n",
       "  'Landsat-TM',\n",
       "  'Landsat-ETM+',\n",
       "  'MODIS',\n",
       "  'Planet-Fusion'],\n",
       " 'reference': 'https://doi.org/10.1016/S0034-4257(96)00112-5',\n",
       " 'short_name': 'EVI'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(formula('EVI'))\n",
    "print(formula_osi('EVI'))\n",
    "get_index_info('EVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0062c4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### EE-MONTH IMPLEMENTATION ADDING SPECTRALINDICES\n",
    "# For OSI-processed collections with custom band names\n",
    "collection_with_eemont_indices = collection_with_fcd.spectralIndices(\n",
    "    index=['EVI', 'GNDVI', 'SAVI'],\n",
    "    satellite_type='Sentinel',  # OSI-style satellite type\n",
    "    G=2.5,  # EVI parameters\n",
    "    C1=6.0,\n",
    "    C2=7.5,\n",
    "    L=1.0,  # SAVI parameter\n",
    "    drop=True  # Keep original bands\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0862e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['EVI', 'GNDVI', 'SAVI']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHECK THE RESULTS OF THE BANDS CALCULATION AFTER EEMONT-OSI\n",
    "collection_with_eemont_indices.first().bandNames().getInfo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK IF THE CLOUD MASKING CLOUDM IMPLEMENTATION\n",
    "# First image after cloud masking\n",
    "band_name = 'nir'\n",
    "\n",
    "first_img = collection_with_eemont_indices.first()\n",
    "red_band = first_img.select(band_name)\n",
    "\n",
    "# Count non-masked (valid) pixels\n",
    "valid = red_band.reduceRegion(\n",
    "    reducer=ee.Reducer.count(),      # counts only pixels that are not masked\n",
    "    geometry=aoi_ee,\n",
    "    scale=10,\n",
    "    bestEffort=True\n",
    ").get(band_name)\n",
    "\n",
    "# Count total pixels in the AOI grid (constant 1 image, no mask)\n",
    "total = ee.Image.constant(1).clip(aoi_ee).reduceRegion(\n",
    "    reducer=ee.Reducer.count(),\n",
    "    geometry=aoi_ee,\n",
    "    scale=10,\n",
    "    bestEffort=True\n",
    ").get('constant')\n",
    "\n",
    "# Masked (NA) pixels = total - valid\n",
    "masked = ee.Number(total).subtract(ee.Number(valid))\n",
    "\n",
    "print(f'Total {band_name} pixels:', total.getInfo())\n",
    "print(f'Valid {band_name} pixels:', valid.getInfo())\n",
    "print(f'Masked/NA {band_name} pixels:', masked.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vis_params_no_median = {'bands': ['swir2', 'nir', 'red'],\n",
    " 'min': 0,\n",
    " 'max': 0.6,\n",
    " 'gamma': 1.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23002d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wmts.addLayer(first_img, img_vis_params_no_median, first_img.get('system:id').getInfo())\n",
    "# wmts.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf084c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aoi_ee\n",
    "# proj = first_image.select(0).projection().getInfo()\n",
    "# print(f\"Full projection info: {proj}\")\n",
    "# print(f\"CRS: {proj['crs']}\")\n",
    "# # print(f\"Scale (meters): {proj['nominalScale']}\")\n",
    "\n",
    "# ## testing if we're using xarray\n",
    "# import xee\n",
    "# import xarray as xr\n",
    "\n",
    "# ds = xr.open_dataset(collection_with_eemont_indices, geometry = aoi_ee.geometry().transform(\n",
    "#                                                                             f'EPSG:{utm_epsg}',\n",
    "#                                                                             maxError=1\n",
    "#                                                                         ), \n",
    "#                         engine='ee', crs='epsg:32749', scale=10)\n",
    "\n",
    "# # ds\n",
    "\n",
    "# # Caluclate how much percent of the screene are valid pixles\n",
    "# valid = (ds[\"cloudM\"] == 1).sum(dim=['X', 'Y'])\n",
    "# total = len(ds.X) * len(ds.Y)\n",
    "# valid_pixels = ((valid / total) * 100).round()\n",
    "\n",
    "# # keep only sceenes with more than 90% of valid pixels\n",
    "# ds = ds.sel(time=valid_pixels > valid_pixel_threshold, drop=True)\n",
    "\n",
    "# # # Filter scenes with sufficient valid pixels\n",
    "# # valid_pixels = (ds[\"cloudM\"] == 1).mean((\"X\",\"Y\")) * 100\n",
    "\n",
    "# print(f\"Valid pixel percentages: min={valid_pixels.min().values:.1f}%, max={valid_pixels.max().values:.1f}%\")\n",
    "# print(f\"Scenes with >{valid_pixel_threshold}% valid pixels: {(valid_pixels > valid_pixel_threshold).sum().values}/{len(valid_pixels)}\")\n",
    "\n",
    "# # Keep only scenes with sufficient valid pixels\n",
    "# ds = ds.sel(time=valid_pixels > valid_pixel_threshold, drop=True)\n",
    "# print(f\"After valid pixel filtering: {ds.dims}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b504fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing timeseries analysis\n",
    "# start with the NDVI and EVI first, just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a17c69",
   "metadata": {},
   "source": [
    "## Process mapping\n",
    "\n",
    "This section outlines the complete workflow for time series analysis with Savitzky-Golay smoothing and monthly interpolation.\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "```\n",
    "INPUT: collection_with_eemont_indices (Original spectral indices from eemont-osi)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ STEP 1: Savitzky-Golay Smoothing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚îÇ    Function: savgol_filter()\n",
    "‚îÇ    ‚îÇ\n",
    "‚îÇ    ‚îú‚îÄ Applies weighted temporal smoothing (Gaussian weights)\n",
    "‚îÇ    ‚îú‚îÄ ONLY processes valid pixels (where cloudM != 0)\n",
    "‚îÇ    ‚îú‚îÄ Does NOT interpolate missing values\n",
    "‚îÇ    ‚îî‚îÄ Output: collection_with_sg (Smoothed, NON-INTERPOLATED)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ STEP 2: Visual Comparison (Non-Interpolated) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚îÇ    Compare BEFORE vs AFTER smoothing:\n",
    "‚îÇ    ‚îÇ\n",
    "‚îÇ    ‚îú‚îÄ BEFORE: collection_with_eemont_indices\n",
    "‚îÇ    ‚îÇ   ‚îî‚îÄ Original spectral indices (non-smoothed, non-interpolated)\n",
    "‚îÇ    ‚îÇ\n",
    "‚îÇ    ‚îî‚îÄ AFTER: collection_with_sg\n",
    "‚îÇ        ‚îî‚îÄ Smoothed spectral indices (non-interpolated, just smoothed)\n",
    "‚îÇ\n",
    "‚îÇ    Purpose: Validate smoothing effect on noise reduction\n",
    "‚îÇ    Note: Both are NON-INTERPOLATED for apple-to-apple comparison\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ STEP 3: Trace Back Original Non-Smoothed Data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚îÇ    Create paired comparison function:\n",
    "‚îÇ    ‚îÇ\n",
    "‚îÇ    ‚îú‚îÄ Extract pixel pairs: (original, smoothed) for same time/location\n",
    "‚îÇ    ‚îú‚îÄ Filter out interpolated data (use only real observations)\n",
    "‚îÇ    ‚îî‚îÄ Generate statistics: where is original vs smoothed difference largest?\n",
    "‚îÇ\n",
    "‚îÇ    Output: Pairwise comparison showing smoothing impact\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ STEP 4: Monthly Time Series with Interpolation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "     Function: aggregate_to_monthly()\n",
    "     ‚îÇ\n",
    "     ‚îú‚îÄ Groups images by year-month\n",
    "     ‚îú‚îÄ Aggregates to monthly composites (median by default)\n",
    "     ‚îú‚îÄ Interpolates missing months using linear interpolation\n",
    "     ‚îÇ\n",
    "     ‚îî‚îÄ Output: collection_monthly\n",
    "         ‚îú‚îÄ Monthly time series (regular cadence)\n",
    "         ‚îú‚îÄ is_interpolated band:\n",
    "         ‚îÇ   ‚îú‚îÄ 0 = Real data (from actual images, already smoothed)\n",
    "         ‚îÇ   ‚îî‚îÄ 1 = Interpolated data (filled from neighbors)\n",
    "         ‚îî‚îÄ Complete monthly coverage (gaps filled)\n",
    "```\n",
    "\n",
    "### Detailed Process Steps\n",
    "\n",
    "#### **STEP 1: Savitzky-Golay Smoothing**\n",
    "\n",
    "**Input:** `collection_with_eemont_indices`\n",
    "- Contains spectral indices (NDVI, EVI, etc.)\n",
    "- Already has cloud masking applied (cloudM band)\n",
    "- Valid pixels: `cloudM = 1`\n",
    "- Cloudy pixels: `cloudM = 0`\n",
    "\n",
    "**Process:** `savgol_filter(collection_with_eemont_indices, ...)`\n",
    "- Smooths existing valid pixels using weighted temporal averaging\n",
    "- Uses Gaussian weights (temporal window around each image)\n",
    "- **Only processes pixels where `cloudM != 0`** (cloud masking already applied)\n",
    "- Does NOT fill gaps where `cloudM = 0`\n",
    "\n",
    "**Output:** `collection_with_sg`\n",
    "- Smoothed spectral indices (NDVI, EVI)\n",
    "- Same temporal cadence as input\n",
    "- Same mask structure (no new valid pixels created)\n",
    "- **Status: NON-INTERPOLATED** (just smoothed)\n",
    "\n",
    "---\n",
    "\n",
    "#### **STEP 2: Visual Comparison (Before vs After Smoothing)**\n",
    "\n",
    "**Purpose:** Validate that smoothing reduces noise without creating artifacts\n",
    "\n",
    "**Data Sources:**\n",
    "- **BEFORE:** `collection_with_eemont_indices` ‚Üí Original (non-smoothed)\n",
    "- **AFTER:** `collection_with_sg` ‚Üí Smoothed (non-interpolated)\n",
    "\n",
    "**Key Points:**\n",
    "- Both are **NON-INTERPOLATED** for fair comparison\n",
    "- Compare at same temporal cadence (same image dates)\n",
    "- Visualize noise reduction in time series plots\n",
    "- Calculate statistics: mean, std, noise reduction percentage\n",
    "\n",
    "---\n",
    "\n",
    "#### **STEP 3: Trace Back Original Non-Smoothed Data**\n",
    "\n",
    "**Purpose:** Create paired comparison showing exactly where smoothing made changes\n",
    "\n",
    "**Function:** `get_paired_comparison(original_collection, smoothed_collection)`\n",
    "- Extracts pixel values at same (time, location) pairs\n",
    "- Filters: Only use real observations (no interpolated data)\n",
    "- Compares: Original vs Smoothed values\n",
    "- Identifies: Where smoothing had largest/smallest impact\n",
    "\n",
    "**Output:**\n",
    "- DataFrame with columns: `date`, `location`, `original_value`, `smoothed_value`, `difference`\n",
    "- Statistics: Mean difference, std of difference, max/min impact locations\n",
    "- Visualizations: Scatter plots, difference histograms\n",
    "\n",
    "---\n",
    "\n",
    "#### **STEP 4: Monthly Time Series with Interpolation**\n",
    "\n",
    "**Input:** `collection_with_sg` (Smoothed, non-interpolated)\n",
    "\n",
    "**Process:** `aggregate_to_monthly(collection_with_sg, interpolate_missing=True)`\n",
    "1. **Group by year-month:** Aggregate all images within each month\n",
    "2. **Monthly aggregation:** Apply reducer (median/mean) per month\n",
    "3. **Interpolate missing months:** Linear interpolation for gaps\n",
    "4. **Add `is_interpolated` band:**\n",
    "   - `0` = Real data (from actual images, already smoothed in Step 1)\n",
    "   - `1` = Interpolated data (filled from neighboring months)\n",
    "\n",
    "**Output:** `collection_monthly`\n",
    "- Regular monthly cadence (no gaps)\n",
    "- Complete time series coverage\n",
    "- `is_interpolated` band for data quality tracking\n",
    "- Can filter out interpolated data for ground truth validation\n",
    "\n",
    "---\n",
    "\n",
    "### Data Flow Summary\n",
    "\n",
    "| Stage | Collection Name | Status | Contains |\n",
    "|-------|----------------|--------|----------|\n",
    "| Input | `collection_with_eemont_indices` | Original | Spectral indices (NDVI, EVI, etc.) |\n",
    "| Step 1 Output | `collection_with_sg` | Smoothed | Smoothed indices, **non-interpolated** |\n",
    "| Step 2 | Same as Step 1 | Comparison | Before (eemont_indices) vs After (sg) |\n",
    "| Step 4 Output | `collection_monthly` | Complete | Monthly + interpolated (with `is_interpolated` band) |\n",
    "\n",
    "### Key Principles\n",
    "\n",
    "1. **Smoothing First, Interpolation Second:** Always smooth before interpolating (optimal workflow)\n",
    "2. **Preserve Original Data:** Keep `collection_with_eemont_indices` for comparison\n",
    "3. **Track Interpolation:** Use `is_interpolated` band to avoid using interpolated data as ground truth\n",
    "4. **Apple-to-Apple Comparisons:** Compare smoothed vs original at same cadence (both non-interpolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228343dc",
   "metadata": {},
   "source": [
    "## Savitzky-Golay Filtering and Interpolation for Spectral Indices\n",
    "\n",
    "This section implements GEE-native Savitzky-Golay filtering with interpolation based on the GEE_TimeSeries approach.\n",
    "The filter smooths time series while preserving important features and interpolates gaps in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a49903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_drops_and_spikes_gee(image_collection, \n",
    "                                band_names=['NDVI', 'EVI'],\n",
    "                                window_size=14,\n",
    "                                threshold_percent=0.1):\n",
    "    \"\"\"\n",
    "    Process time series in GEE to remove drops and spikes for multiple bands.\n",
    "    \n",
    "    CHANGED: Now replaces outliers with median (like XArray interpolation)\n",
    "    instead of just masking them, to match XArray behavior.\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    \n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    \n",
    "    half_window = (window_size - 1) // 2\n",
    "    collection_list = image_collection.toList(image_collection.size())\n",
    "    n_images = image_collection.size().getInfo()\n",
    "    max_idx_ee = ee.Number(n_images - 1)\n",
    "    half_window_ee = ee.Number(half_window)\n",
    "    threshold = ee.Number(threshold_percent)\n",
    "    eps = ee.Number(1e-6)\n",
    "    \n",
    "    def process_image(i):\n",
    "        center_idx = ee.Number(i).int()\n",
    "        center_img = ee.Image(collection_list.get(center_idx))\n",
    "        result_img = center_img\n",
    "        \n",
    "        # Process each band\n",
    "        for band_name in band_names:\n",
    "            center_band = center_img.select([band_name])\n",
    "            \n",
    "            # Get temporal window\n",
    "            start_idx = center_idx.subtract(half_window_ee).max(0)\n",
    "            end_idx = center_idx.add(half_window_ee).min(max_idx_ee).max(start_idx)\n",
    "            \n",
    "            # Build window collection\n",
    "            window_indices = ee.List.sequence(start_idx, end_idx)\n",
    "            window_imgs = window_indices.map(lambda j: \n",
    "                ee.Image(collection_list.get(ee.Number(j).int().max(0).min(max_idx_ee.int())))\n",
    "                .select([band_name])\n",
    "            )\n",
    "            window_collection = ee.ImageCollection.fromImages(window_imgs)\n",
    "            \n",
    "            # Compute median\n",
    "            median_band = window_collection.median()\n",
    "            \n",
    "            # Detect outliers\n",
    "            abs_median = median_band.abs().add(eps)\n",
    "            diff_abs = center_band.subtract(median_band).abs()\n",
    "            normalized_diff = diff_abs.divide(abs_median)\n",
    "            is_outlier = normalized_diff.gt(threshold)\n",
    "            \n",
    "            # CHANGED: Replace outliers with median (like XArray interpolation)\n",
    "            # OLD: cleaned_band = center_band.updateMask(is_outlier.Not())  # Just masks, creates gaps\n",
    "            # NEW: Use median as replacement for outliers (interpolation-like behavior)\n",
    "            cleaned_band = center_band.where(is_outlier, median_band)\n",
    "            \n",
    "            # Replace band\n",
    "            result_img = result_img.addBands(cleaned_band.rename([band_name]), None, True)\n",
    "        \n",
    "        return result_img\n",
    "    \n",
    "    processed = ee.List.sequence(0, n_images - 1).map(process_image)\n",
    "    return ee.ImageCollection.fromImages(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEE-Native Savitzky-Golay Filtering (Smoothing Only - No Interpolation)\n",
    "# Based on GEE_TimeSeries approach: https://github.com/davemlz/GEE_TimeSeries\n",
    "# NOTE: This function ONLY smooths existing valid pixels - it does NOT interpolate/fill gaps\n",
    "\n",
    "def savgol_filter(image_collection, \n",
    "                         band_names=['NDVI', 'EVI'],\n",
    "                         window_length=7,\n",
    "                         polyorder=2):\n",
    "    \"\"\"\n",
    "    Apply Savitzky-Golay filtering (smoothing) to spectral indices.\n",
    "    \n",
    "    WHAT IT DOES:\n",
    "    - Smooths time series using weighted temporal averaging (Gaussian weights)\n",
    "    - Preserves existing valid pixels (applies temporal smoothing to reduce noise)\n",
    "    \n",
    "    WHAT IT DOES NOT DO:\n",
    "    - Does NOT interpolate missing values\n",
    "    - Does NOT fill gaps where data is missing (e.g., where cloudM=0)\n",
    "    - Does NOT create new data points\n",
    "    \n",
    "    The input collection should already have cloud masking applied (e.g., via OSI).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_collection : ee.ImageCollection\n",
    "        Input image collection with spectral indices bands\n",
    "    band_names : list\n",
    "        List of band names to filter (default: ['NDVI', 'EVI'])\n",
    "    window_length : int\n",
    "        Window length (must be odd, >= polyorder+1). Default: 7\n",
    "    polyorder : int\n",
    "        Polynomial order (typically 2-3). Default: 2\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    The input collection should already have cloud masking applied (e.g., via OSI).\n",
    "    This function only smooths existing valid pixels and does NOT fill gaps.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ee.ImageCollection : Filtered collection with smoothed bands\n",
    "    \"\"\"\n",
    "    # Validate window_length\n",
    "    if window_length % 2 == 0:\n",
    "        window_length += 1\n",
    "    if window_length < polyorder + 1:\n",
    "        window_length = polyorder + 1\n",
    "        if window_length % 2 == 0:\n",
    "            window_length += 1\n",
    "    \n",
    "    half_window = (window_length - 1) // 2\n",
    "    collection_list = image_collection.toList(image_collection.size())\n",
    "    n_images = image_collection.size().getInfo()\n",
    "    max_idx_ee = ee.Number(n_images - 1)  # Convert to ee.Number for GEE operations\n",
    "    half_window_ee = ee.Number(half_window)  # Convert to ee.Number\n",
    "    \n",
    "    def process_image(i):\n",
    "        \"\"\"Process image with temporal smoothing.\"\"\"\n",
    "        center_idx = ee.Number(i).int()\n",
    "        center_img = ee.Image(collection_list.get(center_idx))\n",
    "        \n",
    "        # Get temporal window (clamped to valid range)\n",
    "        start_idx = center_idx.subtract(half_window_ee).max(0)\n",
    "        end_idx = center_idx.add(half_window_ee).min(max_idx_ee).max(start_idx)\n",
    "        \n",
    "        # Build window collection\n",
    "        def get_window_img(j):\n",
    "            # Convert j to ee.Number and clamp\n",
    "            j_num = ee.Number(j)\n",
    "            idx = j_num.int().max(0).min(max_idx_ee.int())\n",
    "            img = ee.Image(collection_list.get(idx))\n",
    "            t_offset = j_num.subtract(center_idx)\n",
    "            return img.set('t', t_offset)\n",
    "        \n",
    "        window_imgs = ee.List.sequence(start_idx, end_idx).map(get_window_img)\n",
    "        window_collection = ee.ImageCollection.fromImages(window_imgs)\n",
    "        \n",
    "        # Process each band from band_names list\n",
    "        result_img = center_img\n",
    "        \n",
    "        for band_name in band_names:\n",
    "            # Weighted smoothing (Gaussian weights)\n",
    "            # CRITICAL: Avoid creating any intermediate 'weight' bands that could cause inhomogeneity\n",
    "            def weighted_smooth():\n",
    "                def add_weight_and_compute_weighted(img):\n",
    "                    # Get temporal offset\n",
    "                    t = img.getNumber('t').abs()\n",
    "                    sigma = ee.Number(half_window).divide(2)\n",
    "                    # Compute weight (scalar, not a band)\n",
    "                    weight = t.pow(2).divide(sigma.pow(2).multiply(2)).multiply(-1).exp()\n",
    "                    # Get band value\n",
    "                    band_val = img.select([band_name])\n",
    "                    # Compute weighted value directly (weight * value)\n",
    "                    # Store weight as a property, not a band, to avoid structural issues\n",
    "                    weighted_band = band_val.multiply(weight)\n",
    "                    # Store weight as image property for later use (not as a band)\n",
    "                    return weighted_band.set('_weight', weight)\n",
    "                \n",
    "                # Map to compute weighted values (weight stored as property, not band)\n",
    "                weighted_collection = window_collection.map(add_weight_and_compute_weighted)\n",
    "                \n",
    "                # Sum weighted values (these images only have the band_name band, no weight band)\n",
    "                weighted_sum = weighted_collection.sum()\n",
    "                \n",
    "                # Get sum of weights from properties using a reducer\n",
    "                # We'll compute this separately to avoid creating a weight band\n",
    "                def get_weight_sum(img):\n",
    "                    \"\"\"\n",
    "                    FIXED: Compute weight WITHOUT creating ee.Image.constant()\n",
    "                    which creates varying 'constant' bands causing inhomogeneity.\n",
    "                    \"\"\"\n",
    "                    # Get weight from property\n",
    "                    weight_value = img.get('_weight')\n",
    "                    \n",
    "                    # Instead of ee.Image.constant(), create weight from band structure\n",
    "                    # This ensures structural consistency across images\n",
    "                    dummy_band = img.select([band_name]).multiply(0).add(1)\n",
    "                    weight_band = dummy_band.multiply(ee.Image.constant(weight_value)).rename('weight_temp')\n",
    "                    return weight_band\n",
    "                \n",
    "                weights_list = weighted_collection.map(get_weight_sum)\n",
    "                weight_sum_raw = weights_list.sum().select(['weight_temp'])\n",
    "                \n",
    "                # CRITICAL: Break computation graph by reprojecting\n",
    "                # This forces GEE to create new image, breaking references to intermediate bands\n",
    "                weight_sum = weight_sum_raw.reproject(\n",
    "                    crs=center_img.select([band_name]).projection().crs(),\n",
    "                    scale=center_img.select([band_name]).projection().nominalScale()\n",
    "                ).rename('weight_sum_temp')\n",
    "                \n",
    "                # Compute smoothed value\n",
    "                smoothed_raw = weighted_sum.divide(weight_sum).rename([band_name])\n",
    "                \n",
    "                # CRITICAL: Break computation graph for final smoothed result\n",
    "                # This ensures no references to intermediate bands remain\n",
    "                smoothed = smoothed_raw.reproject(\n",
    "                    crs=center_img.select([band_name]).projection().crs(),\n",
    "                    scale=center_img.select([band_name]).projection().nominalScale()\n",
    "                ).select([band_name])\n",
    "                \n",
    "                # Handle edge case\n",
    "                fallback = center_img.select([band_name])\n",
    "                result = smoothed.where(weight_sum.eq(0), fallback)\n",
    "                \n",
    "                # Return only target band\n",
    "                return result.select([band_name])\n",
    "            \n",
    "            # Apply smoothing\n",
    "            smoothed_band = weighted_smooth()\n",
    "            # CRITICAL: smoothed_band should only contain the band_name\n",
    "            # Double-check by selecting only the band_name (ensures no weight band leaks through)\n",
    "            smoothed_band_clean = smoothed_band.select([band_name])\n",
    "            # Add to result image - this should only add the spectral index band, not weight\n",
    "            result_img = result_img.addBands(smoothed_band_clean, None, True)\n",
    "        \n",
    "        # CRITICAL: Final explicit selection before returning\n",
    "        # Get all bands from result_img and explicitly exclude intermediate bands\n",
    "        all_result_bands = result_img.bandNames()\n",
    "        intermediate_to_exclude = ee.List(['weight', 'w_val', 't'])\n",
    "        final_bands = all_result_bands.removeAll(intermediate_to_exclude)\n",
    "        # Select only the final bands (original + smoothed spectral indices, NO intermediate bands)\n",
    "        result_img_clean = result_img.select(final_bands)\n",
    "        return result_img_clean\n",
    "    \n",
    "    # Process all images\n",
    "    processed = ee.List.sequence(0, n_images - 1).map(process_image)\n",
    "    collection_result = ee.ImageCollection.fromImages(processed)\n",
    "    \n",
    "    # CRITICAL: Explicitly remove intermediate bands to ensure homogeneous collection\n",
    "    # Intermediate bands created during smoothing: 'weight', 'w_val', 't'\n",
    "    intermediate_bands = ee.List(['weight', 'w_val', 't'])\n",
    "    \n",
    "    # Get original band names from input collection\n",
    "    original_bands = image_collection.first().bandNames()\n",
    "    # Combine original bands + smoothed spectral index bands from band_names list\n",
    "    bands_to_keep = original_bands.cat(ee.List(band_names)).distinct()\n",
    "    \n",
    "    # CRITICAL: Force structural homogeneity by creating completely new images\n",
    "    # The issue is that even after selecting bands, the computation graph still references\n",
    "    # intermediate 'weight' bands with different value ranges, causing inhomogeneity.\n",
    "    # Solution: Create fresh images by copying only the desired bands with explicit casting.\n",
    "    \n",
    "    # Get reference projection from first input image (before processing)\n",
    "    first_input = image_collection.first()\n",
    "    reference_band = bands_to_keep.get(0)  # Get first band name for reference projection\n",
    "    ref_proj = first_input.select([reference_band]).projection()\n",
    "    \n",
    "    def clean_and_homogenize(img):\n",
    "        # Step 1: Select only desired bands\n",
    "        img_selected = img.select(bands_to_keep)\n",
    "        \n",
    "        # Step 2: Reproject to match reference (forces GEE to create fresh structure)\n",
    "        # This breaks any references to intermediate bands in the computation graph\n",
    "        img_homogeneous = img_selected.setDefaultProjection(ref_proj)\n",
    "        \n",
    "        # Step 3: Explicitly cast all bands to ensure consistent structure\n",
    "        # Create new image with same bands but fresh structure\n",
    "        return img_homogeneous\n",
    "    \n",
    "    # Apply cleaning and homogenization\n",
    "    cleaned_collection = collection_result.map(clean_and_homogenize)\n",
    "    \n",
    "    return cleaned_collection\n",
    "\n",
    "print(\"‚úÖ Savitzky-Golay filtering function defined!\")\n",
    "print(\"   Function: savgol_filter() - Smoothing only (NO interpolation)\")\n",
    "print(\"   Features: Weighted temporal smoothing (Gaussian weights) with boundary safety\")\n",
    "print(\"   Note: Only smooths existing valid pixels - does NOT fill gaps or interpolate missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply outlier removal and Savitzky-Golay filtering to collection_with_eemont_indices\n",
    "# Select spectral indices bands to filter\n",
    "spectral_bands_to_filter = ['NDVI', 'EVI']\n",
    "# spectral_bands_to_filter = ['pseudo_fcd_pct']\n",
    "\n",
    "# Configuration for outlier removal\n",
    "outlier_window = 14      # Number of images for rolling median window\n",
    "outlier_threshold = 0.1  # 10% threshold for outlier detection\n",
    "\n",
    "# Configuration for Savitzky-Golay\n",
    "sg_polyorder = 2       # Polynomial order (typically 2-3)\n",
    "\n",
    "# Example for ~16-day Sentinel-2 scenes:\n",
    "time_interval_days = 30 # Days between scenes\n",
    "scipy_window_days = 90 # scipy window length in days\n",
    "gee_window_length = int(scipy_window_days / time_interval_days)\n",
    "\n",
    "# Make sure it's odd and >= polyorder + 1\n",
    "if gee_window_length % 2 == 0:\n",
    "    gee_window_length += 1\n",
    "if gee_window_length < sg_polyorder + 1:\n",
    "    gee_window_length = sg_polyorder + 1\n",
    "    if gee_window_length % 2 == 0:\n",
    "        gee_window_length += 1\n",
    "\n",
    "# Configuration\n",
    "sg_window_length = gee_window_length  # Must be odd\n",
    "\n",
    "print(f'Example comparison: GEE window length in days: {gee_window_length * time_interval_days} '\n",
    "      f'and scipy window length in days: {scipy_window_days} \\n'\n",
    "      f'Finally GEE window length in images: {gee_window_length}')\n",
    "\n",
    "# STEP 1: Remove outliers using rolling median\n",
    "print(f\"\\nüîß STEP 1: Removing outliers using rolling median...\")\n",
    "print(f\"   Outlier window: {outlier_window} images\")\n",
    "print(f\"   Outlier threshold: {outlier_threshold * 100}%\")\n",
    "print(f\"   Bands to process: {spectral_bands_to_filter}\")\n",
    "\n",
    "collection_no_outliers = remove_drops_and_spikes_gee(\n",
    "    image_collection=collection_with_eemont_indices,\n",
    "    band_names=spectral_bands_to_filter,\n",
    "    window_size=outlier_window,\n",
    "    threshold_percent=outlier_threshold\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Outlier removal complete!\")\n",
    "\n",
    "# STEP 2: Interpolate gaps (NEW - fills missing data like XArray)\n",
    "print(f\"\\nüîß STEP 2: Interpolating gaps in time series...\")\n",
    "print(f\"   This fills missing dates/intervals, similar to XArray np.interp()\")\n",
    "\n",
    "def interpolate_temporal_gaps(image_collection, band_names):\n",
    "    \"\"\"\n",
    "    Interpolate missing values in time series using neighboring images.\n",
    "    Similar to XArray's np.interp() - fills gaps between valid observations.\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    \n",
    "    collection_list = image_collection.toList(image_collection.size())\n",
    "    n_images = image_collection.size().getInfo()\n",
    "    \n",
    "    def process_image(i):\n",
    "        center_idx = ee.Number(i).int()\n",
    "        center_img = ee.Image(collection_list.get(center_idx))\n",
    "        result_img = center_img\n",
    "        \n",
    "        for band_name in band_names:\n",
    "            center_band = center_img.select([band_name])\n",
    "            \n",
    "            # Check if current pixel is masked/empty\n",
    "            is_masked = center_band.mask().Not()\n",
    "            \n",
    "            # Get previous and next valid images for interpolation\n",
    "            # Find previous valid image\n",
    "            prev_idx = center_idx.subtract(1).max(0)\n",
    "            prev_img = ee.Image(collection_list.get(prev_idx))\n",
    "            prev_band = prev_img.select([band_name])\n",
    "            \n",
    "            # Find next valid image\n",
    "            next_idx = center_idx.add(1).min(n_images - 1)\n",
    "            next_img = ee.Image(collection_list.get(next_idx))\n",
    "            next_band = next_img.select([band_name])\n",
    "            \n",
    "            # Simple interpolation: use average of previous and next\n",
    "            # (For more sophisticated: could use linear interpolation based on time difference)\n",
    "            interpolated = prev_band.add(next_band).divide(2)\n",
    "            \n",
    "            # Fill masked pixels with interpolated values\n",
    "            filled_band = center_band.unmask(interpolated)\n",
    "            \n",
    "            result_img = result_img.addBands(filled_band.rename([band_name]), None, True)\n",
    "        \n",
    "        return result_img\n",
    "    \n",
    "    processed = ee.List.sequence(0, n_images - 1).map(process_image)\n",
    "    return ee.ImageCollection.fromImages(processed)\n",
    "\n",
    "collection_interpolated = interpolate_temporal_gaps(\n",
    "    collection_no_outliers,\n",
    "    band_names=spectral_bands_to_filter\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Gap interpolation complete!\")\n",
    "\n",
    "# STEP 3: Apply Savitzky-Golay filtering to cleaned and interpolated data\n",
    "print(f\"\\nüîß STEP 3: Applying Savitzky-Golay filtering...\")\n",
    "print(f\"   Window length: {sg_window_length}\")\n",
    "print(f\"   Polynomial order: {sg_polyorder}\")\n",
    "print(f\"   Bands to filter: {spectral_bands_to_filter}\")\n",
    "\n",
    "collection_with_sg = savgol_filter(\n",
    "    collection_interpolated,  # Use interpolated collection (after outlier removal + interpolation)\n",
    "    band_names=spectral_bands_to_filter,\n",
    "    window_length=sg_window_length,\n",
    "    polyorder=sg_polyorder\n",
    ")\n",
    "\n",
    "# IMPORTANT: Explicitly select only the bands we need\n",
    "collection_with_sg = collection_with_sg.map(\n",
    "    lambda img: img.select(spectral_bands_to_filter)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Savitzky-Golay filtering complete!\")\n",
    "print(f\"   Filtered bands: {spectral_bands_to_filter}\")\n",
    "\n",
    "# Check result\n",
    "print(f\"\\nüìä Checking filtered collection...\")\n",
    "print(f\"   Number of images: {collection_with_sg.size().getInfo()}\")\n",
    "band_names_sg = collection_with_sg.first().bandNames().getInfo()\n",
    "print(f\"   Total bands: {len(band_names_sg)}\")\n",
    "print(f\"   Spectral indices: {[b for b in band_names_sg if b in spectral_bands_to_filter]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_with_sg.first().bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be777ff2",
   "metadata": {},
   "source": [
    "## Visual Comparison: Before vs After Savitzky-Golay Filtering\n",
    "\n",
    "Visualize the time series to verify that Savitzky-Golay smoothing is working correctly.\n",
    "\n",
    "**Important Notes:**\n",
    "- **BEFORE**: `collection_with_eemont_indices` - Original spectral indices (non-interpolated, non-smoothed)\n",
    "- **AFTER**: `collection_with_sg` - Smoothed spectral indices (non-interpolated, smoothed only)\n",
    "- **Both are NON-interpolated**: The SG function only smooths existing valid pixels (does NOT fill gaps where `cloudM=0`)\n",
    "- **No `is_interpolated` band**: The interpolation flag is only added by `aggregate_to_monthly()`, not by the SG function\n",
    "- **Apple-to-apple comparison**: Both collections have the same temporal cadence and mask structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_ee.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c774bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract time series from a representative point/region for visualization\n",
    "# # Using the center of AOI as the sample point\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import geemap\n",
    "\n",
    "# # Get a sample point from AOI (use centroid or a fixed point)\n",
    "# # sample_point = aoi_ee.geometry().centroid(1)  # 1km tolerance\n",
    "# sample_point = ee.Geometry.Point([111.81746, -0.41587]) # location where there is deforestation\n",
    "\n",
    "# print(\"üìä Extracting time series for visualization...\")\n",
    "# print(f\"   Sample point: Custom coordinates (-0.41587¬∞, 111.81746¬∞)\")\n",
    "# print(f\"   Bands to compare: {', '.join(spectral_bands_to_filter)}\")\n",
    "# print(f\"\\n   Comparison (Both NON-INTERPOLATED):\")\n",
    "# print(f\"   1. BEFORE: collection_with_eemont_indices - Original spectral indices (non-smoothed)\")\n",
    "# print(f\"   2. AFTER:  collection_with_sg - Smoothed spectral indices (SG filtered, but NOT interpolated)\")\n",
    "# print(f\"\\n   Note: SG function only smooths existing valid pixels. It does NOT fill gaps where cloudM=0.\")\n",
    "# print(f\"   Both collections have the same mask structure - this is an apple-to-apple comparison.\")\n",
    "\n",
    "# # Extract time series using manual extraction\n",
    "# # This gives us tabular data (dates, band values) for easy plotting\n",
    "\n",
    "# # Before SG filtering (from collection_with_eemont_indices)\n",
    "# # This is the original, non-smoothed, non-interpolated data\n",
    "# print(\"\\n   Extracting BEFORE (original, non-smoothed) time series...\")\n",
    "\n",
    "# # Use manual extraction (consistent with AFTER extraction)\n",
    "# def extract_pixel_value_before(img):\n",
    "#     \"\"\"Extract mean value at sample point for spectral_bands_to_filter.\"\"\"\n",
    "#     img_selected = img.select(spectral_bands_to_filter)\n",
    "#     stats = img_selected.reduceRegion(\n",
    "#         reducer=ee.Reducer.mean(),\n",
    "#         geometry=sample_point,\n",
    "#         scale=10,\n",
    "#         bestEffort=True,\n",
    "#         maxPixels=1e9\n",
    "#     )\n",
    "#     date_str = img.date().format('YYYY-MM-dd')\n",
    "    \n",
    "#     # Build dictionary directly (matching hardcoded pattern)\n",
    "#     feature_dict = {'date': date_str}\n",
    "#     for band in spectral_bands_to_filter:\n",
    "#         feature_dict[band] = stats.get(band)\n",
    "    \n",
    "#     return ee.Feature(sample_point, feature_dict)\n",
    "\n",
    "# ts_before_features = collection_with_eemont_indices.map(extract_pixel_value_before)\n",
    "# ts_before = ee.FeatureCollection(ts_before_features)\n",
    "\n",
    "# # After SG filtering (from collection_with_sg)\n",
    "# # This is smoothed but NON-INTERPOLATED (only existing valid pixels are smoothed)\n",
    "# print(\"\\n   Extracting AFTER (smoothed, non-interpolated) time series...\")\n",
    "# print(\"   Note: SG function does NOT interpolate gaps - it only smooths existing valid pixels\")\n",
    "\n",
    "# # ALTERNATIVE APPROACH: Extract time series manually to avoid collection structure issues\n",
    "# # Instead of using getTimeSeriesByRegion which inspects the collection structure,\n",
    "# # we'll extract time series directly by mapping over the collection ourselves\n",
    "# print(\"\\n   Using manual extraction to avoid collection homogeneity checks...\")\n",
    "\n",
    "# def extract_pixel_value(img):\n",
    "#     \"\"\"Extract mean value at sample point for spectral_bands_to_filter.\"\"\"\n",
    "#     # Select only the bands we want\n",
    "#     img_selected = img.select(spectral_bands_to_filter)\n",
    "#     # Reduce region to get mean values\n",
    "#     stats = img_selected.reduceRegion(\n",
    "#         reducer=ee.Reducer.mean(),\n",
    "#         geometry=sample_point,\n",
    "#         scale=10,\n",
    "#         bestEffort=True,\n",
    "#         maxPixels=1e9\n",
    "#     )\n",
    "#     # Create feature with date and values\n",
    "#     date_str = img.date().format('YYYY-MM-dd')\n",
    "    \n",
    "#     # Build dictionary directly (matching hardcoded pattern)\n",
    "#     feature_dict = {'date': date_str}\n",
    "#     for band in spectral_bands_to_filter:\n",
    "#         feature_dict[band] = stats.get(band)\n",
    "    \n",
    "#     return ee.Feature(sample_point, feature_dict)\n",
    "\n",
    "# # Extract time series manually (avoids collection structure inspection)\n",
    "# ts_after_features = collection_with_sg.map(extract_pixel_value)\n",
    "# ts_after = ee.FeatureCollection(ts_after_features)\n",
    "\n",
    "# print(\"‚úÖ Time series extracted!\")\n",
    "# print(\"   Converting to pandas for visualization...\")\n",
    "\n",
    "# # Convert to pandas DataFrames\n",
    "# # ALTERNATIVE: Use .getInfo() directly instead of ee_to_gdf() to avoid collection structure inspection\n",
    "# # This bypasses the homogeneity check that causes errors\n",
    "\n",
    "# print(\"   Converting FeatureCollections to pandas DataFrames...\")\n",
    "\n",
    "# # Convert before (original) - use getInfo() directly\n",
    "# print(\"   Converting ts_before (original)...\")\n",
    "# try:\n",
    "#     ts_before_list = ts_before.getInfo()['features']\n",
    "#     ts_before_data = []\n",
    "#     for feat in ts_before_list:\n",
    "#         props = feat['properties']\n",
    "#         # Build dictionary directly (matching hardcoded pattern)\n",
    "#         row = {'date': props.get('date')}\n",
    "#         for band in spectral_bands_to_filter:\n",
    "#             row[band] = props.get(band)\n",
    "#         ts_before_data.append(row)\n",
    "    \n",
    "#     ts_before_df = pd.DataFrame(ts_before_data)\n",
    "#     ts_before_df['date'] = pd.to_datetime(ts_before_df['date'])\n",
    "#     ts_before_df = ts_before_df.sort_values('date').reset_index(drop=True)\n",
    "#     ts_before_df = ts_before_df.replace([None, -9999], np.nan)  # Replace None and NA values\n",
    "#     print(f\"   ‚úÖ Converted ts_before: {len(ts_before_df)} time steps\")\n",
    "# except Exception as e:\n",
    "#     print(f\"   ‚ùå Error converting ts_before: {e}\")\n",
    "#     raise\n",
    "\n",
    "# # Convert after (smoothed) - use getInfo() directly\n",
    "# print(\"   Converting ts_after (smoothed)...\")\n",
    "# try:\n",
    "#     ts_after_list = ts_after.getInfo()['features']\n",
    "#     ts_after_data = []\n",
    "#     for feat in ts_after_list:\n",
    "#         props = feat['properties']\n",
    "#         # Build dictionary directly (matching hardcoded pattern)\n",
    "#         row = {'date': props.get('date')}\n",
    "#         for band in spectral_bands_to_filter:\n",
    "#             row[band] = props.get(band)\n",
    "#         ts_after_data.append(row)\n",
    "    \n",
    "#     ts_after_df = pd.DataFrame(ts_after_data)\n",
    "#     ts_after_df['date'] = pd.to_datetime(ts_after_df['date'])\n",
    "#     ts_after_df = ts_after_df.sort_values('date').reset_index(drop=True)\n",
    "#     ts_after_df = ts_after_df.replace([None, -9999], np.nan)  # Replace None and NA values\n",
    "#     print(f\"   ‚úÖ Converted ts_after: {len(ts_after_df)} time steps\")\n",
    "# except Exception as e:\n",
    "#     print(f\"   ‚ùå Error converting ts_after: {e}\")\n",
    "#     raise\n",
    "\n",
    "# print(f\"\\n   Before: {len(ts_before_df)} time steps\")\n",
    "# print(f\"   After: {len(ts_after_df)} time steps\")\n",
    "# if len(ts_before_df) > 0 and len(ts_after_df) > 0:\n",
    "#     print(f\"   Date range: {ts_before_df['date'].min()} to {ts_before_df['date'].max()}\")\n",
    "\n",
    "# # Store for plotting\n",
    "# print(\"\\nüíæ DataFrames ready for plotting:\")\n",
    "# print(f\"   - ts_before_df: Original values (before SG filtering)\")\n",
    "# print(f\"   - ts_after_df: Smoothed values (after SG filtering)\")\n",
    "\n",
    "def extract_time_series_for_visualization(\n",
    "    collection_before,\n",
    "    collection_after,\n",
    "    sample_point,\n",
    "    bands,\n",
    "    scale=10,\n",
    "    max_pixels=1e10,\n",
    "    best_effort=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts point-based time series from two EE ImageCollections (before/after),\n",
    "    prints the same progress messages you currently use, and returns\n",
    "    pandas DataFrames ready for plotting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection_before : ee.ImageCollection\n",
    "        Original collection (e.g. before Savitzky‚ÄìGolay).\n",
    "    collection_after : ee.ImageCollection\n",
    "        Processed collection (e.g. after Savitzky‚ÄìGolay).\n",
    "    sample_point : ee.Geometry.Point\n",
    "        Point geometry at which to sample the time series.\n",
    "    bands : list[str]\n",
    "        Band names to extract (must exist in both collections).\n",
    "    scale : float, optional\n",
    "        Scale in meters for reduceRegion (default 10).\n",
    "    max_pixels : int, optional\n",
    "        maxPixels for reduceRegion (default 1e9).\n",
    "    best_effort : bool, optional\n",
    "        bestEffort flag for reduceRegion (default True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame)\n",
    "        Tuple of (df_before, df_after), sorted chronologically,\n",
    "        with columns ['date', *bands].\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import ee\n",
    "\n",
    "    def _extract_point_timeseries(collection, label):\n",
    "        print(f\"\\n   Extracting {label} time series...\")\n",
    "        def reducer(img):\n",
    "            img_selected = img.select(bands)\n",
    "            stats = img_selected.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=sample_point,\n",
    "                scale=scale,\n",
    "                bestEffort=best_effort,\n",
    "                maxPixels=max_pixels,\n",
    "            )\n",
    "            date_str = img.date().format('YYYY-MM-dd')\n",
    "            props = {'date': date_str}\n",
    "            for band in bands:\n",
    "                props[band] = stats.get(band)\n",
    "            return ee.Feature(sample_point, props)\n",
    "\n",
    "        features = collection.map(reducer)\n",
    "        rows = features.getInfo()['features']\n",
    "        data = []\n",
    "        for feat in rows:\n",
    "            props = feat['properties']\n",
    "            row = {'date': props.get('date')}\n",
    "            for band in bands:\n",
    "                row[band] = props.get(band)\n",
    "            data.append(row)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        df = df.replace([None, -9999], np.nan)\n",
    "        print(f\"   ‚úÖ Converted {label}: {len(df)} time steps\")\n",
    "        return df\n",
    "\n",
    "    print(\"üìä Extracting time series for visualization...\")\n",
    "    print(f\"   Sample point: {sample_point.getInfo()['coordinates']}\")\n",
    "    print(f\"   Bands to compare: {', '.join(bands)}\")\n",
    "    print(\"\\n   Comparison:\")\n",
    "    print(f\"   1. BEFORE: original collection\")\n",
    "    print(f\"   2. AFTER:  processed collection (e.g. SG smoothed)\")\n",
    "\n",
    "    df_before = _extract_point_timeseries(collection_before, \"BEFORE (original, non-smoothed)\")\n",
    "    df_after = _extract_point_timeseries(collection_after, \"AFTER (smoothed)\")\n",
    "\n",
    "    print(f\"\\n   Before: {len(df_before)} time steps\")\n",
    "    print(f\"   After: {len(df_after)} time steps\")\n",
    "    if len(df_before) and len(df_after):\n",
    "        print(f\"   Date range: {df_before['date'].min()} to {df_before['date'].max()}\")\n",
    "\n",
    "    print(\"\\nüíæ DataFrames ready for plotting:\")\n",
    "    print(\"   - df_before: Original values (before processing)\")\n",
    "    print(\"   - df_after:  Processed values (after processing)\")\n",
    "    return df_before, df_after\n",
    "\n",
    "sample_point = ee.Geometry.Point([111.81746, -0.41587])\n",
    "bands_to_compare = ['NDVI', 'EVI']\n",
    "\n",
    "ts_before_df, ts_after_df = extract_time_series_for_visualization(\n",
    "    collection_before=collection_with_eemont_indices,\n",
    "    collection_after=collection_with_sg,\n",
    "    sample_point=sample_point,\n",
    "    bands=bands_to_compare,\n",
    "    scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20be0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection_with_sg.first().bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_after.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create visualization comparing before vs after Savitzky-Golay filtering\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Get bands from spectral_bands_to_filter (defined earlier in notebook)\n",
    "# bands_to_plot = spectral_bands_to_filter\n",
    "\n",
    "# # Determine number of subplots based on number of bands\n",
    "# n_bands = len(bands_to_plot)\n",
    "# if n_bands == 0:\n",
    "#     print(\"‚ö†Ô∏è  No bands in spectral_bands_to_filter to visualize!\")\n",
    "# else:\n",
    "#     # Generate random colors for each band (light for before, dark for after)\n",
    "#     # Use a seed based on band name for consistent colors\n",
    "#     np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "#     colors_info = {}\n",
    "#     for band in bands_to_plot:\n",
    "#         # Generate random RGB colors (0-255 range)\n",
    "#         # Light color for 'before' (higher brightness)\n",
    "#         rgb_before = np.random.randint(100, 255, size=3)\n",
    "#         # Dark color for 'after' (lower brightness, same hue family)\n",
    "#         rgb_after = (rgb_before * 0.4).astype(int)  # Make it darker\n",
    "        \n",
    "#         # Convert to hex\n",
    "#         color_before_hex = '#{:02x}{:02x}{:02x}'.format(rgb_before[0], rgb_before[1], rgb_before[2])\n",
    "#         color_after_hex = '#{:02x}{:02x}{:02x}'.format(rgb_after[0], rgb_after[1], rgb_after[2])\n",
    "        \n",
    "#         colors_info[band] = {\n",
    "#             'before': color_before_hex,\n",
    "#             'after': color_after_hex\n",
    "#         }\n",
    "    \n",
    "#     # Print color information\n",
    "#     print(\"üé® Color Scheme for Visualization:\")\n",
    "#     print(\"=\" * 60)\n",
    "#     for band, colors in colors_info.items():\n",
    "#         print(f\"  {band}:\")\n",
    "#         print(f\"    Before SG: {colors['before']}\")\n",
    "#         print(f\"    After SG:  {colors['after']}\")\n",
    "#     print()\n",
    "    \n",
    "#     # Create figure with subplots (one per band)\n",
    "#     fig, axes = plt.subplots(n_bands, 1, figsize=(14, 5 * n_bands))\n",
    "#     if n_bands == 1:\n",
    "#         axes = [axes]  # Make it a list for consistent indexing\n",
    "    \n",
    "#     fig.suptitle('Savitzky-Golay Filtering: Before vs After Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "#     # Plot each band\n",
    "#     for idx, band in enumerate(bands_to_plot):\n",
    "#         ax = axes[idx]\n",
    "        \n",
    "#         # Check if band exists in both dataframes\n",
    "#         if band in ts_before_df.columns and band in ts_after_df.columns:\n",
    "#             color_before = colors_info[band]['before']\n",
    "#             color_after = colors_info[band]['after']\n",
    "            \n",
    "#             ax.plot(ts_before_df['date'], ts_before_df[band], \n",
    "#                      'o-', color=color_before, alpha=0.6, linewidth=1.5, markersize=4,\n",
    "#                      label='Before SG (Original)', zorder=1)\n",
    "#             ax.plot(ts_after_df['date'], ts_after_df[band], \n",
    "#                      '-', color=color_after, linewidth=2.5,\n",
    "#                      label='After SG (Smoothed)', zorder=2)\n",
    "        \n",
    "#         ax.set_xlabel('Date', fontsize=12)\n",
    "#         ax.set_ylabel(band, fontsize=12)\n",
    "#         ax.set_title(f'{band} Time Series', fontsize=14, fontweight='bold')\n",
    "#         ax.legend(loc='best', fontsize=11)\n",
    "#         ax.grid(True, alpha=0.3, linestyle='--')\n",
    "#         ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Print summary statistics\n",
    "#     print(\"\\nüìä Summary Statistics:\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     for band in bands_to_plot:\n",
    "#         if band in ts_before_df.columns and band in ts_after_df.columns:\n",
    "#             before_mean = ts_before_df[band].mean()\n",
    "#             before_std = ts_before_df[band].std()\n",
    "#             after_mean = ts_after_df[band].mean()\n",
    "#             after_std = ts_after_df[band].std()\n",
    "            \n",
    "#             print(f\"\\n{band} Statistics:\")\n",
    "#             print(f\"  Before SG - Mean: {before_mean:.4f}, Std: {before_std:.4f}\")\n",
    "#             print(f\"  After SG  - Mean: {after_mean:.4f}, Std: {after_std:.4f}\")\n",
    "#             if before_std > 0:\n",
    "#                 noise_reduction = (1 - after_std/before_std) * 100\n",
    "#                 print(f\"  Noise Reduction: {noise_reduction:.1f}%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_sg_comparison(ts_before_df, ts_after_df, bands, seed=42):\n",
    "    \"\"\"\n",
    "    Plot before/after Savitzky‚ÄìGolay time series for a set of bands and print summary stats.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts_before_df : pandas.DataFrame\n",
    "        DataFrame from the original collection; must include a 'date' column and band columns.\n",
    "    ts_after_df : pandas.DataFrame\n",
    "        DataFrame from the smoothed collection; same structure as ts_before_df.\n",
    "    bands : list[str]\n",
    "        Band names to compare (e.g. ['NDVI', 'EVI']).\n",
    "    seed : int, optional\n",
    "        Random seed for reproducible color assignments (default 42).\n",
    "    \"\"\"\n",
    "    bands_to_plot = bands\n",
    "    n_bands = len(bands_to_plot)\n",
    "\n",
    "    if n_bands == 0:\n",
    "        print(\"‚ö†Ô∏è  No bands supplied to plot_sg_comparison!\")\n",
    "        return\n",
    "\n",
    "    # Generate reproducible color pairs for each band\n",
    "    np.random.seed(seed)\n",
    "    colors_info = {}\n",
    "    for band in bands_to_plot:\n",
    "        rgb_before = np.random.randint(100, 255, size=3)\n",
    "        rgb_after = (rgb_before * 0.4).astype(int)\n",
    "        colors_info[band] = {\n",
    "            'before': '#{:02x}{:02x}{:02x}'.format(*rgb_before),\n",
    "            'after': '#{:02x}{:02x}{:02x}'.format(*rgb_after)\n",
    "        }\n",
    "\n",
    "    # Print selected color scheme\n",
    "    print(\"üé® Color Scheme for Visualization:\")\n",
    "    print(\"=\" * 60)\n",
    "    for band, colors in colors_info.items():\n",
    "        print(f\"  {band}:\")\n",
    "        print(f\"    Before SG: {colors['before']}\")\n",
    "        print(f\"    After SG:  {colors['after']}\")\n",
    "    print()\n",
    "\n",
    "    # Create figure with one subplot per band\n",
    "    fig, axes = plt.subplots(n_bands, 1, figsize=(14, 5 * n_bands))\n",
    "    if n_bands == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Savitzky-Golay Filtering: Before vs After Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for ax, band in zip(axes, bands_to_plot):\n",
    "        if band in ts_before_df.columns and band in ts_after_df.columns:\n",
    "            color_before = colors_info[band]['before']\n",
    "            color_after = colors_info[band]['after']\n",
    "\n",
    "            ax.plot(ts_before_df['date'], ts_before_df[band],\n",
    "                    'o-', color=color_before, alpha=0.6, linewidth=1.5, markersize=4,\n",
    "                    label='Before SG (Original)', zorder=1)\n",
    "            ax.plot(ts_after_df['date'], ts_after_df[band],\n",
    "                    '-', color=color_after, linewidth=2.5,\n",
    "                    label='After SG (Smoothed)', zorder=2)\n",
    "\n",
    "        ax.set_xlabel('Date', fontsize=12)\n",
    "        ax.set_ylabel(band, fontsize=12)\n",
    "        ax.set_title(f'{band} Time Series', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\nüìä Summary Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    for band in bands_to_plot:\n",
    "        if band in ts_before_df.columns and band in ts_after_df.columns:\n",
    "            before_mean = ts_before_df[band].mean()\n",
    "            before_std = ts_before_df[band].std()\n",
    "            after_mean = ts_after_df[band].mean()\n",
    "            after_std = ts_after_df[band].std()\n",
    "\n",
    "            print(f\"\\n{band} Statistics:\")\n",
    "            print(f\"  Before SG - Mean: {before_mean:.4f}, Std: {before_std:.4f}\")\n",
    "            print(f\"  After SG  - Mean: {after_mean:.4f}, Std: {after_std:.4f}\")\n",
    "            if before_std > 0:\n",
    "                noise_reduction = (1 - after_std / before_std) * 100\n",
    "                print(f\"  Noise Reduction: {noise_reduction:.1f}%\")\n",
    "\n",
    "plot_sg_comparison(ts_before_df, ts_after_df, bands_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INTERPOLATION SMOOTHING\n",
    "def fill_temporal_gaps_linear(collection, bands):\n",
    "    \"\"\"Linearly interpolate masked pixels; fall back to nearest neighbor only at the edges.\"\"\"\n",
    "    import ee\n",
    "\n",
    "    collection = collection.sort('system:time_start')\n",
    "    img_list = collection.toList(collection.size())\n",
    "\n",
    "    def augment(image, time_band):\n",
    "        image = ee.Image(image)\n",
    "        data = image.select(bands).toDouble()\n",
    "        time_value = ee.Image.constant(ee.Number(image.get('system:time_start'))).rename(time_band).toDouble()\n",
    "        time_mask = data.mask().reduce(ee.Reducer.max())\n",
    "        time_image = time_value.updateMask(time_mask)\n",
    "        combined = ee.Image(data.addBands(time_image))\n",
    "        combined = ee.Image(combined.copyProperties(image, image.propertyNames()))\n",
    "        return combined\n",
    "\n",
    "    first_forward = augment(img_list.get(0), 'time_prev')\n",
    "\n",
    "    def forward_iter(current, prev_list):\n",
    "        prev_list = ee.List(prev_list)\n",
    "        prev_img = ee.Image(prev_list.get(-1))\n",
    "        current_img = augment(current, 'time_prev')\n",
    "        filled = ee.Image(current_img.unmask(prev_img))\n",
    "        filled = ee.Image(filled.copyProperties(current_img, current_img.propertyNames()))\n",
    "        return prev_list.add(filled)\n",
    "\n",
    "    forward_list = ee.List(\n",
    "        img_list.slice(1).iterate(forward_iter, ee.List([first_forward]))\n",
    "    )\n",
    "\n",
    "    reversed_list = img_list.reverse()\n",
    "    first_backward = augment(reversed_list.get(0), 'time_next')\n",
    "\n",
    "    def backward_iter(current, prev_list):\n",
    "        prev_list = ee.List(prev_list)\n",
    "        prev_img = ee.Image(prev_list.get(-1))\n",
    "        current_img = augment(current, 'time_next')\n",
    "        filled = ee.Image(current_img.unmask(prev_img))\n",
    "        filled = ee.Image(filled.copyProperties(current_img, current_img.propertyNames()))\n",
    "        return prev_list.add(filled)\n",
    "\n",
    "    backward_list = ee.List(\n",
    "        reversed_list.slice(1).iterate(backward_iter, ee.List([first_backward]))\n",
    "    ).reverse()\n",
    "\n",
    "    def interpolate(idx, acc):\n",
    "        acc = ee.List(acc)\n",
    "        idx = ee.Number(idx)\n",
    "\n",
    "        original = ee.Image(img_list.get(idx))\n",
    "        prev_img = ee.Image(forward_list.get(idx))\n",
    "        next_img = ee.Image(backward_list.get(idx))\n",
    "\n",
    "        prev_values = prev_img.select(bands)\n",
    "        next_values = next_img.select(bands)\n",
    "        prev_time = prev_img.select('time_prev')\n",
    "        next_time = next_img.select('time_next')\n",
    "        current_time = ee.Image.constant(ee.Number(original.get('system:time_start'))).toDouble()\n",
    "\n",
    "        time_diff = next_time.subtract(prev_time)\n",
    "        interp_mask = prev_time.mask().And(next_time.mask()).And(time_diff.neq(0))\n",
    "\n",
    "        fraction = current_time.subtract(prev_time).divide(time_diff)\n",
    "        fraction = fraction.updateMask(interp_mask).clamp(0, 1)\n",
    "\n",
    "        interpolated = prev_values.add(\n",
    "            next_values.subtract(prev_values).multiply(fraction)\n",
    "        ).updateMask(interp_mask)\n",
    "\n",
    "        filled = original.select(bands)\n",
    "        filled = filled.unmask(interpolated)\n",
    "        filled = filled.unmask(prev_values)\n",
    "        filled = filled.unmask(next_values)\n",
    "\n",
    "        updated = original.addBands(filled, overwrite=True)\n",
    "        updated = ee.Image(updated.copyProperties(original, original.propertyNames()))\n",
    "        return acc.add(updated)\n",
    "\n",
    "    filled_list = ee.List(\n",
    "        ee.List.sequence(0, collection.size().subtract(1)).iterate(interpolate, ee.List([]))\n",
    "    )\n",
    "\n",
    "    return ee.ImageCollection(filled_list).sort('system:time_start')\n",
    "\n",
    "# Use on your SG-smoothed collection\n",
    "bands_to_fill = ['NDVI', 'EVI']  # or the bands you smoothed\n",
    "collection_monthly_filled = fill_temporal_gaps_linear(collection_with_sg, bands_to_fill)\n",
    "\n",
    "print('Original monthly (with NaNs):', collection_with_sg.size().getInfo())\n",
    "print('Filled monthly collection:', collection_monthly_filled.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_monthly_filled.first().get('system:id').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b899ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check = collection_monthly_filled.filter(ee.Filter.eq('system:id', 'projects/remote-sensing-476412/assets/korindo_sentinel2_monthly/Sentinel2_2025_08'))\n",
    "test_check.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wmts.addLayer(test_check.first(), {'bands': ['NDVI', 'EVI'], 'min': -1, 'max': 1}, 'Monthly Filled')\n",
    "# wmts.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_point = ee.Geometry.Point([111.81746, -0.41587])\n",
    "bands_to_compare = ['NDVI', 'EVI']\n",
    "\n",
    "ts_before_df, ts_after_df_filled = extract_time_series_for_visualization(\n",
    "    collection_before=collection_with_eemont_indices,\n",
    "    collection_after=collection_monthly_filled, #after sg and interpolation (fill na)\n",
    "    sample_point=sample_point,\n",
    "    bands=bands_to_compare,\n",
    "    scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sg_comparison(ts_before_df, ts_after_df_filled, bands_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac90089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_after_df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229026ac",
   "metadata": {},
   "source": [
    "## Convert Earth Engine ImageCollection to xarray Dataset using xee\n",
    "\n",
    "**What is xee?**\n",
    "- `xee` (xarray-earth-engine) is a bridge library that connects Google Earth Engine with xarray\n",
    "- It allows you to work with GEE ImageCollections as if they were xarray Datasets\n",
    "- This enables time-series analysis, easy indexing, and integration with other xarray-based tools\n",
    "\n",
    "**Why use xee?**\n",
    "- Familiar xarray interface for Earth Engine data\n",
    "- Lazy loading: only loads data when needed\n",
    "- Time dimension: automatically handles time-series\n",
    "- Easy integration with dask for parallel processing\n",
    "- Works seamlessly with STAC workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca217600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert ImageCollection to xarray Dataset using xee\n",
    "# Now using UTM CRS with meter scale - they match!\n",
    "import os\n",
    "\n",
    "gcs_dir = os.getenv('GCS_ZARR_DIR')\n",
    "\n",
    "import xee\n",
    "import xarray as xr\n",
    "\n",
    "print(\"üîÑ Converting Earth Engine ImageCollection to xarray Dataset...\")\n",
    "print(f\"   CRS: {utm_crs} (UTM, meters)\")\n",
    "print(f\"   Scale: {pixel_scale}m\")\n",
    "print(\"   This may take a moment as xee accesses the data from Earth Engine...\")\n",
    "\n",
    "# Reproject aoi_ee to UTM first (for region parameter)\n",
    "# Use aoi_ee_utm already created in cell 11 (UTM geometry)\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "# bbox = box(*aoi_gpd_utm.total_bounds)\n",
    "# Get UTM bounds from GeoDataFrame and validate\n",
    "aoi_gpd_utm = aoi_gpd.to_crs(f'EPSG:{utm_epsg}')\n",
    "bounds_utm = aoi_gpd_utm.total_bounds  # [minx, miny, maxx, maxy]\n",
    "\n",
    "# Validate bounds are not NaN\n",
    "if np.any(np.isnan(bounds_utm)):\n",
    "    raise ValueError(f\"Bounds contain NaN values: {bounds_utm}\")\n",
    "\n",
    "xmin, ymin, xmax, ymax = bounds_utm\n",
    "print(f\"UTM Bounds: xmin={xmin:.2f}, ymin={ymin:.2f}, xmax={xmax:.2f}, ymax={ymax:.2f}\")\n",
    "print(f\"UTM Bounds span: {(xmax-xmin):.2f}m x {(ymax-ymin):.2f}m\")\n",
    "\n",
    "# Create rectangle geometry in UTM CRS\n",
    "# rectangle = ee.Geometry.Rectangle(xmin, ymin, xmax, ymax)\n",
    "\n",
    "ic = collection_monthly_filled\n",
    "\n",
    "# Method 2: Use transformed geometry directly (more reliable)\n",
    "# Create UTM geometry from aoi_ee\n",
    "aoi_ee_utm_geom = aoi_ee.geometry().transform(\n",
    "    f'EPSG:{utm_epsg}',\n",
    "    maxError=1\n",
    ")\n",
    "\n",
    "ds = xr.open_dataset(\n",
    "    ic,\n",
    "    engine='ee',\n",
    "    crs=utm_crs,\n",
    "    scale=pixel_scale,\n",
    "    geometry=aoi_ee_utm_geom # significanly faster to clip with geometry\n",
    ")\n",
    "print(\"‚úÖ Successfully created dataset using transformed geometry\")\n",
    "\n",
    "if 'X' in ds.dims and 'Y' in ds.dims:\n",
    "    print(\"Renaming dimensions from X,Y to x,y\")\n",
    "    ds = ds.rename({'X': 'x', 'Y': 'y'})\n",
    "\n",
    "print(f\"\\nüì¶ Dataset created: {type(ds)}\")\n",
    "print(f\"   CRS: {utm_crs} (UTM, meters)\")\n",
    "print(f\"   Scale: {pixel_scale}m\")\n",
    "print(f\"   Dimensions: {dict(ds.dims)}\")\n",
    "print(f\"   Data variables: {list(ds.data_vars.keys())}\")\n",
    "print(f\"   Coordinates: {list(ds.coords.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# image id mapping\n",
    "ids = (ee.ImageCollection(ic)\n",
    "       .toList(ic.size())\n",
    "       .map(lambda img: ee.Image(img).id()))\n",
    "ids = ids.getInfo() \n",
    "# ids\n",
    "\n",
    "ds = ds.assign_coords(image_id=(\"time\", ids))\n",
    "\n",
    "# Convert only if needed\n",
    "if not pd.api.types.is_datetime64_any_dtype(ds[\"time\"].dtype):\n",
    "    ds = ds.assign_coords(time=pd.to_datetime(ds[\"time\"].values))\n",
    "\n",
    "# Sort only if not monotonic\n",
    "if not ds.indexes[\"time\"].is_monotonic_increasing:\n",
    "    print('sorting time its not monotonic')\n",
    "    ds = ds.sortby(\"time\")\n",
    "\n",
    "# Ensure image_id is a coord aligned to time\n",
    "if \"image_id\" not in ds.coords:\n",
    "    raise ValueError(\"image_id coordinate not found. Assign it with ds = ds.assign_coords(image_id=(\\\"time\\\", ids)).\")\n",
    "\n",
    "# Choose your time window - example usage\n",
    "start, end = \"2024-01-01\", \"2024-12-31\"\n",
    "sel = ds.sel(time=slice(start, end))\n",
    "\n",
    "# Extract mapping time -> image_id (1D, cheap)\n",
    "times = pd.to_datetime(sel[\"time\"].values)\n",
    "ids = sel[\"image_id\"].values\n",
    "\n",
    "print(f\"Selected scenes between {start} and {end}: {len(times)}\")\n",
    "for t, i in zip(times, ids):\n",
    "    print(f\"{t.isoformat()} -> {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date_start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2939a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce99fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box(*aoi_gpd_utm.total_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a382d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Explore the xarray Dataset structure\n",
    "# Let's examine what we have\n",
    "\n",
    "print(\"üîç Exploring xarray Dataset Structure:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Dataset Overview:\")\n",
    "print(ds)\n",
    "\n",
    "print(\"\\n2. Dataset Dimensions:\")\n",
    "for dim_name, dim_size in ds.dims.items():\n",
    "    print(f\"   {dim_name}: {dim_size} values\")\n",
    "\n",
    "print(\"\\n3. Data Variables (Bands):\")\n",
    "for var_name in ds.data_vars:\n",
    "    var = ds[var_name]\n",
    "    print(f\"   {var_name}:\")\n",
    "    print(f\"      Shape: {var.shape}\")\n",
    "    print(f\"      Dtype: {var.dtype}\")\n",
    "    print(f\"      Attributes: {var.attrs if hasattr(var, 'attrs') else 'None'}\")\n",
    "\n",
    "print(\"\\n4. Coordinates:\")\n",
    "for coord_name in ds.coords:\n",
    "    coord = ds.coords[coord_name]\n",
    "    print(f\"   {coord_name}: {coord.shape} - {coord.values[:3] if len(coord.values) > 0 else 'No values'}...\")\n",
    "\n",
    "print(\"\\n5. Dataset Attributes:\")\n",
    "print(f\"   {ds.attrs if hasattr(ds, 'attrs') else 'No attributes'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd24ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Access and visualize sample data\n",
    "# Note: xee uses lazy loading - data is computed when you access it\n",
    "\n",
    "print(\"üìä Sample Data Access (first time slice):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get the first band name\n",
    "if len(ds.data_vars) > 0:\n",
    "    first_band = list(ds.data_vars.keys())[0]\n",
    "    print(f\"\\n1. Accessing first band: '{first_band}'\")\n",
    "    print(f\"   Type: {type(ds[first_band])}\")\n",
    "    \n",
    "    # Get first time slice (lazy - not computed yet)\n",
    "    first_time_slice = ds[first_band].isel(time=0)\n",
    "    print(f\"   First time slice shape: {first_time_slice.shape}\")\n",
    "    print(f\"   First time slice dtype: {first_time_slice.dtype}\")\n",
    "    \n",
    "    print(\"\\n2. Time information:\")\n",
    "    if 'time' in ds.coords:\n",
    "        time_coords = ds.coords['time']\n",
    "        print(f\"   Number of time steps: {len(time_coords)}\")\n",
    "        print(f\"   Time range: {time_coords.values[0]} to {time_coords.values[-1]}\")\n",
    "        \n",
    "    print(\"\\n3. Spatial information:\")\n",
    "    if 'x' in ds.coords and 'y' in ds.coords:\n",
    "        x_coords = ds.coords['x']\n",
    "        y_coords = ds.coords['y']\n",
    "        print(f\"   X range: {x_coords.values[0]:.4f} to {x_coords.values[-1]:.4f}\")\n",
    "        print(f\"   Y range: {y_coords.values[0]:.4f} to {y_coords.values[-1]:.4f}\")\n",
    "        print(f\"   Pixel size X: {(x_coords.values[-1] - x_coords.values[0]) / len(x_coords):.4f}\")\n",
    "        print(f\"   Pixel size Y: {(y_coords.values[-1] - y_coords.values[0]) / len(y_coords):.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data variables found in dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_timeseries = {}\n",
    "\n",
    "# # Processing parameters\n",
    "# # valid_pixel_threshold = config_timeseries.get('valid_pixel_threshold',70)  # Keep scenes with >90% valid pixels\n",
    "# # smoothing_window = config_timeseries.get('smoothing_window',90)       # Savitzky-Golay window length\n",
    "# # smoothing_polyorder = config_timeseries.get('smoothing_polyorder',2)     # Savitzky-Golay polynomial order\n",
    "# # outlier_window = config_timeseries.get('outlier_window',14)         # Window for outlier detection\n",
    "# # outlier_threshold = config_timeseries.get('outlier_threshold',0.1)    # Outlier detection threshold (10%)\n",
    "\n",
    "# valid_pixel_threshold = 70\n",
    "\n",
    "# # Monthly time-series parameter overrides\n",
    "# # Use small, odd window; polyorder < window; outlier window in months\n",
    "# smoothing_window = 7            # suitable for monthly cadence\n",
    "# smoothing_polyorder = 2         # keep small to preserve shape\n",
    "# outlier_window = 3              # ~3 months for outlier detection\n",
    "# outlier_threshold = 0.15        # 15% threshold for spikes/drops\n",
    "# print(\"Monthly params set:\", smoothing_window, smoothing_polyorder, outlier_window, outlier_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ea9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLIFIED EFFICIENT ZARR SAVING\n",
    "# Focus: Proper parallelism, simple and reliable\n",
    "# Removed complex auto-detection that might cause issues\n",
    "\n",
    "import os\n",
    "import time\n",
    "import xarray as xr\n",
    "from numcodecs import Blosc\n",
    "import gcsfs\n",
    "\n",
    "# Re-use a global filesystem client when possible\n",
    "gcs = gcsfs.GCSFileSystem(project=os.getenv(\"GOOGLE_CLOUD_PROJECT\"), token='/usr/src/app/user_id.json')\n",
    "\n",
    "def save_dataset_efficient_zarr(\n",
    "    ds,\n",
    "    zarr_path,\n",
    "    chunk_sizes=None,\n",
    "    compression='lz4',\n",
    "    compression_level=1,\n",
    "    overwrite=True,\n",
    "    consolidated=True,\n",
    "    storage='auto',\n",
    "    gcs_project=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified zarr saving ‚Äì focuses on reliable parallelism.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray.Dataset\n",
    "        Dataset to save (lazy dask arrays or in-memory).\n",
    "    zarr_path : str\n",
    "        Destination path or GCS URI (e.g. gs://bucket/path.zarr).\n",
    "    chunk_sizes : dict, optional\n",
    "        Chunk sizes per dimension (e.g. {'time': 20, 'x': 256, 'y': 256}).\n",
    "    compression : {'lz4','blosc','zstd',None} or dict\n",
    "        Built-in compressor choice or explicit encoding dict.\n",
    "    compression_level : int\n",
    "        Compression level (1 fastest, 9 best compression).\n",
    "    overwrite : bool\n",
    "        Overwrite existing zarr store.\n",
    "    consolidated : bool\n",
    "        Create consolidated metadata (recommended).\n",
    "    storage : {'auto','local','gcs'}\n",
    "        Force storage backend or infer from path when 'auto'.\n",
    "    gcs_project : str, optional\n",
    "        Explicit GCP project for a fresh filesystem client.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The zarr_path that was written.\n",
    "    \"\"\"\n",
    "    def _format_size(num_bytes: int) -> str:\n",
    "        size_mb = num_bytes / (1024 * 1024)\n",
    "        size_gb = size_mb / 1024\n",
    "        return f\"{size_gb:.2f} GB\" if size_gb >= 1 else f\"{size_mb:.2f} MB\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    storage = storage.lower()\n",
    "    if storage == 'auto':\n",
    "        storage = 'gcs' if zarr_path.startswith('gs://') else 'local'\n",
    "    if storage not in {'local', 'gcs'}:\n",
    "        raise ValueError(\"storage must be one of {'auto', 'local', 'gcs'}\")\n",
    "\n",
    "    fs = None\n",
    "    if storage == 'gcs':\n",
    "        fs = gcs if gcs_project is None else gcsfs.GCSFileSystem(project=gcs_project)\n",
    "    else:\n",
    "        zarr_dir = os.path.dirname(zarr_path) if os.path.dirname(zarr_path) else '.'\n",
    "        if zarr_dir and not os.path.exists(zarr_dir):\n",
    "            os.makedirs(zarr_dir, exist_ok=True)\n",
    "\n",
    "    # Handle overwrite\n",
    "    if storage == 'gcs':\n",
    "        if fs.exists(zarr_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(\n",
    "                    f\"Zarr store already exists on GCS: {zarr_path}\\n\"\n",
    "                    \"Set overwrite=True to replace it.\"\n",
    "                )\n",
    "            print(f\"üóëÔ∏è  Removing existing GCS zarr store: {zarr_path}\")\n",
    "            fs.rm(zarr_path, recursive=True)\n",
    "    else:\n",
    "        if os.path.exists(zarr_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(\n",
    "                    f\"Zarr store already exists: {zarr_path}\\n\"\n",
    "                    \"Set overwrite=True to replace it.\"\n",
    "                )\n",
    "            import shutil\n",
    "            print(f\"üóëÔ∏è  Removing existing zarr store: {zarr_path}\")\n",
    "            shutil.rmtree(zarr_path)\n",
    "\n",
    "    # Default chunk sizes\n",
    "    if chunk_sizes is None:\n",
    "        chunk_sizes = {}\n",
    "        dims = ds.dims\n",
    "        if 'time' in dims:\n",
    "            chunk_sizes['time'] = min(20, dims['time'])\n",
    "        if 'x' in dims:\n",
    "            chunk_sizes['x'] = min(256, dims['x'])\n",
    "        if 'y' in dims:\n",
    "            chunk_sizes['y'] = min(256, dims['y'])\n",
    "        for dim_name, dim_len in dims.items():\n",
    "            chunk_sizes.setdefault(dim_name, min(100, dim_len))\n",
    "\n",
    "    print(f\"üì¶ Saving to zarr: {zarr_path}\")\n",
    "    print(f\"   Dimensions: {dict(ds.dims)}\")\n",
    "    print(f\"   Chunks: {chunk_sizes}\")\n",
    "    print(f\"   Compression: {compression} (level {compression_level})\")\n",
    "    print(f\"   Storage: {storage}\")\n",
    "\n",
    "    # Prepare compression\n",
    "    if compression == 'lz4':\n",
    "        compressor = Blosc(cname='lz4', clevel=compression_level, shuffle=Blosc.SHUFFLE, blocksize=0)\n",
    "        encoding = {var: {'compressor': compressor} for var in ds.data_vars}\n",
    "    elif compression == 'blosc':\n",
    "        compressor = Blosc(cname='blosclz', clevel=compression_level, shuffle=Blosc.SHUFFLE, blocksize=0)\n",
    "        encoding = {var: {'compressor': compressor} for var in ds.data_vars}\n",
    "    elif compression == 'zstd':\n",
    "        compressor = Blosc(cname='zstd', clevel=compression_level, shuffle=Blosc.SHUFFLE, blocksize=0)\n",
    "        encoding = {var: {'compressor': compressor} for var in ds.data_vars}\n",
    "    elif compression is None:\n",
    "        encoding = {}\n",
    "    else:\n",
    "        encoding = compression  # assume dict supplied\n",
    "\n",
    "    # Chunk and save\n",
    "    ds_chunked = ds.chunk(chunk_sizes)\n",
    "    print(\"üíæ Writing to zarr (with automatic parallelism)...\")\n",
    "\n",
    "    store = fs.get_mapper(zarr_path) if storage == 'gcs' else zarr_path\n",
    "    try:\n",
    "        from dask.diagnostics import ProgressBar\n",
    "        with ProgressBar():\n",
    "            ds_chunked.to_zarr(\n",
    "                store,\n",
    "                mode='w',\n",
    "                encoding=encoding,\n",
    "                consolidated=consolidated,\n",
    "                compute=True,\n",
    "            )\n",
    "    except ImportError:\n",
    "        ds_chunked.to_zarr(\n",
    "            store,\n",
    "            mode='w',\n",
    "            encoding=encoding,\n",
    "            consolidated=consolidated,\n",
    "            compute=True,\n",
    "        )\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Size reporting\n",
    "    total_size = None\n",
    "    if storage == 'gcs':\n",
    "        try:\n",
    "            size_info = fs.du(zarr_path)\n",
    "            if isinstance(size_info, dict):\n",
    "                total_size = sum(size_info.values())\n",
    "            elif isinstance(size_info, (int, float)):\n",
    "                total_size = size_info\n",
    "        except Exception as exc:\n",
    "            print(f\"‚ö†Ô∏è  Could not compute GCS store size: {exc}\")\n",
    "    else:\n",
    "        if os.path.exists(zarr_path):\n",
    "            total_size = 0\n",
    "            for dirpath, _, filenames in os.walk(zarr_path):\n",
    "                for f in filenames:\n",
    "                    fp = os.path.join(dirpath, f)\n",
    "                    total_size += os.path.getsize(fp)\n",
    "\n",
    "    if total_size is not None:\n",
    "        size_str = _format_size(total_size)\n",
    "        write_speed = total_size / elapsed / (1024 * 1024)\n",
    "        print(\"‚úÖ Dataset saved successfully!\")\n",
    "        print(f\"   Store size: {size_str}\")\n",
    "        print(f\"   Time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "        print(f\"   Write speed: {write_speed:.1f} MB/s\")\n",
    "        print(f\"   Path: {zarr_path}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Dataset saved successfully! (size unavailable)\")\n",
    "        print(f\"   Time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "        print(f\"   Path: {zarr_path}\")\n",
    "\n",
    "    return zarr_path\n",
    "\n",
    "\n",
    "def load_dataset_zarr(zarr_path, consolidated=True, storage='auto', gcs_project=None):\n",
    "    \"\"\"\n",
    "    Load a dataset from a zarr store located locally or on GCS.\n",
    "    \"\"\"\n",
    "    storage = storage.lower()\n",
    "    if storage == 'auto':\n",
    "        storage = 'gcs' if zarr_path.startswith('gs://') else 'local'\n",
    "    if storage not in {'local', 'gcs'}:\n",
    "        raise ValueError(\"storage must be one of {'auto', 'local', 'gcs'}\")\n",
    "\n",
    "    if storage == 'gcs':\n",
    "        fs = gcs if gcs_project is None else gcsfs.GCSFileSystem(project=gcs_project)\n",
    "        if not fs.exists(zarr_path):\n",
    "            raise FileNotFoundError(f\"Zarr store not found on GCS: {zarr_path}\")\n",
    "        mapper = fs.get_mapper(zarr_path)\n",
    "        print(f\"üìÇ Loading dataset from GCS zarr: {zarr_path}\")\n",
    "        ds = xr.open_zarr(mapper, consolidated=consolidated)\n",
    "    else:\n",
    "        if not os.path.exists(zarr_path):\n",
    "            raise FileNotFoundError(f\"Zarr store not found: {zarr_path}\")\n",
    "        print(f\"üìÇ Loading dataset from zarr: {zarr_path}\")\n",
    "        ds = xr.open_zarr(zarr_path, consolidated=consolidated)\n",
    "\n",
    "    print(f\"‚úÖ Dataset loaded: {dict(ds.dims)}\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "print(\"‚úÖ Simplified zarr saving functions loaded!\")\n",
    "print(\"\\nKey simplifications:\")\n",
    "print(\"  - No complex auto-detection\")\n",
    "print(\"  - Always uses compute=True (let dask handle parallelism)\")\n",
    "print(\"  - Simple, reliable, focuses on parallelism\")\n",
    "print(\"  - Works with both lazy and in-memory arrays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e884edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"use GEE\")\n",
    "\n",
    "# # --- Step 1: Compute valid pixel percentage per scene ---\n",
    "# # Let Earth Engine compute the mean of valid pixels (server-side)\n",
    "# valid_pixels = (ds[\"cloudM\"] == 1).mean((\"y\", \"x\")) * 100\n",
    "\n",
    "# # --- Step 2: Bring down only small summary stats ---\n",
    "# # This triggers small, fast fetches (not full rasters)\n",
    "# min_val = float(valid_pixels.min().values)\n",
    "# max_val = float(valid_pixels.max().values)\n",
    "\n",
    "# # Compute valid mask and count (still efficient)\n",
    "# valid_mask = valid_pixels > valid_pixel_threshold\n",
    "# n_valid = int((valid_mask).sum().values)\n",
    "# n_total = int(len(valid_pixels.time))\n",
    "\n",
    "# print(f\"Valid pixel percentages: min={min_val:.1f}%, max={max_val:.1f}%\")\n",
    "# print(f\"Scenes with >{valid_pixel_threshold}% valid pixels: {n_valid}/{n_total}\")\n",
    "\n",
    "# # --- Step 3: Filter dataset ---\n",
    "# # This step remains server-side (GEE will only load the scenes you need)\n",
    "# ds = ds.sel(time=valid_mask, drop=True)\n",
    "# print(f\"After valid pixel filtering: {ds.dims}\")\n",
    "\n",
    "# # --- Step 4: Cloud masking (already done in GEE) ---\n",
    "# # No need to apply ds.where(ds.cloudM == 1)\n",
    "# print(\"Applied cloud masking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417172af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffe342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect time coordinate and list timestamps in 2024\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure we have a datetime index/array from ds.time\n",
    "_time_values = pd.to_datetime(ds[\"time\"].values)\n",
    "_time_index = pd.DatetimeIndex(_time_values)\n",
    "\n",
    "print(f\"Total scenes: {_time_index.size}\")\n",
    "print(f\"Time span: {_time_index.min().date()} -> {_time_index.max().date()}\")\n",
    "\n",
    "# Filter to 2024 only (time info only, no further filtering yet)\n",
    "_times_2024 = _time_index[_time_index.year == 2024]\n",
    "print(f\"Scenes in 2024: {len(_times_2024)}\")\n",
    "\n",
    "# Display the 2024 timestamps (ISO format)\n",
    "for ts in _times_2024:\n",
    "    print(ts.isoformat())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## example selection\n",
    "# # If cloudM is 0/1\n",
    "# ds_example = ds.sel(time=\"2024-02-10\")\n",
    "\n",
    "# ds_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a54dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa732d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# unique_vals = np.unique(ds['cloudM'].values)\n",
    "# print(f\"Unique values: {unique_vals}\")\n",
    "# print(f\"Has 0: {0 in unique_vals}, Has 1: {1 in unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_cloudm_values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üîç Checking cloudM values in ds_example (optimized server-side)...\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# if 'cloudM' not in ds_example.data_vars:\n",
    "#     print(\"‚ùå ERROR: 'cloudM' not found in dataset.\")\n",
    "#     print(f\"Available variables: {list(ds_example.data_vars.keys())}\")\n",
    "# else:\n",
    "#     cloudM = ds_example['cloudM']\n",
    "\n",
    "#     # --- Method 1: Compute unique values using xarray/xee's reduction (lazy if Dask/GEE-backed)\n",
    "#     print(\"\\nüìä Unique values (computed lazily if possible):\")\n",
    "#     try:\n",
    "#         unique_vals = cloudM.astype(\"float32\").chunk({\"x\": 512, \"y\": 512}).reduce(np.nanmin, dim=None)\n",
    "#         min_val = unique_vals.compute()  # triggers computation, minimal data pulled\n",
    "#         max_val = cloudM.reduce(np.nanmax, dim=None).compute()\n",
    "#         print(f\"   Value range: min={min_val}, max={max_val}\")\n",
    "#     except Exception as e:\n",
    "#         print(\"‚ö†Ô∏è Could not compute unique values lazily:\", e)\n",
    "\n",
    "#     # --- Method 2: Compute fraction of valid pixels per time step (still on server if xee-backed)\n",
    "#     print(\"\\nüìà Fraction of clear pixels per time slice:\")\n",
    "#     if \"time\" in cloudM.dims:\n",
    "#         valid_fraction = (cloudM == 1).mean(dim=(\"x\", \"y\"))\n",
    "#         cloudy_fraction = (cloudM == 0).mean(dim=(\"x\", \"y\"))\n",
    "\n",
    "#         # These remain deferred operations until .compute() or .values is called\n",
    "#         print(\"   Computing summary (this runs on GEE if xee-backed)...\")\n",
    "#         summary = xr.Dataset({\n",
    "#             \"clear_fraction\": valid_fraction,\n",
    "#             \"cloudy_fraction\": cloudy_fraction\n",
    "#         }).compute()\n",
    "\n",
    "#         for t_idx, t_val in enumerate(summary.time.values[:3]):  # first 3 timesteps\n",
    "#             cf = float(summary.clear_fraction.isel(time=t_idx).values * 100)\n",
    "#             cl = float(summary.cloudy_fraction.isel(time=t_idx).values * 100)\n",
    "#             print(f\"   Time {t_idx} ({t_val}): clear={cf:.2f}%, cloud={cl:.2f}%\")\n",
    "\n",
    "#     # --- Method 3: Summary statistics (still lazy)\n",
    "#     print(\"\\nüìä Summary:\")\n",
    "#     print(f\"   Dtype: {cloudM.dtype}\")\n",
    "#     print(f\"   Shape: {cloudM.shape}\")\n",
    "#     print(f\"   Dims: {list(cloudM.dims)}\")\n",
    "#     print(f\"   Lazy computation: {'Yes' if hasattr(cloudM.data, 'compute') else 'No'}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"üí° Interpretation:\")\n",
    "# print(\"   - All operations above stay on GEE unless `.values` or `.compute()` is called.\")\n",
    "# print(\"   - `.values` or `.compute()` explicitly fetches data to client.\")\n",
    "# print(\"   - Keep operations vectorized (e.g. `.mean()`, `.reduce()`) to use Earth Engine‚Äôs computation graph.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick_check_cloudm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # QUICK CHECK - One-liner version\n",
    "# # import numpy as np\n",
    "\n",
    "# # # Quick check for unique values\n",
    "# # unique_vals = np.unique(ds_example['cloudM'].values)\n",
    "# # print(f\"Unique values in cloudM: {unique_vals}\")\n",
    "# # print(f\"Has 0: {0 in unique_vals}, Has 1: {1 in unique_vals}\")\n",
    "\n",
    "# # # Quick counts\n",
    "# # cloudm = ds_example['cloudM'].values\n",
    "# # print(f\"Count of 0: {np.sum(cloudm == 0):,}\")\n",
    "# # print(f\"Count of 1: {np.sum(cloudm == 1):,}\")\n",
    "# # print(f\"Count of NaN: {np.sum(np.isnan(cloudm)):,}\")\n",
    "\n",
    "# print(\"Checking cloudM values lazily (server-side)...\")\n",
    "\n",
    "# cloudM = ds_example[\"cloudM\"]\n",
    "\n",
    "# # Fraction of clear and cloudy pixels (server-side computation)\n",
    "# clear_fraction = (cloudM == 1).mean((\"x\", \"y\"))\n",
    "# cloud_fraction = (cloudM == 0).mean((\"x\", \"y\"))\n",
    "\n",
    "# # Trigger minimal computation only\n",
    "# summary = cloudM.reduce(np.nanmin, dim=None).compute(), cloudM.reduce(np.nanmax, dim=None).compute()\n",
    "# print(f\"Min, Max values: {summary}\")\n",
    "\n",
    "# print(\"\\nAverage clear/cloud ratio per timestep:\")\n",
    "# if \"time\" in cloudM.dims:\n",
    "#     frac = xr.Dataset({\n",
    "#         \"clear\": clear_fraction,\n",
    "#         \"cloud\": cloud_fraction\n",
    "#     }).compute()  # still small ‚Äì only one value per time slice\n",
    "#     print(frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3847256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"‚öôÔ∏è Using GEE server-side masking via Xee\")\n",
    "\n",
    "# # Ensure we're working on GEE-backed data\n",
    "# assert hasattr(ds_example['swir1'].data, \"_ee_object\"), \"This dataset is not Xee-backed!\"\n",
    "\n",
    "# # --- Step 1: Define the lazy mask operation (server-side) ---\n",
    "# # When using xee, operations like .where() or arithmetic are translated into\n",
    "# # Earth Engine expressions, not computed locally.\n",
    "# result_lazy = ds_example['swir1'].where(ds_example['cloudM'] == 0)\n",
    "\n",
    "# # --- Step 2: Confirm it's still a GEE-backed XeeArray ---\n",
    "# print(f\"‚úÖ Type: {type(result_lazy.data)} (should be xee.xarray.XeeArray)\")\n",
    "# print(\"üì° Still server-side; nothing has been downloaded yet.\")\n",
    "\n",
    "# # --- Step 3: Optional ‚Äî get metadata only (safe server-side) ---\n",
    "# print(\"üß© Metadata:\")\n",
    "# print(f\"  Shape: {result_lazy.sizes}\")\n",
    "# print(f\"  Dims: {result_lazy.dims}\")\n",
    "# print(f\"  Data type: {result_lazy.dtype}\")\n",
    "\n",
    "# # --- Step 4: Do NOT call .values or .compute() here ---\n",
    "# # Those would trigger a full download.\n",
    "# # Instead, perform further chained operations ‚Äî mean(), reduce(), etc. ‚Äî\n",
    "# # and only call .values at the end for small summaries if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(ds['swir1'].data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_lazy.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accessing data where cloudM == 1 (valid pixels)\n",
    "# # cloudM == 1 means no cloud, but some values may be NaN outside AOI boundary\n",
    "# result_valid = ds_example['swir1'].where(ds_example['cloudM'] == 1).data\n",
    "# print(f\"Type: {type(result_valid)} - Still lazy (chunked)\")\n",
    "# print(\"Note: NaN values can occur due to:\")\n",
    "# print(\"  - Outside AOI geometry boundary\")\n",
    "# print(\"  - Missing data in source\")\n",
    "# print(\"  - Processing artifacts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_valid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick_check_values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QUICK CHECK - One-liner methods\n",
    "\n",
    "# # Quick check if has values:\n",
    "# result = result_valid.compute()\n",
    "# has_values = np.any(~np.isnan(result))\n",
    "# print(f\"Has values: {has_values}\")\n",
    "\n",
    "# # Count valid values:\n",
    "# if has_values:\n",
    "#     valid_pct = 100 * np.sum(~np.isnan(result)) / result.size\n",
    "#     print(f\"Valid values: {np.sum(~np.isnan(result)):,} / {result.size:,} ({valid_pct:.1f}%)\")\n",
    "    \n",
    "# # Get min/max of valid values:\n",
    "# if has_values:\n",
    "#     print(f\"Value range: [{np.nanmin(result):.4f}, {np.nanmax(result):.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec105e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x = ds.x.values\n",
    "ds_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff026a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y = ds.y.values\n",
    "ds_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9794015",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_time_list = ds.time.values\n",
    "ds_time_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61163189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_time_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13234d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_example_one_point_value = ds_example.isel(x=46, y=0, time=0)\n",
    "# ds_example_one_point_value['swir2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_example_one_point_value.image_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7efe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do timeseries selection per month - for its best availability here, as we can see that probably not possible for daily\n",
    "# print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = ds.time.values[0]\n",
    "# end_date = ds.time.values[-1]\n",
    "\n",
    "# print(f\"Start date: {start_date}\")\n",
    "# print(f\"End date: {end_date}\")\n",
    "\n",
    "# # resampling, for using later in smoothing\n",
    "# resampling_freq = 'MS'  # Monthly resampling\n",
    "# output_freq = 'MS'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if we can get the data and masking the duplicates, this is requires for STAC, but for GEE i think we dont have problem, but we can see the differences later in dims\n",
    "# mask = ~pd.Series(ds.time.values).duplicated().values\n",
    "# ds_removed_duplicates = ds.isel(time=mask, drop=True)\n",
    "# print(f\"After removing duplicates: {ds_removed_duplicates.dims}\")\n",
    "\n",
    "# # check the time range\n",
    "# # ds_removed_duplicates.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b40dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_time_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b825b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # interpolation\n",
    "# resampled_t  = pd.date_range(ds.time.min().values, ds.time.max().values, freq=resampling_freq)\n",
    "# # resampled_t\n",
    "\n",
    "# # check the time range\n",
    "# # ds_removed_duplicates.time.values\n",
    "\n",
    "# # # resampled_t\n",
    "# bands_to_interp =  [\n",
    "# #  'cloudM',\n",
    "#  'NDVI',\n",
    "#  'ndwi',\n",
    "#  'msavi2',\n",
    "#  'MTVI2',\n",
    "#  'VARI',\n",
    "#  'BSI',\n",
    "#  'BI',\n",
    "#  'SI',\n",
    "#  'pseudo_fcd_pct']\n",
    "\n",
    "# # band_data_list = []\n",
    "# # for band in list(bands_to_interp):\n",
    "# #     print('start with band ', band )\n",
    "# #     band_data = ds[band].interp(time=resampled_t)\n",
    "# #     band_data_list.append(band_data)\n",
    "\n",
    "# # improvement\n",
    "# # Ensure monotonic, unique time\n",
    "# ds = ds.sortby('time')\n",
    "# ds = ds.sel(time=~ds.indexes['time'].duplicated())\n",
    "\n",
    "# zarr_path = 'data/ds_resampled.zarr'\n",
    "zarr_path = os.getenv('GCS_ZARR_DIR') + '/ds_resampled.zarr'\n",
    "storage = 'gcs'\n",
    "\n",
    "# if not os.path.exists(zarr_path):\n",
    "#     # Direct linear interpolation onto target grid (requires SciPy)\n",
    "#     ds_resampled = ds[bands_to_interp].interp(time=resampled_t, method='linear')\n",
    "#     ds_resampled\n",
    "# else:\n",
    "#     print('we will load the zarr file in the next cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud storage ls $GCS_ZARR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54101e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ceb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8436aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CAUSE IT TAKES TIME LETS SAVE THE DATASET TO ZARR - one time only, later we can just load the zarr file\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# Reload xarray plugins to ensure zarr engine is available (in case zarr was installed after xarray import)\n",
    "import xarray as xr\n",
    "importlib.reload(xr.backends.plugins)\n",
    "\n",
    "ds_resampled = ds # GEE CALCULATED SIDE FOR INTERPOLATION AND SMOOTHING\n",
    "\n",
    "# if path not exists, then save the dataset to zarr\n",
    "if not os.path.exists(zarr_path):\n",
    "    # Save to zarr (keep using in-memory version)\n",
    "    save_dataset_efficient_zarr(ds_resampled, zarr_path,\n",
    "    chunk_sizes={'time': 40, 'x': 1024, 'y': 1024},  # Optimized for time-series processing, gcs api call increase time\n",
    "        compression='lz4',  # Fastest compression option\n",
    "        compression_level=1,  # Level 1 = fastest (use 3-5 for better compression if speed not critical)\n",
    "        overwrite=True,\n",
    "        consolidated=True, storage=storage\n",
    "    )\n",
    "else:\n",
    "    ds_resampled = load_dataset_zarr(zarr_path, storage=storage)\n",
    "    \n",
    "ds_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_resampled = load_dataset_zarr(zarr_path, storage=storage)\n",
    "ds_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import savgol_filter\n",
    "\n",
    "# def remove_drops_and_spikes_1d(ser, window, threshold_percent):\n",
    "#     \"\"\"\n",
    "#     Process a 1D time series to remove drops and spikes.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     ser : 1D numpy array\n",
    "#         Time series data\n",
    "#     window : int\n",
    "#         Size of the rolling window for outlier detection\n",
    "#     threshold_percent : float\n",
    "#         Relative threshold for flagging outliers (e.g., 0.1 for 10%)\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     cleaned : 1D numpy array\n",
    "#         Time series with outliers replaced by interpolated values\n",
    "#     \"\"\"\n",
    "#     eps = 1e-6  # Avoid division by zero\n",
    "#     s = pd.Series(ser)\n",
    "#     median = s.rolling(window=window, center=True, min_periods=1).median().values\n",
    "    \n",
    "#     spikes = ((ser - median) / (np.abs(median) + eps)) > threshold_percent\n",
    "#     drops = ((median - ser) / (np.abs(median) + eps)) > threshold_percent\n",
    "#     outliers = spikes | drops\n",
    "    \n",
    "#     # Replace outliers with NaN\n",
    "#     ser_no_outliers = ser.copy()\n",
    "#     ser_no_outliers[outliers] = np.nan\n",
    "    \n",
    "#     # Interpolate over NaN values using linear interpolation\n",
    "#     x = np.arange(len(ser))\n",
    "#     valid = ~np.isnan(ser_no_outliers)\n",
    "#     if valid.sum() < 2:\n",
    "#         cleaned = ser_no_outliers  # Not enough valid points to interpolate\n",
    "#     else:\n",
    "#         cleaned = np.interp(x, x[valid], ser_no_outliers[valid])\n",
    "        \n",
    "#     return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab58204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f69136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0141e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# from dask.diagnostics import ProgressBar\n",
    "\n",
    "# # ds_resampled\n",
    "# def clean_and_smooth_1d(ts, outlier_window, outlier_threshold, polyorder, window_length):\n",
    "#     if np.all(np.isnan(ts)):\n",
    "#         return ts\n",
    "#     cleaned = remove_drops_and_spikes_1d(ts, window=outlier_window, threshold_percent=outlier_threshold)\n",
    "#     return savgol_filter(cleaned, polyorder=polyorder, window_length=window_length, mode=\"interp\")\n",
    "\n",
    "# ## OPTIMIZED: Process bands separately to reduce memory footprint\n",
    "# # This approach processes each band independently, reducing memory per chunk from ~1.8GB to ~180MB\n",
    "# # Much faster and more memory-efficient than processing all bands at once\n",
    "\n",
    "# import dask.array as da\n",
    "\n",
    "# smoothed_bands = {}\n",
    "# total_bands = len(bands_to_interp)\n",
    "\n",
    "# print(f\"üîÑ Processing {total_bands} bands separately (more memory-efficient)...\")\n",
    "# print(f\"   This approach uses ~10x less memory per operation\")\n",
    "\n",
    "# for i, band_name in enumerate(tqdm(bands_to_interp, desc=\"Bands\", unit=\"band\"), 1):\n",
    "#     print(f\"   [{i}/{total_bands}] Processing {band_name}...\")\n",
    "    \n",
    "#     # Process one band at a time\n",
    "#     band_arr = ds_resampled[band_name]\n",
    "    \n",
    "#     # Chunking: time must be single chunk for core dimension, spatial dimensions chunked\n",
    "#     # Smaller spatial chunks = lower memory per chunk, better parallelism\n",
    "#     band_arr = band_arr.chunk({\"time\": -1, \"y\": 256, \"x\": 256})\n",
    "    \n",
    "#     # Apply smoothing function\n",
    "#     smoothed_band = xr.apply_ufunc(\n",
    "#         clean_and_smooth_1d,\n",
    "#         band_arr,\n",
    "#         kwargs=dict(\n",
    "#             outlier_window=outlier_window,\n",
    "#             outlier_threshold=outlier_threshold,\n",
    "#             polyorder=smoothing_polyorder,\n",
    "#             window_length=smoothing_window,\n",
    "#         ),\n",
    "#         input_core_dims=[[\"time\"]],\n",
    "#         output_core_dims=[[\"time\"]],\n",
    "#         vectorize=True,\n",
    "#         dask=\"parallelized\",\n",
    "#         output_dtypes=[band_arr.dtype],\n",
    "#     )\n",
    "\n",
    "#     with ProgressBar():\n",
    "#         smoothed_bands[band_name] = smoothed_band.compute()\n",
    "#     print(f\"       ‚úÖ {band_name} complete\")\n",
    "\n",
    "# # Combine into dataset\n",
    "# smoothed = xr.Dataset(smoothed_bands)\n",
    "\n",
    "# print(f\"\\n‚úÖ All {total_bands} bands processed and combined!\")\n",
    "# print(\"‚úÖ Smoothing computation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient_zarr_save",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPLEMENT TSFRESH!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zarr_save_example",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_time_series(ds, x_idx, y_idx, title=\"Time Series\"):\n",
    "    \"\"\"\n",
    "    Plot time series for a specific pixel.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds : xarray.Dataset\n",
    "        Dataset containing time series data\n",
    "    x_idx, y_idx : int\n",
    "        Pixel coordinates\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    if 'NDVI' in ds.data_vars:\n",
    "        ds.NDVI.isel(x=x_idx, y=y_idx).plot(label='NDVI', alpha=0.7)\n",
    "    if 'EVI' in ds.data_vars:\n",
    "        ds.EVI.isel(x=x_idx, y=y_idx).plot(label='EVI', alpha=0.7)\n",
    "        \n",
    "    plt.title(f\"{title} - x={x_idx}, y={y_idx}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0838344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to monthly (aggregate to monthly averages)\n",
    "# This actually creates monthly data by averaging all observations within each month\n",
    "band_clean = smoothed.resample(time='MS').mean()  # 'MS' = Month Start\n",
    "\n",
    "# OPTIMIZED: Compute after resample since smoothed is already computed\n",
    "# This makes the next resample operation fast\n",
    "print(\"üîÑ Computing monthly resampled data...\")\n",
    "band_clean = band_clean.compute()\n",
    "print(\"‚úÖ Monthly resampling complete!\")\n",
    "\n",
    "# Alternatively, you can use other aggregation functions:\n",
    "# band_clean = smoothed.resample(time='MS').median().compute()  # monthly median\n",
    "# band_clean = smoothed.resample(time='MS').max().compute()     # monthly maximum\n",
    "\n",
    "band_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling_freq = resampling_freq\n",
    "monthly_time = pd.date_range(start_date, end_date, freq=resampling_freq)\n",
    "monthly_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273586a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_clean = band_clean.reindex(time=monthly_time)\n",
    "band_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_processed = band_clean\n",
    "\n",
    "# Resample to final output frequency\n",
    "ds_processed = ds_processed.resample(time=output_freq).mean()\n",
    "print(f\"Final dataset shape: {ds_processed.dims}\")\n",
    "print(f\"Time range: {ds_processed.time.min().values} to {ds_processed.time.max().values}\")\n",
    "\n",
    "# Add plot dimension\n",
    "ds_processed = ds_processed.expand_dims(plot=['aoi'])\n",
    "print(f\"With plot dimension: {ds_processed.dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c24c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single value - should be FAST now since data is already computed!\n",
    "# After optimizations, ds_processed should be in memory (not lazy)\n",
    "ndvi_value = ds_processed.isel(x=30, y=30, time=30, plot=0)['NDVI'].values\n",
    "print(f\"NDVI value: {ndvi_value}\")\n",
    "\n",
    "# Alternative: Use .item() for scalar values\n",
    "# ndvi_value = ds_processed.isel(x=30, y=30, time=30, plot=0)['NDVI'].item()\n",
    "\n",
    "ndvi_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "layer = 'aoi'\n",
    "\n",
    "# Plot a random time series\n",
    "if ds_processed.NDVI.size > 0:\n",
    "    # Find a pixel with valid data\n",
    "    valid_pixels = np.where(~ds_processed.NDVI.isnull().all(dim='time'))\n",
    "    if len(valid_pixels[0]) > 0:\n",
    "        idx = random.randint(0, len(valid_pixels[0]) - 1) # plot (draw) the random pixel in the dataset\n",
    "        y_idx, x_idx = valid_pixels[0][idx], valid_pixels[1][idx]\n",
    "        \n",
    "        plot_time_series(ds_processed, x_idx, y_idx, f\"Processed {layer}\")\n",
    "    else:\n",
    "        print(\"No valid pixels found for plotting\")\n",
    "else:\n",
    "    print(\"No data to plot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"N time steps:\", ds_resampled.sizes[\"time\"])\n",
    "print(\"requested window:\", smoothing_window, \"polyorder:\", smoothing_polyorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdc893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
