{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = forestry.run_eligibility(config=config, use_gee=True)\n",
    "\n",
    "# # Original validated points (before ML split)\n",
    "# training_info = result['intermediate_results']['training_points_info']\n",
    "# print(f\"Original validated points: {training_info['num_points_after_validation']}\")\n",
    "\n",
    "# # Actual ML training points (after split)\n",
    "# ml_training = result['intermediate_results']['ml_training_points']\n",
    "# print(f\"ML training points: {ml_training.size().getInfo()}\")\n",
    "\n",
    "# # Actual ML validation points (after split) - for confusion matrix\n",
    "# ml_validation = result['intermediate_results']['ml_validation_points']\n",
    "# print(f\"ML validation points: {ml_validation.size().getInfo()}\")\n",
    "\n",
    "# # Use validation points for confusion matrix\n",
    "# # lc.matrix_confusion(\n",
    "# #     result['intermediate_results']['selected_image_lc'],\n",
    "# #     ml_validation,\n",
    "# #     result['intermediate_results']['algo_ml_selected']\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forestry_carbon_arr.example_usage import main\n",
    "result = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the vectors\n",
    "from wfs_manager import WFSManager\n",
    "\n",
    "# result\n",
    "AOI = result['config']['AOI']\n",
    "training_points_ee = result['intermediate_results']['training_points_info']['training_points_ee']\n",
    "\n",
    "wfs = WFSManager(fastapi_url=\"http://fastapi:8000\", wfs_base_url=\"http://localhost:8001\")\n",
    "wfs.addLayer(training_points_ee, \"Training Points Dynamic\")\n",
    "wfs.addLayer(AOI, \"AOI Boundary\")\n",
    "wfs.publish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrelated to the project by for testing -->\n",
    "import geemap\n",
    "import os \n",
    "from gee_integration import add_tms_layer_to_mapstore\n",
    "from gee_lib.osi.utils import generate_map_id\n",
    "\n",
    "new_aoi_test = geemap.shp_to_ee('00_input/concession.shp')\n",
    "wfs.addLayer(new_aoi_test, \"new AOI Boundary\")\n",
    "wfs.publish()\n",
    "\n",
    "path_cog =  os.getenv('GCS_PATH')\n",
    "# cog gcs to ee image\n",
    "\n",
    "drone_cog = geemap.load_GeoTIFF(path_cog)\n",
    "### #type(drone_cog)\n",
    "\n",
    "map_layers = generate_map_id({'drone_cog': {}}, { 'drone_cog': drone_cog})['map_layers']\n",
    "map_layers\n",
    "\n",
    "drone_info = map_layers['drone_cog']\n",
    "\n",
    "\n",
    "### #!cat /root/.config/gcloud/application_default_credentials.json\n",
    "### #re add\n",
    "### result = list_layers_to_wmts(map_layers, AOI)\n",
    "### #result\n",
    "### #Add a TMS layer\n",
    "\n",
    "\n",
    "drone_name = list(map_layers.keys())[0]\n",
    "drone_layer = map_layers[drone_name]\n",
    "tms_result = add_tms_layer_to_mapstore(\n",
    "    layer_name=drone_name,\n",
    "    layer_url=drone_info.get('tile_url', ''),\n",
    "    use_fastapi_proxy=False, # change this to True if you want to use the fastapi proxy\n",
    "    fastapi_pub_url=\"http://localhost:8001\"\n",
    ")\n",
    "\n",
    "drone_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df803642",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['visualization_params']['FCD1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46852eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## displaying the rasters\n",
    "### TRY the new Approach, wmts manager, make the simpler line for adding layer based on project\n",
    "from wmts_manager import WMTSManager\n",
    "\n",
    "project_name = result['config']['project_name']\n",
    "image_mosaick = result['intermediate_results']['image_mosaick']\n",
    "vis_param = result['visualization_params']['mosaic']\n",
    "mosaic_name = result['intermediate_results']['layer_names']['image_mosaick']\n",
    "FCD1_1 = result['intermediate_results']['FCD1_1']\n",
    "fcd_visparams = result['visualization_params']['FCD1_1']\n",
    "# fcd_visparams = {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}\n",
    "fcd1_1_layer_name = result['intermediate_results']['layer_names']['FCD1_1']\n",
    "FCD2_1 = result['intermediate_results']['FCD2_1']\n",
    "fcd2_1_layer_name = result['intermediate_results']['layer_names']['FCD2_1']\n",
    "treeLossYear = result['intermediate_results']['hansen_results']['treeLossYear']\n",
    "treeLoss = result['intermediate_results']['hansen_results']['treeLoss']\n",
    "minLoss = result['intermediate_results']['hansen_results']['minLoss']\n",
    "\n",
    "\n",
    "wmts = WMTSManager(project_name=project_name, aoi=AOI.geometry()) # equal to the defining map properties \n",
    "wmts.addLayer(image_mosaick, vis_param, mosaic_name)\n",
    "wmts.addLayer(FCD1_1, fcd_visparams, fcd1_1_layer_name)\n",
    "wmts.addLayer(FCD2_1, fcd_visparams, fcd2_1_layer_name)\n",
    "wmts.addLayer(treeLossYear.randomVisualizer(), {}, f'treeLossYear')\n",
    "wmts.addLayer(treeLoss.randomVisualizer(), {}, f'treeLoss')\n",
    "wmts.addLayer(minLoss.randomVisualizer(), {}, f'minLoss')\n",
    "wmts.publish() # execution to the WMTS server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440cf9a-baa6-4bb5-a321-df6325bd9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72289e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FCD1_1.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa33205",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154db31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LC\n",
    "rf = result['intermediate_results']['classifier_results']['classified_image_rf']\n",
    "svm = result['intermediate_results']['classifier_results']['classified_image_svm']\n",
    "gbm = result['intermediate_results']['classifier_results']['classified_image_gbm']\n",
    "cart = result['intermediate_results']['classifier_results']['classified_image_cart']\n",
    "\n",
    "rf_layer_name = result['intermediate_results']['layer_names']['land_cover_rf']\n",
    "svm_layer_name = result['intermediate_results']['layer_names']['land_cover_svm']\n",
    "gbm_layer_name = result['intermediate_results']['layer_names']['land_cover_gbm']\n",
    "cart_layer_name = result['intermediate_results']['layer_names']['land_cover_cart']\n",
    "\n",
    "vis_param_lc = result['visualization_params']['land_cover']\n",
    "\n",
    "wmts.addLayer(rf, vis_param_lc, rf_layer_name)\n",
    "wmts.addLayer(svm, vis_param_lc, svm_layer_name)\n",
    "wmts.addLayer(gbm, vis_param_lc, gbm_layer_name)\n",
    "wmts.addLayer(cart, vis_param_lc, cart_layer_name)\n",
    "\n",
    "## zone\n",
    "# Access FCD classified zone\n",
    "fcd_classified_zone = result['intermediate_results']['fcd_classified_zone']\n",
    "\n",
    "# Access zones for all algorithms\n",
    "zones = result['intermediate_results']['zones_all_algorithms']\n",
    "zone_rf = zones['rf']\n",
    "zone_svm = zones['svm']\n",
    "zone_gbm = zones['gbm']\n",
    "zone_cart = zones['cart']\n",
    "\n",
    "# Access layer names\n",
    "zones_names = result['intermediate_results']['layer_names']\n",
    "fcd_zone_name = zones_names['fcd_classified_zone']\n",
    "rf_zone_name = zones_names['zone_rf']\n",
    "svm_zone_name = zones_names['zone_svm']\n",
    "gbm_zone_name = zones_names['zone_gbm']\n",
    "cart_zone_name = zones_names['zone_cart']\n",
    "\n",
    "fcd_classified_zone = result['intermediate_results']['fcd_classified_zone']\n",
    "vis_params_zone = result['visualization_params']['zone']\n",
    "\n",
    "wmts.addLayer(fcd_classified_zone, vis_params_zone, rf_zone_name)\n",
    "wmts.addLayer(zone_rf, vis_params_zone, rf_zone_name)\n",
    "wmts.addLayer(zone_svm, vis_params_zone, svm_zone_name)\n",
    "wmts.addLayer(zone_gbm, vis_params_zone, gbm_zone_name)\n",
    "wmts.addLayer(zone_cart, vis_params_zone, cart_zone_name)\n",
    "\n",
    "# re-overlay the data for zoning from the selected method if they give the best metric, and when we check visually the land cover map make sense, also FCD approach is already there\n",
    "final_zone = result['final_zone']\n",
    "final_zone_layer_name = result['intermediate_results']['layer_names']['final_zone']\n",
    "\n",
    "\n",
    "wmts.addLayer(final_zone, vis_params_zone, final_zone_layer_name)\n",
    "wmts.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.auth import default\n",
    "# creds, project = default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d41671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud projects list\n",
    "# !gcloud config list\n",
    "# !gcloud auth list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !earthengine authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud config set project ee-iwansetiawan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ae635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install earthengine-api --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eae631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import ee\n",
    "# from gee_lib.osi.auth import initialize_gee, check_gee_initialization\n",
    "\n",
    "# # ee.Initialize(project=os.getenv('GOOGLE_CLOUD_PROJECT'))\n",
    "# # ee.Initialize(project='ee-iwansetiawan')\n",
    "\n",
    "# # Initialize GEE\n",
    "# # authenticate = initialize_gee(project_id=os.getenv('GOOGLE_CLOUD_PROJECT'), use_service_account=False)\n",
    "# authenticate = initialize_gee(project_id=os.getenv('GOOGLE_CLOUD_PROJECT'),use_service_account=True)\n",
    "\n",
    "# # # Verify it's working\n",
    "# # if check_gee_initialization():\n",
    "# #     print(\"Ready to use GEE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !gcloud --version\n",
    "\n",
    "# # os.getenv('GOOGLE_CLOUD_PROJECT')\n",
    "\n",
    "# from google.cloud import storage\n",
    "# client = storage.Client()\n",
    "# print(client.project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323bf4f-84c7-4e0c-b467-0926b0f4d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud.storage.buckets.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# ### need improvement on how to manage this config, we also in the config the path to the static file\n",
    "# # maybe we need to not put the path in the config.json, don't know yet\n",
    "# # Move to the parent directory of the current script\n",
    "# parent_dir = os.getcwd()\n",
    "\n",
    "# # Construct the absolute path to the JSON file in the 'input' folder\n",
    "# json_path= os.path.join(parent_dir, '00_input', 'balaban_conf.json')\n",
    "\n",
    "# # Read and load the JSON data from the file\n",
    "# with open(json_path, 'r') as file:\n",
    "#     config = json.load(file)\n",
    "\n",
    "# print('config---> ',config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ee0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## import modules\n",
    "# import osi\n",
    "# import pandas as pd\n",
    "# import geemap\n",
    "\n",
    "# from osi.utils.main import validate_aoi\n",
    "# # convert the modules for image collection (cloudless masking, compositing, reducer etc)\n",
    "# from osi.image_collection.main import ImageCollection\n",
    "# from osi.spectral_indices.spectral_analysis import SpectralAnalysis\n",
    "# from osi.spectral_indices.utils import normalization_100\n",
    "# from osi.hansen.historical_loss import HansenHistorical\n",
    "# from osi.classifying.assign_zone import AssignClassZone\n",
    "# from osi.legends.utils import convert_to_legend_items\n",
    "# from osi.legends.main import LegendsBuilder\n",
    "# from osi.obia.main import OBIASegmentation\n",
    "# from osi.ml.main import LandcoverML\n",
    "# from osi.fcd.main_fcd import FCDCalc\n",
    "# from osi.pca.pca_gee import PCA\n",
    "# from osi.hansen.historical_loss import HansenHistorical\n",
    "# from osi.classifying.assign_zone import AssignClassZone\n",
    "# from osi.arcpy.utils import safe_get_data_source\n",
    "\n",
    "\n",
    "# AOIt_shp_plot = geemap.shp_to_ee(config['AOI_path'])\n",
    "# crs_input = config['crs_input']\n",
    "# I_satellite = config['I_satellite']\n",
    "# project_name = config['project_name']\n",
    "\n",
    "# start_date = config['date_start_end'][0]\n",
    "# end_date = config['date_start_end'][1]\n",
    "\n",
    "# layer_name_image_mosaick = f'image_mosaick_result_ee_{project_name}'\n",
    "\n",
    "# AOI = AOIt_shp_plot\n",
    "# config['AOI'] = AOI\n",
    "\n",
    "# ndwi_hi = 0.1\n",
    "# if config['I_satellite'] == 'Landsat':\n",
    "#     ndwi_hi = config['ndwi_hi_landsat']\n",
    "# elif I_satellite == 'Sentinel':\n",
    "#     ndwi_hi = config['ndwi_hi_sentinel']\n",
    "# elif I_satellite == 'Planet':\n",
    "#     ndwi_hi = config['ndwi_hi_planet']\n",
    "\n",
    "# ### Masking and overlay and area helper Make an image out of the AOI area attribute -> convert featurecollection into raster (image) for overlaying tools\n",
    "# OID = config['OID_field_name']\n",
    "# AOI_img = AOI.filter(ee.Filter.notNull([OID])).reduceToImage(\n",
    "#     properties= [OID],\n",
    "#     reducer= ee.Reducer.first()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now starting to do analysis\n",
    "# # initiate instance class for the image collection and later mosaicking\n",
    "# classInputCollection = ImageCollection(I_satellite=I_satellite,\n",
    "#                                        AOI=AOI, \n",
    "#                                        date_start_end=config['date_start_end'], \n",
    "#                                        cloud_cover_threshold = config['cloud_cover_threshold'],\n",
    "#                                        region=config['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8939d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run the method from image collection loaded, cloudless compositing until to image_mosaick\n",
    "# image_mosaick = classInputCollection.image_mosaick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gee_lib.osi.utils import generate_map_id\n",
    "\n",
    "# # Generate Map IDs\n",
    "# ### Defining params visualization and layer name\n",
    "# layer_name = f'{I_satellite} mosaicked - {start_date}-{end_date} VegColor'\n",
    "\n",
    "# if config['I_satellite'] == 'Planet':\n",
    "#     # true color {\"bands\":[\"red\",\"green\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5}\n",
    "#     # nir veg color {\"bands\":[\"red\",\"nir\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5 }\n",
    "#     vis_param = {\"bands\":[\"red\",\"green\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5}\n",
    "# else:\n",
    "#     vis_param = {'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 0.6, 'gamma': 1.5}\n",
    "\n",
    "# layers_data = {'project_name': 'Sentinel-2 Cloudless Composite Analysis'}\n",
    "\n",
    "\n",
    "# print(\"âœ“ Map IDs generated for all layers\")\n",
    "# # Display tile URLs\n",
    "# for layer_name, map_id_dict in generate_map_id({layer_name: vis_param}, {layer_name: image_mosaick})['all_mapid'].items():\n",
    "#     tile_url = map_id_dict['tile_fetcher'].url_format\n",
    "#     print(f\"\\n{layer_name.upper()}:\")\n",
    "#     print(f\"  Tile URL: {tile_url}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa107a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## META data layers\n",
    "# layers_data = {\n",
    "#     'project_name': project_name,\n",
    "# }\n",
    "\n",
    "# # # Option 1: Simple tile URLs only\n",
    "# # map_layers = {\n",
    "# #     layer_name: map_ids[layer_name]['tile_fetcher'].url_format}\n",
    "\n",
    "# # Option 2 with more detail combination for generating wmts\n",
    "# map_layers = generate_map_id({layer_name: vis_param}, {layer_name: image_mosaick})['map_layers']\n",
    "# map_layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import sys\n",
    "# # sys.path.append('/usr/src/app/fastapi-gee-service')\n",
    "# from gee_integration import process_gee_to_mapstore\n",
    "\n",
    "# # Import the AOI fix function properly\n",
    "# from gee_lib.osi.utils import process_aoi_geometry\n",
    "\n",
    "# def list_layers_to_wmts(map_layers, AOI):\n",
    "#     \"\"\"\n",
    "#     Convert map layers to WMTS format\n",
    "    \n",
    "#     Args:\n",
    "#         map_layers: Dictionary of map layers\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Fix 1: Use correct map layers\n",
    "#     print(f\"\\nðŸ” Available map layers:\")\n",
    "#     print(f\"   map_layers: {len(map_layers)}\")\n",
    "\n",
    "#     # Fix 2: Fix AOI coordinates using the existing function\n",
    "#     print(f\"\\nðŸ”§ Fixing AOI coordinates...\")\n",
    "#     AOI_geom = AOI.geometry()\n",
    "#     aoi_info = process_aoi_geometry(AOI_geom)\n",
    "\n",
    "#     print(f\"âœ… Fixed AOI Info:\")\n",
    "#     print(f\"   Bbox: {aoi_info['bbox']}\")\n",
    "#     print(f\"   Center: {aoi_info['center']}\")\n",
    "\n",
    "#     print(\"ðŸš€ Processing GEE Analysis to MapStore...\")\n",
    "#     print(f\"   Project: {layers_data['project_name']}\")\n",
    "#     print(f\"   Layers: {len(map_layers)}\")\n",
    "#     print(f\"   AOI: {aoi_info['bbox']}\")\n",
    "\n",
    "#     # Process the complete integration\n",
    "#     result = process_gee_to_mapstore(\n",
    "#         map_layers=map_layers,\n",
    "#         project_name=layers_data['project_name'],\n",
    "#         aoi_info=aoi_info,\n",
    "#         clear_cache_first=True,\n",
    "#         fastapi_url=\"http://fastapi:8000\"  # Internal Docker network , this should be in localhost, but we can override as well\n",
    "#     )\n",
    "#     return result\n",
    "\n",
    "# result = list_layers_to_wmts(map_layers, AOI) # EQUIVALENT TO MAP.ADDLAYER(RASTER)\n",
    "# result\n",
    "\n",
    "# ## EXAMPLE TO PUSH GEE TO GEOJSON FAST API and get WFS RESULT, (EQUIVALENT MAP.ADDLAYER (VECTOR))\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # Example GeoJSON data\n",
    "# geojson_data = AOI.getInfo() # important this ee.FeatureCollection should convert to geojson first\n",
    "# name_aoi = 'gee_aoi_dynamic'\n",
    "\n",
    "# link_fastapi = 'http://fastapi:8000/fc/'+name_aoi #only from container, not from localhost\n",
    "\n",
    "# # Push to API\n",
    "# response = requests.post(\n",
    "#     link_fastapi, # running in the notebook for now\n",
    "#     json=geojson_data\n",
    "# )\n",
    "\n",
    "# print('link_localhost: ', 'http://localhost:8001/fc/'+name_aoi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat /usr/src/app/mapstore/config/localConfig.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the new TMS management system\n",
    "# from gee_integration import add_tms_layer_to_mapstore, list_gee_tms_layers, clear_all_gee_tms_layers # still needed\n",
    "\n",
    "\n",
    "# print(\"Adding TMS layer with Direct GEE TILES...\")\n",
    "# # Get the first layer as an example\n",
    "# first_layer_name = list(map_layers.keys())[0]\n",
    "# first_layer_info = map_layers[first_layer_name]\n",
    "\n",
    "# # Add a TMS layer\n",
    "# tms_result = add_tms_layer_to_mapstore(\n",
    "#     layer_name=first_layer_name,\n",
    "#     layer_url=first_layer_info.get('tile_url', ''),\n",
    "#     use_fastapi_proxy=False, # change this to True if you want to use the fastapi proxy\n",
    "#     fastapi_pub_url=\"http://localhost:8001\"\n",
    "# )\n",
    "\n",
    "# print(f\"\\nðŸ“Š TMS Proxy Result:\")\n",
    "# print(f\"   Status: {tms_result['status']}\")\n",
    "# if tms_result['status'] == 'success':\n",
    "#     print(f\"   Service ID: {tms_result['service_id']}\")\n",
    "#     print(f\"   Layer Title: {tms_result['layer_title']}\")\n",
    "#     print(f\"   TMS URL: {tms_result['tms_url']}\")\n",
    "#     print(f\"   Uses FastAPI Proxy: {tms_result['use_fastapi_proxy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_gee_tms_layers()\n",
    "# clear_all_gee_tms_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2665427f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b176fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "\n",
    "# ### validate the input is correct\n",
    "# ##AOI\n",
    "# AOI_shp_path = config['AOI_path']\n",
    "# AOI_shp = gpd.GeoDataFrame.from_file(AOI_shp_path)\n",
    "# AOI_shp.head()\n",
    "\n",
    "# # make sure the related id is exist in the AOI_shp\n",
    "# id_name = config['OID_field_name']\n",
    "# if id_name not in AOI_shp.columns:\n",
    "#     raise ValueError(f\"The field {id_name} does not exist in the AOI shapefile.\")\n",
    "\n",
    "# # check if the AOI_shp is in the correct crs\n",
    "# if AOI_shp.crs != config['crs_input']:\n",
    "#     AOI_shp = AOI_shp.to_crs(config['crs_input'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## validate the training points (this notebook assume the training points is already exist in the project)\n",
    "# input_training_points_path = config['input_training']\n",
    "# training_points = gpd.GeoDataFrame.from_file(input_training_points_path)\n",
    "\n",
    "# # check if the training points is in the correct crs\n",
    "# if training_points.crs != config['crs_input']:\n",
    "#     training_points = training_points.to_crs(config['crs_input'])\n",
    "\n",
    "# print('before_validation: ',training_points.shape)\n",
    "# # Function to check if a value is an integer\n",
    "# def is_integer(value):\n",
    "#     return isinstance(value, int)\n",
    "\n",
    "# # Filter out non-integer values in the 'code_lu' column\n",
    "# training_points['code_lu'] = training_points['code_lu'].apply(lambda x: x if is_integer(x) else None)\n",
    "\n",
    "# print('after validation: ',training_points.shape)\n",
    "# training_points.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0366f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can add the training point to the map (WFS) ;)\n",
    "# training_points_ee = geemap.geopandas_to_ee(training_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee210067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example GeoJSON data, adding again above (points, not only AOI polygon)\n",
    "# geojson_data = training_points_ee.getInfo() # important this ee.FeatureCollection should convert to geojson first\n",
    "# name_aoi = 'training_points_dynamic'\n",
    "\n",
    "# link_fastapi = 'http://fastapi:8000/fc/'+name_aoi #only from container, not from localhost\n",
    "\n",
    "# # Push to API\n",
    "# response = requests.post(\n",
    "#     link_fastapi, # running in the notebook for now\n",
    "#     json=geojson_data\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pallette_class_segment = {\n",
    "#             '1': '#83ff5a',  # forest_trees (1)\n",
    "#             '2': '#ffe3b3',  # shrubland (2)\n",
    "#             '3': '#ffff33',  # grassland (3)\n",
    "#             '4': '#f89696',  # openland (4)\n",
    "#             '5': '#1900ff',  # waterbody_wet_area (5)\n",
    "#             '6': '#e6e6fa',  # plantation (6)\n",
    "#             '7': '#FFFFFF',   # gray_infrastructure (7)\n",
    "#             '8': '#4B0082',  # oil_palm (8) - Dark Purple\n",
    "#             '9': '#8B4513',  # cropland (9) - Brown\n",
    "#             '10': '#87CEEB',  # waterbody (10) - Light Blue\n",
    "#             '11': '#2F4F4F',  # wetlands (11) - Dark Teal\n",
    "#             '12': '#ADFF2F',  # forest_trees_regrowth (12) - Light Green\n",
    "#             '13': '#8B0000',  # historical_treeloss_10years (13) - Dark Red\n",
    "#             '14': '#DAA520'   # paddy_irrigated (14) - Golden Yellow\n",
    "\n",
    "#             }\n",
    "\n",
    "# training_points['code_lu'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e111d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [f.name for f in map.listLayers()]\n",
    "# [f.name for f in arc_ops.list_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f801bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classImageSpectral = SpectralAnalysis(image_mosaick,config)\n",
    "# class_FCD_run = FCDCalc(config).fcd_calc()\n",
    "# FCD1_1 = class_FCD_run['FCD1_1']\n",
    "# FCD2_1 = class_FCD_run['FCD2_1']\n",
    "\n",
    "# # FCD1_1_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(FCD1_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']},\n",
    "# #                                                    f'FCD1_1_{project_name}')\n",
    "\n",
    "# fcd_visparams = {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}\n",
    "# fcd1_1_layer_name = f'FCD1_1_{project_name}'\n",
    "# fcd2_1_layer_name = f'FCD2_1_{project_name}'\n",
    "\n",
    "# # FCD2_1_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(FCD2_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']},\n",
    "# #                                                    f'FCD2_1_{project_name}')\n",
    "\n",
    "# map_layers = generate_map_id({layer_name: vis_param, fcd1_1_layer_name: fcd_visparams, fcd2_1_layer_name: fcd_visparams}, \n",
    "#                              {layer_name: image_mosaick, fcd1_1_layer_name: FCD1_1, fcd2_1_layer_name: FCD2_1})['map_layers']\n",
    "\n",
    "# print('finish processing PCA please continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb254d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = list_layers_to_wmts(map_layers, AOI) # EQUIVALENT TO MAP.ADDLAYER(RASTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## starting to look at the historical data (Hansen - global foresty watch)\n",
    "# hansen_class = HansenHistorical(config)\n",
    "# run_hansen = hansen_class.initiate_tcl()\n",
    "# LastImageLandsat, treeLossYear, minLoss, ForestArea2000Hansen, gfc =  \\\n",
    "#                                  run_hansen['LastImageLandsat'], \\\n",
    "#                                  run_hansen['treeLossYear'], \\\n",
    "#                                  run_hansen['minLoss'], \\\n",
    "#                                  run_hansen['ForestArea2000Hansen'], \\\n",
    "#                                  run_hansen['gfc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## if we want to add the hansen layer to the map\n",
    "# tree_loss_year = treeLossYear.randomVisualizer()\n",
    "\n",
    "# # arc_ops.adding_ee_to_arcgisPro(treeLossYear.randomVisualizer(), {},\n",
    "# #                                                    f'treeLossYear')\n",
    "\n",
    "# treeLoss = treeLossYear.gte(0).And(treeLossYear.lte(23)).selfMask()\n",
    "# # arc_ops.adding_ee_to_arcgisPro(treeLoss.randomVisualizer(), {},\n",
    "# #                                                    f'treeLoss')\n",
    "\n",
    "# #Canopy cover percentage (e.g. 30%), for Indonesia\n",
    "# cc = ee.Number(30)\n",
    "\n",
    "# #Minimum forest area in pixels (e.g. 3 pixels, ~ 0.27 ha in this example).\n",
    "# pixels = ee.Number(3)\n",
    "\n",
    "# #Minimum mapping area for tree loss (usually same as the minimum forest area).\n",
    "# lossPixels = pixels\n",
    "\n",
    "# canopyCover = gfc.select(['treecover2000'])\n",
    "# canopyCoverThreshold = canopyCover.gte(cc).selfMask()\n",
    "\n",
    "# #Use connectedPixelCount() to get contiguous area.\n",
    "# contArea = canopyCoverThreshold.connectedPixelCount()\n",
    "# #Apply the minimum area requirement.\n",
    "# minArea = contArea.gte(pixels).selfMask()\n",
    "\n",
    "# treecoverLoss = minArea.And(treeLoss).rename(f'lossfrom_0-23').selfMask()\n",
    "        \n",
    "# #Create connectedPixelCount() to get contiguous area.\n",
    "# contLoss = treecoverLoss.connectedPixelCount()\n",
    "# #Apply the minimum area requirement, and get the TCL data ---> minLoss - ACTUAL TCL AREA from Hansen since the year_start_loss\n",
    "# minLoss = contLoss.gte(lossPixels).selfMask()\n",
    "\n",
    "\n",
    "# # arc_ops.adding_ee_to_arcgisPro(minLoss.randomVisualizer(), {},\n",
    "# #                                                    f'minLoss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TRY the new Approach, wmts manager, make the simpler line for adding layer based on project\n",
    "# from wmts_manager import WMTSManager\n",
    "\n",
    "# wmts = WMTSManager(project_name=project_name, aoi=AOI.geometry()) # equal to the defining map properties \n",
    "# wmts.addLayer(image_mosaick, vis_param, layer_name)\n",
    "# wmts.addLayer(FCD1_1, fcd_visparams, fcd1_1_layer_name)\n",
    "# wmts.addLayer(FCD2_1, fcd_visparams, fcd2_1_layer_name)\n",
    "# wmts.addLayer(treeLossYear.randomVisualizer(), {}, f'treeLossYear')\n",
    "# wmts.addLayer(treeLoss.randomVisualizer(), {}, f'treeLoss')\n",
    "# wmts.addLayer(minLoss.randomVisualizer(), {}, f'minLoss')\n",
    "# result = wmts.publish() # execution to the WMTS server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wfs_manager import WFSManager\n",
    "\n",
    "# wfs = WFSManager(fastapi_url=\"http://fastapi:8000\", wfs_base_url=\"http://localhost:8001\")\n",
    "# wfs.addLayer(training_points_ee, \"Training Points Dynamic\")\n",
    "# wfs.addLayer(AOI, \"AOI Boundary\")\n",
    "# result = wfs.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9663e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b38c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW (Clean and Flexible):\n",
    "# from osi.utils.main import generate_map_id_list, create_layer_info\n",
    "\n",
    "# # Define your layers in a clean list\n",
    "# layers = [\n",
    "#     create_layer_info(layer_name, image_mosaick, vis_param, \"Sentinel Mosaicked Image\"),\n",
    "#     create_layer_info(fcd1_1_layer_name, FCD1_1, fcd_visparams, \"Forest Cover Density 1\"),\n",
    "#     create_layer_info(fcd2_1_layer_name, FCD2_1, fcd_visparams, \"Forest Cover Density 2\")\n",
    "# ]\n",
    "\n",
    "# # Generate Map IDs\n",
    "# result = generate_map_id_list(layers)\n",
    "# map_layers = result['map_layers']\n",
    "# map_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c17749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # arc_ops.list_layers = map.listLayers()\n",
    "# # arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "# config['AOI_img'] = AOI_img\n",
    "\n",
    "# class_assigning_fcd =  AssignClassZone(config, FCD1_1=FCD1_1, FCD2_1=FCD2_1)\n",
    "# list_images_classified = class_assigning_fcd.assigning_fcd_class(gfc, minLoss)\n",
    "\n",
    "# fcd_classified_zone = list_images_classified['all_zone']\n",
    "\n",
    "# vis_params_fcd_classified = class_assigning_fcd.vis_param_merged\n",
    "# # Convert the dictionary to the LEGEND_ITEMS format\n",
    "# legend_items = convert_to_legend_items(class_assigning_fcd.legend_class)\n",
    "\n",
    "# # fcd_classified_zone_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(fcd_classified_zone, vis_params_fcd_classified,\n",
    "# #                                                    f'FCD_classified_zone_{project_name}')\n",
    "# wmts.addLayer(fcd_classified_zone, vis_params_fcd_classified, f'FCD_classified_zone_{project_name}')\n",
    "# result = wmts.publish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ADDING DIRECTLY SPECTRAL INDICES\n",
    "# # classImageSpectral\n",
    "# pca_scale = classImageSpectral.pca_scale #pca_scale is spatial resolution. eg planet: 5\n",
    "# ndwi_image = classImageSpectral.NDWI_func()\n",
    "# msavi2_image = classImageSpectral.MSAVI2_func()\n",
    "# mtvi2_image = classImageSpectral.MTVI2_func()\n",
    "# ndvi_image = classImageSpectral.NDVI_func()\n",
    "# vari_image = classImageSpectral.VARI_func()\n",
    "\n",
    "# image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari = (\n",
    "#     image_mosaick\n",
    "#     .addBands(ndwi_image)\n",
    "#     .addBands(msavi2_image)\n",
    "#     .addBands(mtvi2_image)\n",
    "#     .addBands(ndvi_image)\n",
    "#     .addBands(vari_image)\n",
    "# )\n",
    "\n",
    "# red_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['red']), pca_scale=pca_scale, AOI=AOI)\n",
    "# green_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['green']), pca_scale=pca_scale, AOI=AOI)\n",
    "# blue_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['blue']), pca_scale=pca_scale, AOI=AOI)\n",
    "# nir_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['nir']), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# image_norm = red_norm.addBands(green_norm).addBands(blue_norm).addBands(nir_norm)\n",
    "\n",
    "# image_norm_ndvi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('NDVI'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_ndwi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('ndwi'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_msavi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('msavi2'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_mtvi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('MTVI2'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_vari = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('VARI'), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# # red_norm.bandNames().getInfo()\n",
    "# image_norm_with_spectral_indices = image_norm.addBands(image_norm_ndvi).addBands(image_norm_ndwi).addBands(image_norm_msavi2).addBands(image_norm_mtvi2).addBands(image_norm_vari)\n",
    "# image_norm_with_spectral_indices_FCD = image_norm_with_spectral_indices.addBands(FCD2_1.select('FCD').rename('FCD2_1')).addBands(FCD1_1.select('FCD').rename('FCD1_1'))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f23f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obia = OBIASegmentation(config=config, image=image_norm_with_spectral_indices_FCD, pca_scale=pca_scale) #pca_scale basically is spatial resolution e.g planet: 5\n",
    "# clusters = obia.SNIC_cluster()['clusters']\n",
    "# object_properties_image = obia.summarize_cluster(is_include_std = False)\n",
    "\n",
    "# lc = LandcoverML(config=config,\n",
    "#                  input_image = image_norm_with_spectral_indices_FCD,\n",
    "#                 cluster_properties=object_properties_image,\n",
    "#                 pca_scale = pca_scale)\n",
    "\n",
    "# classifier = lc.run_classifier()\n",
    "\n",
    "# legend_lc = lc.lc_legend_param()\n",
    "# vis_param_lc = legend_lc['vis_param_lc']\n",
    "\n",
    "# legend_lc = legend_lc['legend_class']\n",
    "# # Convert the dictionary to the LEGEND_ITEMS format\n",
    "# legend_items_lc = convert_to_legend_items(legend_lc)\n",
    "\n",
    "# training_points = classifier['training_points']\n",
    "# validation_points = classifier['validation_points']\n",
    "\n",
    "# rf = classifier['classified_image_rf']\n",
    "# svm = classifier['classified_image_svm']\n",
    "# gbm = classifier['classified_image_gbm']\n",
    "# cart = classifier['classified_image_cart']\n",
    "\n",
    "# # fcd lc, 5 classes only, just nice to know\n",
    "# fcd_lc = list_images_classified['fcd_class_lc_image']\n",
    "# fcd_lc_vs = list_images_classified['vis_param_segment_lc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_mosaick_all_bands = image_mosaick.addBands([FCD2_1.select('FCD').rename('FCD2_1'), FCD1_1.select('FCD').rename('FCD1_1')])\n",
    "\n",
    "# ## ADDING DIRECTLY SPECTRAL INDICES\n",
    "# # classImageSpectral\n",
    "# pca_scale = classImageSpectral.pca_scale\n",
    "# ndwi_image = classImageSpectral.NDWI_func()\n",
    "# msavi2_image = classImageSpectral.MSAVI2_func()\n",
    "# mtvi2_image = classImageSpectral.MTVI2_func()\n",
    "# ndvi_image = classImageSpectral.NDVI_func()\n",
    "# vari_image = classImageSpectral.VARI_func()\n",
    "\n",
    "# image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari = (\n",
    "#     image_mosaick_all_bands\n",
    "#     .addBands(ndwi_image)\n",
    "#     .addBands(msavi2_image)\n",
    "#     .addBands(mtvi2_image)\n",
    "#     .addBands(ndvi_image)\n",
    "#     .addBands(vari_image)\n",
    "# )\n",
    "\n",
    "# red_norm = normalization_100(image_mosaick.select(['red']), pca_scale=pca_scale, AOI=AOI)\n",
    "# green_norm = normalization_100(image_mosaick.select(['green']), pca_scale=pca_scale, AOI=AOI)\n",
    "# blue_norm = normalization_100(image_mosaick.select(['blue']), pca_scale=pca_scale, AOI=AOI)\n",
    "# nir_norm = normalization_100(image_mosaick.select(['nir']), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# image_norm = red_norm.addBands(green_norm).addBands(blue_norm).addBands(nir_norm)\n",
    "\n",
    "# image_norm_ndvi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('NDVI'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_ndwi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('ndwi'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_msavi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('msavi2'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_mtvi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('MTVI2'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_vari = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('VARI'), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# # red_norm.bandNames().getInfo()\n",
    "# image_norm_with_spectral_indices = image_norm.addBands(image_norm_ndvi).addBands(image_norm_ndwi).addBands(image_norm_msavi2).addBands(image_norm_mtvi2).addBands(image_norm_vari)\n",
    "# image_norm_with_spectral_indices_FCD = image_norm_with_spectral_indices.addBands(FCD2_1.select('FCD').rename('FCD2_1')).addBands(FCD1_1.select('FCD').rename('FCD1_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_mosaick_all_bands = image_mosaick.addBands([FCD2_1.select('FCD').rename('FCD2_1'), FCD1_1.select('FCD').rename('FCD1_1')])\n",
    "\n",
    "# ## ADDING DIRECTLY SPECTRAL INDICES\n",
    "# # classImageSpectral\n",
    "# pca_scale = classImageSpectral.pca_scale\n",
    "# ndwi_image = classImageSpectral.NDWI_func()\n",
    "# msavi2_image = classImageSpectral.MSAVI2_func()\n",
    "# mtvi2_image = classImageSpectral.MTVI2_func()\n",
    "# ndvi_image = classImageSpectral.NDVI_func()\n",
    "# vari_image = classImageSpectral.VARI_func()\n",
    "\n",
    "# image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari = (\n",
    "#     image_mosaick_all_bands\n",
    "#     .addBands(ndwi_image)\n",
    "#     .addBands(msavi2_image)\n",
    "#     .addBands(mtvi2_image)\n",
    "#     .addBands(ndvi_image)\n",
    "#     .addBands(vari_image)\n",
    "# )\n",
    "\n",
    "# red_norm = normalization_100(image_mosaick.select(['red']), pca_scale=pca_scale, AOI=AOI)\n",
    "# green_norm = normalization_100(image_mosaick.select(['green']), pca_scale=pca_scale, AOI=AOI)\n",
    "# blue_norm = normalization_100(image_mosaick.select(['blue']), pca_scale=pca_scale, AOI=AOI)\n",
    "# nir_norm = normalization_100(image_mosaick.select(['nir']), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# image_norm = red_norm.addBands(green_norm).addBands(blue_norm).addBands(nir_norm)\n",
    "\n",
    "# image_norm_ndvi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('NDVI'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_ndwi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('ndwi'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_msavi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('msavi2'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_mtvi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('MTVI2'), pca_scale=pca_scale, AOI=AOI)\n",
    "# image_norm_vari = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('VARI'), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# # red_norm.bandNames().getInfo()\n",
    "# image_norm_with_spectral_indices = image_norm.addBands(image_norm_ndvi).addBands(image_norm_ndwi).addBands(image_norm_msavi2).addBands(image_norm_mtvi2).addBands(image_norm_vari)\n",
    "# image_norm_with_spectral_indices_FCD = image_norm_with_spectral_indices.addBands(FCD2_1.select('FCD').rename('FCD2_1')).addBands(FCD1_1.select('FCD').rename('FCD1_1'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f85f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# obia = OBIASegmentation(config=config, image=image_norm_with_spectral_indices_FCD, pca_scale=pca_scale) #pca_scale basically is spatial resolution e.g planet: 5\n",
    "# clusters = obia.SNIC_cluster()['clusters']\n",
    "# object_properties_image = obia.summarize_cluster(is_include_std = False)\n",
    "# # make sure has all the same type of data in all bands, for exporting purpose\n",
    "# object_properties_image = object_properties_image.clip(AOI).toFloat()\n",
    "\n",
    "# config[\"date_analyzed\"] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# lc = LandcoverML(config=config,\n",
    "#                  input_image = image_norm_with_spectral_indices_FCD,\n",
    "#                 cluster_properties=object_properties_image,\n",
    "#                  num_class=5, # make sure this one is align with total type landcover stratification, for a sample creation, but not for using the existing input training\n",
    "#                 pca_scale = pca_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8357c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "create_training_gee = False\n",
    "\n",
    "#create stratified random sampling based on K-means classes\n",
    "# create_training_gee\n",
    "if create_training_gee:\n",
    "    print('yes')\n",
    "    \n",
    "    ########### SAMPLE NUMBER CREATION BASED ON https://docs.google.com/spreadsheets/d/1J8MEi4IDn6faok6UUn9L64T61yWk0D4q/edit?gid=1919918133#gid=1919918133\n",
    "#     # example\n",
    "#     strata_area_based_kmeans = {\n",
    "#     'Forest': 100,\n",
    "#     'Shrub': 100,\n",
    "#     'Grass': 100,\n",
    "#     'Crop': 100,\n",
    "#     'Water': 100\n",
    "#     }\n",
    "    \n",
    "    # try with K-means input\n",
    "    random_samples_creation = lc.stratified_random_creation()\n",
    "    df_sample_n = random_samples_creation['df_sample_n']\n",
    "    stratified_training = random_samples_creation['stratified_training']\n",
    "       \n",
    "    # Export the samples to a CSV file in Google Drive\n",
    "    export_stratified_point = ee.batch.Export.table.toDrive(\n",
    "        collection=stratified_training,\n",
    "        description=f'Stratified_Random_Samples_{project_name}',\n",
    "        folder=f'lu_input_{project_name}',\n",
    "        fileFormat='SHP'\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    export_stratified_point.start()\n",
    "\n",
    "    # Monitor the task status\n",
    "    import time\n",
    "    while export_stratified_point.active():\n",
    "        print('Export task status:', export_stratified_point.status())\n",
    "        time.sleep(10)\n",
    "\n",
    "    print(f'Export task completed: Stratified_Random_Samples_{project_name}')\n",
    "    \n",
    "    # Open in gdrive in your computer\n",
    "    location_stratified_exported = fr'G:\\My Drive\\lu_input_{project_name}\\Stratified_Random_Samples_{project_name}.shp'\n",
    "    print(location_stratified_exported) #make sure the location is correct (G: is connected by gdrive desktop!)\n",
    "    \n",
    "    # arcgis layer object\n",
    "    training_points = map.addDataFromPath(location_stratified_exported)\n",
    "    # training_points.name = 'change the name here'\n",
    "    \n",
    "    path_shp_input_training = training_points.dataSource\n",
    "    \n",
    "else:\n",
    "    print('we will use the existing training_points or labelled')\n",
    "    print(f'location of the training sample is in {config[\"input_training\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arc_ops.list_layers = map.listLayers()\n",
    "# arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "# starting to do ML analysis\n",
    "classifier = lc.run_classifier()\n",
    "\n",
    "legend_lc = lc.lc_legend_param()\n",
    "vis_param_lc = legend_lc['vis_param_lc']\n",
    "\n",
    "training_points = classifier['training_points']\n",
    "validation_points = classifier['validation_points']\n",
    "\n",
    "rf = classifier['classified_image_rf']\n",
    "svm = classifier['classified_image_svm']\n",
    "gbm = classifier['classified_image_gbm']\n",
    "cart = classifier['classified_image_cart']\n",
    "\n",
    "# fcd lc, 5 classes only, just nice to know\n",
    "fcd_lc = list_images_classified['fcd_class_lc_image']\n",
    "fcd_lc_vs = list_images_classified['vis_param_segment_lc']\n",
    "# fcd_lc_arc = arc_ops.adding_ee_to_arcgisPro(fcd_lc,fcd_lc_vs, 'fcd-method_lc_result')\n",
    "# rf_arc = arc_ops.adding_ee_to_arcgisPro(rf,vis_param_lc,'Random_forest_lc_result')\n",
    "# svm_arc = arc_ops.adding_ee_to_arcgisPro(svm,vis_param_lc,'SVM_lc_result')\n",
    "# gbm_arc = arc_ops.adding_ee_to_arcgisPro(gbm,vis_param_lc,'GBM_lc_result')\n",
    "# cart_arc = arc_ops.adding_ee_to_arcgisPro(cart,vis_param_lc,'CART_lc_result')\n",
    "\n",
    "wmts.addLayer(rf, vis_param_lc, 'Random_forest_lc_result')\n",
    "wmts.addLayer(svm, vis_param_lc, 'SVM_lc_result')\n",
    "wmts.addLayer(gbm, vis_param_lc, 'GBM_lc_result')\n",
    "wmts.addLayer(cart, vis_param_lc, 'CART_lc_result')\n",
    "result = wmts.publish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.getcwd(),\"01_output\") # example we create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "lc.matrix_confusion(fcd_lc,validation_points,'fcd',output_dir)\n",
    "lc.matrix_confusion(rf, validation_points, 'rf', output_dir)\n",
    "lc.matrix_confusion(svm, validation_points, 'svm', output_dir)\n",
    "lc.matrix_confusion(gbm, validation_points, 'gbm', output_dir)\n",
    "lc.matrix_confusion(cart, validation_points, 'cart', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_ml_selected = 'rf'\n",
    "selected_image_lc = rf\n",
    "if config['algo_ml_selected'] == 'rf':\n",
    "    algo_ml_selected = 'rf'\n",
    "    selected_image_lc = rf\n",
    "elif config['algo_ml_selected'] == 'svm':\n",
    "    algo_ml_selected = 'svm'\n",
    "    selected_image_lc = svm\n",
    "elif config['algo_ml_selected'] == 'gbm':\n",
    "    algo_ml_selected = 'gbm'\n",
    "    selected_image_lc = gbm\n",
    "elif config['algo_ml_selected'] == 'cart':\n",
    "    algo_ml_selected = 'cart'\n",
    "    selected_image_lc = cart\n",
    "print('algo_ml_selected: ',algo_ml_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d182ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-overlay the data for zoning from the selected method if they give the best metric, and when we check visually the land cover map make sense, also FCD approach is already there\n",
    "image_for_zone = selected_image_lc\n",
    "\n",
    "# comment this first, just check the LC above, then run the overlay zoning classification after\n",
    "HighForestDense = list_images_classified['HighForestDense']\n",
    "\n",
    "final_zone = class_assigning_fcd.assign_zone_ml(image_for_zone, minLoss,AOI_img, HighForestDense)\n",
    "wmts.addLayer(final_zone, vis_params_fcd_classified, f'Final_zone_ML_{algo_ml_selected}_Hansen')\n",
    "result = wmts.publish()\n",
    "\n",
    "# arc_ops.adding_ee_to_arcgisPro(final_zone, vis_params_fcd_classified, f'Final_zone_ML_{algo_ml_selected}_Hansen')  # the naming probably will need to change, for some concistencies only so that you understand again later to read the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3997f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
