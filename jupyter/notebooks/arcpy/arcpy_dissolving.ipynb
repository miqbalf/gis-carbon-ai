{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf7ee1-8c1d-4c23-acff-0a62e693c12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y:\\\\gis-carbon-ai\\\\jupyter\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4bb52a-b601-49d0-9fc8-b3defd3ebd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "# arcpy.SignInToPortal()\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = '00_input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6dad72-2fce-474d-81e8-c274180a9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbd3a72-f002-4f59-bfad-60f3dc0f3f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944821f6-7872-4059-a402-4bf6e8bcf697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getenv(\"GOOGLE_CLOUD_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6592390-c634-4279-ad21-973e0aa05cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "gcs = gcsfs.GCSFileSystem(project=os.getenv(\"GOOGLE_CLOUD_PROJECT\"), token='../../backend/user_id.json')\n",
    "fs = gcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95b0dd8-6d1a-4902-8932-cdd900e7e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DS TRAIN CHECK RESAMPLING\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "path_training = '00_input/training_shp/'\n",
    "\n",
    "layers = [shp for shp in os.listdir(path_training) if shp.endswith('.shp') and shp.startswith('sample')]\n",
    "gcs_path = 'gs://{os.getenv('GCS_BUCKET_PATH')}/01-korindo/sample_tsfresh/20251112_training_gdf_col_filtered.parquet'\n",
    "\n",
    "use_parquet_training = True\n",
    "\n",
    "if use_parquet_training != True:\n",
    "    gdf_list = []\n",
    "\n",
    "    for lyr in layers:\n",
    "        print(lyr)\n",
    "    gdf = gpd.read_file(os.path.join(path_training,lyr))\n",
    "    gdf['layer'] = lyr.replace('.shp', '')\n",
    "    print(gdf.crs)\n",
    "    gdf_utm = gdf.to_crs(crs_ds)\n",
    "    gdf_list.append(gdf_utm)\n",
    "\n",
    "    training_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))\n",
    "    # training_gdf = gpd.read_file('00_input/training_shp/sample_1.shp')\n",
    "    # training_gdf.head()\n",
    "    # training_gdf.head()\n",
    "\n",
    "    # training_gdf.crs\n",
    "\n",
    "    # training_gdf.geometry.head()\n",
    "    # training_gdf.columns\n",
    "\n",
    "    list_columns_time = [i for i in training_gdf.columns if i.startswith('t_') and not i.endswith('D')]\n",
    "    list_columns_time = list(sorted(list_columns_time))\n",
    "    # list_columns_time\n",
    "\n",
    "    columns_filter = ['layer'] + list_columns_time + ['geometry']\n",
    "\n",
    "    training_gdf_col_filtered = training_gdf[columns_filter]\n",
    "    # training_gdf_col_filtered.head()\n",
    "    # training_gdf_col_filtered.plot()\n",
    "\n",
    "    print(training_gdf_col_filtered.shape)\n",
    "\n",
    "    # Save as GeoParquet (BEST option)\n",
    "    gcs_path = gcs_path    \n",
    "    training_gdf_col_filtered.to_parquet(gcs_path, filesystem=fs, compression='snappy')\n",
    "\n",
    "else:\n",
    "    training_gdf_col_filtered = gpd.read_parquet(gcs_path, filesystem=fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa55fa44-3e83-4d70-b5ae-ca896283e425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>t_201603</th>\n",
       "      <th>t_201606</th>\n",
       "      <th>t_201609</th>\n",
       "      <th>t_201612</th>\n",
       "      <th>t_201703</th>\n",
       "      <th>t_201706</th>\n",
       "      <th>t_201709</th>\n",
       "      <th>t_201712</th>\n",
       "      <th>t_201803</th>\n",
       "      <th>...</th>\n",
       "      <th>t_202501</th>\n",
       "      <th>t_202502</th>\n",
       "      <th>t_202503</th>\n",
       "      <th>t_202504</th>\n",
       "      <th>t_202505</th>\n",
       "      <th>t_202506</th>\n",
       "      <th>t_202507</th>\n",
       "      <th>t_202508</th>\n",
       "      <th>t_202509</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((591831.671 9951866.774, 592488.463 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((590668.414 9951528.793, 590655.818 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((592279.476 9951073.580, 592242.830 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((591967.853 9951121.158, 591963.540 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((590410.775 9951324.006, 590396.290 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      layer  t_201603  t_201606  t_201609  t_201612  t_201703  t_201706  \\\n",
       "0  sample_2       NaN       1.0       1.0       1.0       1.0       1.0   \n",
       "1  sample_2       NaN       0.0       0.0       0.0       1.0       1.0   \n",
       "2  sample_2       NaN       1.0       1.0       1.0       1.0       1.0   \n",
       "3  sample_2       NaN       1.0       1.0       1.0       1.0       1.0   \n",
       "4  sample_2       NaN       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   t_201709  t_201712  t_201803  ...  t_202501  t_202502  t_202503  t_202504  \\\n",
       "0       1.0       1.0       1.0  ...       1.0       1.0       1.0       1.0   \n",
       "1       1.0       1.0       1.0  ...       1.0       1.0       1.0       1.0   \n",
       "2       1.0       1.0       1.0  ...       1.0       1.0       1.0       1.0   \n",
       "3       1.0       1.0       1.0  ...       1.0       1.0       1.0       1.0   \n",
       "4       0.0       0.0       0.0  ...       1.0       1.0       1.0       1.0   \n",
       "\n",
       "   t_202505  t_202506  t_202507  t_202508  t_202509  \\\n",
       "0       1.0       1.0       1.0       1.0       NaN   \n",
       "1       1.0       1.0       1.0       1.0       NaN   \n",
       "2       1.0       1.0       1.0       1.0       NaN   \n",
       "3       1.0       1.0       1.0       1.0       NaN   \n",
       "4       1.0       1.0       1.0       1.0       NaN   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((591831.671 9951866.774, 592488.463 9...  \n",
       "1  POLYGON ((590668.414 9951528.793, 590655.818 9...  \n",
       "2  POLYGON ((592279.476 9951073.580, 592242.830 9...  \n",
       "3  POLYGON ((591967.853 9951121.158, 591963.540 9...  \n",
       "4  POLYGON ((590410.775 9951324.006, 590396.290 9...  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_gdf_col_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb57575-b6eb-4559-8ded-47e1fda65980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (131301, 71)\n",
      "Long format shape: (9059769, 4)\n",
      "Time columns found: 69\n",
      "{\"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\", \"type\": \"ProjectedCRS\", \"name\": \"WGS 84 / UTM zone 49S\", \"base_crs\": {\"name\": \"WGS 84\", \"datum_ensemble\": {\"name\": \"World Geodetic System 1984 ensemble\", \"members\": [{\"name\": \"World Geodetic System 1984 (Transit)\"}, {\"name\": \"World Geodetic System 1984 (G730)\"}, {\"name\": \"World Geodetic System 1984 (G873)\"}, {\"name\": \"World Geodetic System 1984 (G1150)\"}, {\"name\": \"World Geodetic System 1984 (G1674)\"}, {\"name\": \"World Geodetic System 1984 (G1762)\"}, {\"name\": \"World Geodetic System 1984 (G2139)\"}], \"ellipsoid\": {\"name\": \"WGS 84\", \"semi_major_axis\": 6378137, \"inverse_flattening\": 298.257223563}, \"accuracy\": \"2.0\", \"id\": {\"authority\": \"EPSG\", \"code\": 6326}}, \"coordinate_system\": {\"subtype\": \"ellipsoidal\", \"axis\": [{\"name\": \"Geodetic latitude\", \"abbreviation\": \"Lat\", \"direction\": \"north\", \"unit\": \"degree\"}, {\"name\": \"Geodetic longitude\", \"abbreviation\": \"Lon\", \"direction\": \"east\", \"unit\": \"degree\"}]}, \"id\": {\"authority\": \"EPSG\", \"code\": 4326}}, \"conversion\": {\"name\": \"UTM zone 49S\", \"method\": {\"name\": \"Transverse Mercator\", \"id\": {\"authority\": \"EPSG\", \"code\": 9807}}, \"parameters\": [{\"name\": \"Latitude of natural origin\", \"value\": 0, \"unit\": \"degree\", \"id\": {\"authority\": \"EPSG\", \"code\": 8801}}, {\"name\": \"Longitude of natural origin\", \"value\": 111, \"unit\": \"degree\", \"id\": {\"authority\": \"EPSG\", \"code\": 8802}}, {\"name\": \"Scale factor at natural origin\", \"value\": 0.9996, \"unit\": \"unity\", \"id\": {\"authority\": \"EPSG\", \"code\": 8805}}, {\"name\": \"False easting\", \"value\": 500000, \"unit\": \"metre\", \"id\": {\"authority\": \"EPSG\", \"code\": 8806}}, {\"name\": \"False northing\", \"value\": 10000000, \"unit\": \"metre\", \"id\": {\"authority\": \"EPSG\", \"code\": 8807}}]}, \"coordinate_system\": {\"subtype\": \"Cartesian\", \"axis\": [{\"name\": \"Easting\", \"abbreviation\": \"E\", \"direction\": \"east\", \"unit\": \"metre\"}, {\"name\": \"Northing\", \"abbreviation\": \"N\", \"direction\": \"north\", \"unit\": \"metre\"}]}, \"scope\": \"Navigation and medium accuracy spatial referencing.\", \"area\": \"Between 108\\u00b0E and 114\\u00b0E, southern hemisphere between 80\\u00b0S and equator, onshore and offshore. Australia. Indonesia.\", \"bbox\": {\"south_latitude\": -80, \"west_longitude\": 108, \"north_latitude\": 0, \"east_longitude\": 114}, \"id\": {\"authority\": \"EPSG\", \"code\": 32749}}\n",
      "shape of training_gdf after drop NA: (8791293, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "use_existing_df_long = False # save some cost here to download from gcs\n",
    "#gcs_path_df_long = 'gs://{os.getenv('GCS_BUCKET_PATH')}/01-korindo/sample_tsfresh/20251112_df_long.parquet'\n",
    "\n",
    "if use_existing_df_long != True:\n",
    "    # training_gdf_col_filtered\n",
    "\n",
    "    t_cols = [col for col in training_gdf_col_filtered.columns if col.startswith('t_')]\n",
    "\n",
    "    # Melt the dataframe with geometry as id_var\n",
    "    df_long = pd.melt(\n",
    "        training_gdf_col_filtered, \n",
    "        id_vars=['layer','geometry'],\n",
    "        value_vars=t_cols,\n",
    "        var_name='time_period',\n",
    "        value_name='value'\n",
    "    )\n",
    "\n",
    "    # Set geometry as index\n",
    "    # df_long = df_long.set_index('geometry')\n",
    "\n",
    "    print(f\"Original shape: {training_gdf_col_filtered.shape}\")\n",
    "    print(f\"Long format shape: {df_long.shape}\")\n",
    "    print(f\"Time columns found: {len(t_cols)}\")\n",
    "    # print(f\"\\nFirst few rows:\")\n",
    "    # df_long.head()\n",
    "    # df_long.layer.unique()\n",
    "\n",
    "    # df_long.reset_index(inplace=True)\n",
    "    # df_long.head()\n",
    "\n",
    "    ## reformating the column (date)\n",
    "    df_long = df_long.rename(columns={'value': 'type'})\n",
    "    df_long['date'] = df_long['time_period'].str[2:].astype(int)\n",
    "    # df_long.head()\n",
    "\n",
    "    # type(df_long)\n",
    "\n",
    "    training_gdf = df_long.copy()\n",
    "    # Remove multipolygons\n",
    "    # training_gdf = training_gdf.explode()\n",
    "    print(training_gdf.crs)\n",
    "\n",
    "    ##### conversion\n",
    "    # Drop rows where 'type' is NA\n",
    "    training_gdf = training_gdf.copy()\n",
    "    training_gdf = training_gdf.dropna(subset=['type'])\n",
    "    training_gdf['date'] = pd.to_datetime(training_gdf['date'], format='%Y%m')\n",
    "\n",
    "    # add year columnt\n",
    "    training_gdf['year'] = training_gdf['date'].dt.year\n",
    "\n",
    "    # convert column 'type' from string to int\n",
    "    training_gdf['type'] = training_gdf['type'].astype(int)\n",
    "    print('shape of training_gdf after drop NA:', training_gdf.shape)\n",
    "    \n",
    "    # training_gdf.to_parquet(gcs_path_df_long, filesystem=fs, compression='snappy') # i shouldn't export for now\n",
    "\n",
    "else:\n",
    "    training_gdf = gpd.read_parquet(gcs_path_df_long, filesystem=fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe5f85c-d2cd-4a75-8dde-2ab7cee1aa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>geometry</th>\n",
       "      <th>time_period</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131213</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>POLYGON ((584180.083 9968585.299, 584157.366 9...</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131214</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>POLYGON ((583509.394 9968409.259, 583519.222 9...</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131215</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>POLYGON ((585435.167 9969315.480, 585465.247 9...</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131216</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>POLYGON ((585162.142 9969842.168, 585157.111 9...</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131217</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>POLYGON ((584315.521 9969957.392, 584316.046 9...</td>\n",
       "      <td>t_201603</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           layer                                           geometry  \\\n",
       "131213  sample_3  POLYGON ((584180.083 9968585.299, 584157.366 9...   \n",
       "131214  sample_3  POLYGON ((583509.394 9968409.259, 583519.222 9...   \n",
       "131215  sample_3  POLYGON ((585435.167 9969315.480, 585465.247 9...   \n",
       "131216  sample_3  POLYGON ((585162.142 9969842.168, 585157.111 9...   \n",
       "131217  sample_3  POLYGON ((584315.521 9969957.392, 584316.046 9...   \n",
       "\n",
       "       time_period  type       date  year  \n",
       "131213    t_201603     1 2016-03-01  2016  \n",
       "131214    t_201603     1 2016-03-01  2016  \n",
       "131215    t_201603     1 2016-03-01  2016  \n",
       "131216    t_201603     1 2016-03-01  2016  \n",
       "131217    t_201603     1 2016-03-01  2016  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a764b7e4-a4d8-40a9-8e07-f59266d473c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DISSOLVING, takes too long:\n",
    "# gdf_1_dissolved = training_gdf[training_gdf['type'] == 1].dissolve(by=['date', 'layer'])\n",
    "# gdf_0_dissolved = training_gdf[training_gdf['type'] == 0].dissolve(by=['date', 'layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5b014e-411a-4f77-a518-bf6a095e1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().resolve().parents[1]  # adjust if your cwd differs\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from arcpy_arcgis_api_lib.xls_append.data_val import pandas_to_esri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf202c6-0d39-4459-a594-26e7f82ad414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcpy_arcgis_api_lib.xls_append.data_val import pandas_to_esri\n",
    "\n",
    "def export_training_gdf_to_feature_class(\n",
    "    training_gdf: gpd.GeoDataFrame,\n",
    "    gdb_name: str = \"training_timeseries.gdb\",\n",
    "    feature_class_name: str = \"training_timeseries\",\n",
    "    workspace: str | None = None,\n",
    "    overwrite: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Persist `training_gdf` into a file geodatabase feature class.\n",
    "\n",
    "    - Creates the target GDB inside `workspace` (default: `arcpy.env.workspace`)\n",
    "    - Uses `arcgis.features.GeoAccessor` for conversion, so geometry/CRS are preserved\n",
    "    - Leverages `arcpy_arcgis_api_lib`’s `pandas_to_esri` mapping to preview ArcGIS field types\n",
    "    \"\"\"\n",
    "    if not isinstance(training_gdf, gpd.GeoDataFrame):\n",
    "        raise TypeError(\"training_gdf must be a GeoDataFrame\")\n",
    "\n",
    "    if training_gdf.crs is None:\n",
    "        raise ValueError(\"training_gdf is missing a CRS; set one before exporting\")\n",
    "\n",
    "    base_workspace = workspace or arcpy.env.workspace or arcpy.env.scratchWorkspace\n",
    "    if base_workspace is None:\n",
    "        raise ValueError(\"Set `arcpy.env.workspace` or pass a `workspace` path\")\n",
    "\n",
    "    gdb_path = Path(base_workspace) / gdb_name\n",
    "    if gdb_path.suffix.lower() != \".gdb\":\n",
    "        gdb_path = gdb_path.with_suffix(\".gdb\")\n",
    "    gdb_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not arcpy.Exists(str(gdb_path)):\n",
    "        arcpy.management.CreateFileGDB(str(gdb_path.parent), gdb_path.name)\n",
    "\n",
    "    esri_type_preview = {\n",
    "        col: pandas_to_esri.get(str(training_gdf[col].dtype), \"esriFieldTypeString\")\n",
    "        for col in training_gdf.columns\n",
    "        if col != training_gdf.geometry.name\n",
    "    }\n",
    "    display(pd.DataFrame.from_dict(esri_type_preview, orient=\"index\", columns=[\"esri_type\"]))\n",
    "\n",
    "    sedf = GeoAccessor.from_geodataframe(training_gdf)\n",
    "    output_fc = str(gdb_path / feature_class_name)\n",
    "\n",
    "    if arcpy.Exists(output_fc) and overwrite:\n",
    "        arcpy.management.Delete(output_fc)\n",
    "\n",
    "    sedf.spatial.to_featureclass(location=output_fc)\n",
    "    return output_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e473238-06f6-4307-a93c-540b9f8ac268",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_class_path = export_training_gdf_to_feature_class(\n",
    "    training_gdf,\n",
    "    gdb_name=\"training.gdb\",\n",
    "    feature_class_name=\"korindo_training_long\"\n",
    ")\n",
    "print(f\"Feature class saved to: {feature_class_path}\")\n",
    "print(arcpy.management.GetCount(feature_class_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b593d-05f9-4b3e-a4f9-f26c62535e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_class_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}